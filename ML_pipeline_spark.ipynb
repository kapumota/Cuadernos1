{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines de ML usando SparkML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='color: red'>El propósito de este cuaderno es mostrarte cómo usar SparkML para crear pipelines de aprendizaje automático.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Tabla de contenidos__\n",
    "\n",
    "<ol>\n",
    "  <li>\n",
    "    <a href=\"#Objectives\">Objetivos\n",
    "    </a>\n",
    "  </li>\n",
    "  <li>\n",
    "    <a href=\"#Datasets\">Conjuntos de datos\n",
    "    </a>\n",
    "  </li>\n",
    "  <li>\n",
    "    <a href=\"#Setup\">Configuración\n",
    "    </a>\n",
    "    <ol>\n",
    "      <li>\n",
    "        <a href=\"#Installing-Required-Libraries\">Instalación de librerías requeridas\n",
    "        </a>\n",
    "      </li>\n",
    "      <li>\n",
    "        <a href=\"#Importing-Required-Libraries\">Importación de librerías requeridas\n",
    "        </a>\n",
    "      </li>\n",
    "    </ol>\n",
    "  </li>\n",
    "  <li>\n",
    "    <a href=\"#Examples\">Ejemplos\n",
    "    </a>\n",
    "    <ol>\n",
    "    <li>\n",
    "      <a href=\"#Task-1---Load-data-set\">Tarea 1 - Cargar conjunto de datos\n",
    "      </a>\n",
    "    </li>\n",
    "    <li>\n",
    "      <a href=\"#Task-2---Define-pipeline-stages\">Tarea 2 - Definir etapas del pipeline\n",
    "      </a>\n",
    "    </li>\n",
    "    <li>\n",
    "      <a href=\"#Task-3---Build-the-pipeline\">Tarea 3 - Construir el pipeline\n",
    "      </a>\n",
    "    </li>\n",
    "    <li>\n",
    "      <a href=\"#Task-4---Split-the-data\">Tarea 4 - Dividir los datos\n",
    "      </a>\n",
    "    </li>\n",
    "    <li>\n",
    "      <a href=\"#Task-5---Fit-the-pipeline\">Tarea 5 - Ajustar el pipeline\n",
    "      </a>\n",
    "    </li>\n",
    "    <li>\n",
    "      <a href=\"#Task-6---Evaluate-the-model\">Tarea 6 - Evaluar el modelo\n",
    "      </a>\n",
    "    </li>\n",
    "    </ol>\n",
    "  </li>\n",
    "  <li>\n",
    "    <a href=\"#Exercises\">Ejercicios\n",
    "    </a>\n",
    "  </li>\n",
    "  <ol>\n",
    "    <li>\n",
    "      <a href=\"#Exercise-1---Load-data-set\">Ejercicio 1 - Cargar conjunto de datos\n",
    "      </a>\n",
    "    </li>\n",
    "    <li>\n",
    "      <a href=\"#Exercise-2---Define-pipeline-stages\">Ejercicio 2 - Definir etapas del pipeline\n",
    "      </a>\n",
    "    </li>\n",
    "    <li>\n",
    "      <a href=\"#Exercise-3---Build-the-pipeline\">Ejercicio 3 - Construir el pipeline\n",
    "      </a>\n",
    "    </li>\n",
    "    <li>\n",
    "      <a href=\"#Exercise-4---Split-the-data\">Ejercicio 4 - Dividir los datos\n",
    "      </a>\n",
    "    </li>\n",
    "    <li>\n",
    "      <a href=\"#Exercise-5---Fit-the-pipeline\">Ejercicio 5 - Ajustar el pipeline\n",
    "      </a>\n",
    "    </li>\n",
    "    <li>\n",
    "      <a href=\"#Exercise-6---Evaluate-the-model\">Ejercicio 6 - Evaluar el modelo\n",
    "      </a>\n",
    "    </li>\n",
    "  </ol>\n",
    "</ol>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivos\n",
    "\n",
    "Después de completar este cuaderno podrás:\n",
    "\n",
    " - Crear un pipeline de aprendizaje automático.\n",
    " - Agregar etapas al pipeline.\n",
    " - Ejecutar el pipeline.\n",
    " - Crear un pipeline de aprendizaje automático para regresión.\n",
    " - Crear un pipeline de aprendizaje automático para clasificación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjuntos de datos\n",
    "\n",
    "En este cuaderno utilizaremos los siguientes conjuntos de datos:\n",
    "\n",
    " - Versión modificada del conjunto de datos de millaje de automóviles. Conjunto de datos original disponible en https://archive.ics.uci.edu/ml/datasets/auto+mpg \n",
    " - Versión modificada del conjunto de datos Iris. Conjunto de datos original disponible en https://archive.ics.uci.edu/ml/datasets/Iris \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuración\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyspark==3.1.2 -q\n",
    "#!pip install findspark -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importación de librerías requeridas\n",
    "\n",
    "_Recomendamos importar todas las librerías necesarias en un solo lugar (aquí):_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puedes usar esta sección para suprimir advertencias generadas por tu código\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# FindSpark simplifica el proceso de uso de Apache Spark con Python\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "# Importar funciones y clases para modelos de Machine Learning en SparkML\n",
    "from pyspark.ml.regression import LinearRegression  # Regresión Lineal\n",
    "from pyspark.ml.classification import LogisticRegression  # Regresión Logística\n",
    "\n",
    "# Importar herramientas para la transformación de datos\n",
    "from pyspark.ml.feature import VectorAssembler  # Ensamblaje de vectores de características\n",
    "from pyspark.ml.feature import StandardScaler  # Normalización de características\n",
    "from pyspark.ml.feature import StringIndexer  # Indexación de variables categóricas\n",
    "\n",
    "# Crear una sesión de Spark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Importar funciones y clases para la creación de pipelines\n",
    "from pyspark.ml import Pipeline  \n",
    "\n",
    "# Importar funciones y clases para la evaluación de modelos\n",
    "from pyspark.ml.evaluation import RegressionEvaluator  # Evaluador para modelos de regresión\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator  # Evaluador para clasificación multicategoría\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 1 - Cargar conjunto de datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignoramos warnings de comandos de SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Ejemplo de un pipeline de ML\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descargar el archivo de datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0231EN-SkillsNetwork/datasets/mpg.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga el conjunto de datos en el DataFrame de Spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando la función spark.read.csv, cargamos los datos en un DataFrame.\n",
    "# El parámetro header=True indica que el archivo CSV tiene una fila de encabezado.\n",
    "# El parámetro inferSchema=True permite que Spark detecte automáticamente los tipos de datos de las columnas.\n",
    "\n",
    "# Se carga el conjunto de datos mpg\n",
    "mpg_data = spark.read.csv(\"mpg.csv\", header=True, inferSchema=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprime el esquema del conjunto de datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muestra las primeras 5 filas del conjunto de datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2 - Definimos etapas del pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etapa 1 - Ensambla las columnas de entrada en un único vector\n",
    "vectorAssembler = VectorAssembler(\n",
    "    inputCols=[\"Weight\", \"Horsepower\", \"Engine Disp\"],  # Columnas de entrada\n",
    "    outputCol=\"features\"  # Nombre de la columna de salida con el vector ensamblado\n",
    ")\n",
    "\n",
    "# Etapa 2 - Escala las características utilizando StandardScaler\n",
    "scaler = StandardScaler(\n",
    "    inputCol=\"features\",  # Columnas de entrada a escalar\n",
    "    outputCol=\"scaledFeatures\"  # Nombre de la columna de salida con las características escaladas\n",
    ")\n",
    "\n",
    "# Etapa 3 - Crea una instancia de regresión lineal\n",
    "lr = LinearRegression(\n",
    "    featuresCol=\"scaledFeatures\",  # Columnas de características a usar en la regresión\n",
    "    labelCol=\"MPG\"  # Variable objetivo (consumo de combustible en millas por galón)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 3 - Se construye el pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construcción del pipeline\n",
    "# Se mencionan todas las etapas del pipeline en el orden de ejecución.\n",
    "pipeline = Pipeline(stages=[vectorAssembler, scaler, lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 4 - Se divide los datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se divide los datos en conjuntos de entrenamiento y prueba\n",
    "(trainingData, testData) = mpg_data.randomSplit([0.7, 0.3], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 5 -  Se ajusta el pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajusta el pipeline a los datos de entrenamiento\n",
    "# Ignora cualquier advertencia. Las advertencias se deben a configuraciones simplificadas y ajustes de seguridad del entorno de laboratorio.\n",
    "\n",
    "model = pipeline.fit(trainingData)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 6 - Evaluación del modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizar predicciones en los datos de prueba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprime el valor de RMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"MPG\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) =\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detenine la sesión de Spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicios\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 1 - Cargar conjunto de datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea SparkSession con appname \"Ejercicio de pipeline ML\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignore any warnings by SparkSession command\n",
    "\n",
    "spark = #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Haz clic aquí para una pista</summary>\n",
    "    \n",
    "Utiliza SparkSession.builder\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Haz clic aquí para la solución</summary>\n",
    "    \n",
    "```python\n",
    "spark = SparkSession.builder.appName(\"ML Pipeline Exercise\").getOrCreate()\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descarga el conjunto de datos iris\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0231EN-SkillsNetwork/datasets/iris.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga el conjunto de datos en el DataFrame de Spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Haz clic aquí para una pista</summary>\n",
    "    \n",
    "Utiliza el método spark.read.csv\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Haz clic aquí para la solución</summary>\n",
    "    \n",
    "```python\n",
    "iris_data = spark.read.csv(\"iris.csv\", header=True, inferSchema=True)\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprime el esquema del conjunto de datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observa que la \"Species\" es una columna de tipo cadena\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muestra las primeras 5 filas del conjunto de datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 2 - Definir etapas del pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etapa 1 - Crea una etapa indexadora utilizando StringIndexer que convierta la columna Species en una columna numérica llamada \"label\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Haz clic aquí para una pista</summary>\n",
    "    \n",
    "Utiliza StringIndexer con inputCol como \"Species\" y outputCol como \"label\"\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Haz clic aquí para la solución</summary>\n",
    "    \n",
    "```python\n",
    "indexer = StringIndexer(inputCol=\"Species\", outputCol=\"label\")\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etapa 2 - Crea una etapa vectorAssembler que genere un vector de características llamado features utilizando \"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorAssembler = #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Haz clic aquí para una pista</summary>\n",
    "    \n",
    "Utiliza el VectorAssembler\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Haz clic aquí para la solución</summary>\n",
    "    \n",
    "```python\n",
    "vectorAssembler = VectorAssembler(inputCols=[\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\",\"PetalWidthCm\"], outputCol=\"features\")\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etapa 3 - Creaa una etapa escaladora que escale las características utilizando StandardScaler, y nombra la columna de salida como scaledFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Haz clic aquí para una pista</summary>\n",
    "    \n",
    "Utiliza el StandardScaler\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Haz clic aquí para la solución</summary>\n",
    "    \n",
    "```python\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etapa 4 - Crea una etapa de regresión logística usando featuresCol=\"scaledFeatures\", labelCol=\"label\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Haz clic aquí para una pista</summary>\n",
    "    \n",
    "Utiliza SparkSession.builder\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Haz clic aquí para la solución</summary>\n",
    "    \n",
    "```python\n",
    "classifier = LogisticRegression(featuresCol=\"scaledFeatures\", labelCol=\"label\")\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 3 - Construir el pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construye un pipeline con las cuatro etapas creadas anteriormente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Haz clic aquí para una pista</summary>\n",
    "    \n",
    "Construye el pipeline utilizando las 4 etapas creadas anteriormente\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Haz clic aquí para la solución</summary>\n",
    "    \n",
    "```python\n",
    "pipeline = Pipeline(stages=[indexer,vectorAssembler, scaler, classifier])\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 4 - Dividir los datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide los datos en conjuntos de entrenamiento y prueba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = iris_data.randomSplit([0.7, 0.3], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 5 - Ajustar el pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajusta el pipeline a los datos de entrenamiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = #TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Haz clic aquí para una pista</summary>\n",
    "    \n",
    "Utiliza el método fit del pipeline\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Haz clic aquí para la solución</summary>\n",
    "    \n",
    "```python\n",
    "model = pipeline.fit(trainingData)\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 6 - Evaluar el modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realiza predicciones en los datos de prueba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Haz clic aquí para una pista</summary>\n",
    "    \n",
    "Utiliza el método transform del modelo\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Haz clic aquí para la solución</summary>\n",
    "    \n",
    "```python\n",
    "predictions = model.transform(testData)\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluar el rendimiento del modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprime el valor de RMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy =\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detiene la sesión de Spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "prev_pub_hash": "4bc9b90337588bf090800ef1b66ab21220ebda6c01cfc7d3c1a630354810e8ba"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

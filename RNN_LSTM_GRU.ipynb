{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLeftss5kqL4"
   },
   "source": [
    "### Redes neuronales recurrentes\n",
    "\n",
    "Sea la siguiente red neuronal recurrente:\n",
    "\n",
    "![RNN.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gseb1Ov8land"
   },
   "source": [
    "La relación de recurrencia:\n",
    "\n",
    "$s_t = f(W s_{t -1} + Ux_t)$.\n",
    "\n",
    "Implementamos una relación de recurrencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 608,
     "status": "ok",
     "timestamp": 1625710143968,
     "user": {
      "displayName": "CESAR JESUS LARA AVILA",
      "photoUrl": "",
      "userId": "01059333317062820707"
     },
     "user_tz": 300
    },
    "id": "JFuDFDF5lme6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1625710144601,
     "user": {
      "displayName": "CESAR JESUS LARA AVILA",
      "photoUrl": "",
      "userId": "01059333317062820707"
     },
     "user_tz": 300
    },
    "id": "Dhsjak11khXz"
   },
   "outputs": [],
   "source": [
    "def pasos(s, x, U, W):\n",
    "  return x * U + s * W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IR2CX_vtlw-x"
   },
   "source": [
    "En el siguiente bloque de código, realizamos una implementación del paso hacia adelante, que devuelve la activación $s$ para cada paso recurrente y cada muestra en el lote: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1625710144602,
     "user": {
      "displayName": "CESAR JESUS LARA AVILA",
      "photoUrl": "",
      "userId": "01059333317062820707"
     },
     "user_tz": 300
    },
    "id": "Fwypm6iLlh65"
   },
   "outputs": [],
   "source": [
    "def forward(x, U, W):\n",
    "  numero_de_muestras = len(x) # numero de muestras en el minibatch\n",
    "  longitud_secuencia = len(x[0]) # Longitud de la muestra\n",
    "\n",
    "  s = np.zeros((numero_de_muestras, longitud_secuencia + 1))\n",
    "\n",
    "  #Actualizar los estados en la secuencia\n",
    "  for t in range(0, longitud_secuencia):\n",
    "    s[:, t +1] = pasos(s[:, t], x[:, t], U, W)  # funcion de pasos\n",
    "\n",
    "  return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1DVcTFxnR-A"
   },
   "source": [
    "Ahora que tenemos la función de pérdida y paso hacia adelante, podemos definir cómo se propaga el gradiente hacia atrás. Dado que el RNN desplegado es equivalente a una red de retroalimentación regular, podemos usar la regla de la cadena de retropropagación que presentamos anteriormente.\n",
    "\n",
    "Debido a que los pesos, W y U, se comparten entre las capas, acumularemos las derivadas de error para cada paso recurrente y al final, actualizaremos los pesos con el valor acumulado. \n",
    "\n",
    "Primero, necesitamos obtener el gradiente de la salida, $\\mathbf{s}_t$, con respecto a la función de pérdida $\\partial E/\\partial s$. Una vez que tenemos esta función la propagaremos hacia atrás a través de la pila de actividades que construimos durante el paso hacia adelante. Este pase hacia atrás saca las actividades de la pila para acumular las derivadas de error en cada paso de tiempo. La relación de recurrencia para propagar este gradiente a través de la red se puede escribir de la siguiente manera (regla de la cadena):\n",
    "\n",
    "$$\\frac{\\partial E}{\\partial s_{t -1}} = \\frac{\\partial E}{\\partial s_t}\\frac{\\partial s_t}{\\partial s_{t -1}} = \\frac{\\partial E}{\\partial s_t}W$$\n",
    "\n",
    "Aquí $E$ es la función de pérdida.\n",
    "\n",
    "Los gradientes de los pesos, U y W, se acumulan de la siguiente manera: \n",
    "\n",
    "$$\\frac{\\partial E}{\\partial U} = \\sum_{t =0}^{n}\\frac{\\partial E}{\\partial s_t}x_t$$\n",
    "\n",
    "$$\\frac{\\partial E}{\\partial W} = \\sum_{t =0}^{n}\\frac{\\partial E}{\\partial s_t}s_{t -1}$$\n",
    "\n",
    "\n",
    "La siguiente es una implementación del pase hacia atrás: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1625710144603,
     "user": {
      "displayName": "CESAR JESUS LARA AVILA",
      "photoUrl": "",
      "userId": "01059333317062820707"
     },
     "user_tz": 300
    },
    "id": "mmYa3-yYmUIH"
   },
   "outputs": [],
   "source": [
    "def backward(x, s, y, W):\n",
    "  longitud_secuencia = len(x[0])\n",
    "  s_t = s[:, -1]\n",
    "  gS = 2*(s_t -y)\n",
    "\n",
    "  gU, gW = 0,  0 # Inicializando gradientes\n",
    "\n",
    "  # Gradientes acumulados en el paso hacía atrás\n",
    "\n",
    "  for k in range(longitud_secuencia, 0, -1):\n",
    "    gU += np.sum(gS *x[:, k -1])\n",
    "    gW += np.sum(gS * s[:, k -1] )\n",
    "\n",
    "    gS = gS * W\n",
    "\n",
    "  return gU, gW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uXwhoZlnoejR"
   },
   "source": [
    "Ahora podemos intentar usar el descenso de gradientes para optimizar nuestra red. Calculamos `gradientes` (usando el error cuadrático medio) con la ayuda de la función `backward` y los usamos para actualizar el valor de los pesos: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1625710144604,
     "user": {
      "displayName": "CESAR JESUS LARA AVILA",
      "photoUrl": "",
      "userId": "01059333317062820707"
     },
     "user_tz": 300
    },
    "id": "auqz6ekzoLgM"
   },
   "outputs": [],
   "source": [
    "def entrenamiento(x, y, epocas, tasa_aprendizaje=0.0005):\n",
    "  pesos = (-2, 0) \n",
    "  \n",
    "  losses = list()\n",
    "  \n",
    "  gradientes_u = list()\n",
    "  \n",
    "  gradientes_w = list()\n",
    "\n",
    "  for i in range(epocas):\n",
    "    s = forward(x, pesos[0], pesos[1])\n",
    "\n",
    "    # Calcular la perdida\n",
    "\n",
    "    loss = (y[0] - s[-1, -1]) ** 2\n",
    "    \n",
    "    losses.append(loss)\n",
    "\n",
    "    gradientes = backward(x, s, y, pesos[1])\n",
    "    gradientes_u.append(gradientes[0])\n",
    "    gradientes_w.append(gradientes[1])\n",
    "\n",
    "     # Actualizar cada parametro p, p = p - (gradiente * tasa_aprendizaje)\n",
    "\n",
    "    pesos = tuple((p - gp * tasa_aprendizaje) for p, gp in zip(pesos, gradientes))\n",
    "\n",
    "  print(pesos)   \n",
    "\n",
    "  return np.array(losses), np.array(gradientes_u), np.array(gradientes_w)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sxY3CN7IwFpI"
   },
   "source": [
    "A continuación, implementaremos la función `plot_entrenamiento` relacionada, que muestra la función `loss` y los gradientes para cada peso durante las épocas: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 628,
     "status": "ok",
     "timestamp": 1625710145221,
     "user": {
      "displayName": "CESAR JESUS LARA AVILA",
      "photoUrl": "",
      "userId": "01059333317062820707"
     },
     "user_tz": 300
    },
    "id": "x1SRyihdwATk"
   },
   "outputs": [],
   "source": [
    "def plot_entrenamiento(losses, gradientes_u, gradientes_w):\n",
    "  import matplotlib.pyplot as plt\n",
    "\n",
    "  # remover los valores nan  y los valores inf\n",
    "  losses = losses[~np.isnan(losses)][:-1]\n",
    "  gradientes_u = gradientes_u[~np.isnan(gradientes_u)][:-1]\n",
    "  gradientes_w = gradientes_w[~np.isnan(gradientes_w)][:-1]\n",
    "\n",
    "   \n",
    "  # plot los pesos U y  W\n",
    "  fig, ax1 = plt.subplots(figsize=(10, 6.8))\n",
    "\n",
    "  ax1.set_ylim(-3, 600)\n",
    "  ax1.set_xlabel('epocas')\n",
    "  ax1.plot(gradientes_u, label='grad U', color='blue', linestyle=':')\n",
    "  ax1.plot(gradientes_w, label='grad W', color='red', linestyle='--')\n",
    "  ax1.legend(loc='upper left')\n",
    "\n",
    "  \n",
    "  ax2 = ax1.twinx() # \n",
    "\n",
    "#Descomentar para dibujar gradientes explosivos \n",
    "  ax2.set_ylim(-3, 200)\n",
    "  ax2.plot(losses, label='Perdida', color='green')\n",
    "  ax2.tick_params(axis='y', labelcolor='green') \n",
    "  ax2.legend(loc='upper right')\n",
    " \n",
    "  fig.tight_layout()\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CaGHGJjBxnhl"
   },
   "source": [
    "Finalmente, entrenemos a la red para que aprenda una sola secuencia binaria corta, donde $x$ es la secuencia e $y$ es la etiqueta: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1625710145222,
     "user": {
      "displayName": "CESAR JESUS LARA AVILA",
      "photoUrl": "",
      "userId": "01059333317062820707"
     },
     "user_tz": 300
    },
    "id": "_0Uc6vhBxkAD",
    "outputId": "4487b794-9721-4a52-fcc9-89032d6bef7b"
   },
   "outputs": [],
   "source": [
    "x = np.array([[0, 0, 0, 0, 1, 0, 1, 0, 1, 0]])\n",
    "y = np.array([3])\n",
    "\n",
    "losses, gradientes_u, gradientes_w = entrenamiento(x, y, epocas=150)\n",
    "plot_entrenamiento(losses, gradientes_u, gradientes_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95Qac2XiyYop"
   },
   "source": [
    "Podemos tropezar con gradientes explosivos en un NN de avance regular, pero es especialmente pronunciado en las RNN. Para entender por qué, recordemos la regla de la cadena de propagación del gradiente recurrente para los dos pasos de secuencia consecutivos que definimos anteriormente:\n",
    "\n",
    "$$\\frac{\\partial E}{\\partial s_{t -1}} = \\frac{\\partial E}{\\partial s_t}\\frac{\\partial s_t}{\\partial s_{t -1}} = \\frac{\\partial E}{\\partial s_t}W$$\n",
    "\n",
    "Dependiendo de la longitud de la secuencia, una RNN desplegada puede ser mucho más profundo en comparación con una red normal. Al mismo tiempo, los pesos, W, de un RNN se comparten en todos los pasos. Por lo tanto, podemos generalizar esta fórmula para calcular el gradiente entre dos pasos no consecutivos de la secuencia. Como W se comparte, la ecuación forma una progresión geométrica: \n",
    "\n",
    "\n",
    "$$\\frac{\\partial s_t}{\\partial s_{t -k}} = \\frac{\\partial s_t}{\\partial s_{t -1}}\\frac{\\partial s_{t-1}}{\\partial s_{t -2}} \\dots \\frac{\\partial s_{t-k +1}}{\\partial s_{t -k}} = \\prod_{j =1}^k\\frac{\\partial s_{t -j +1}}{\\partial s_{t -j}} = W^k$$\n",
    "\n",
    "Para demostrar el problema de los gradientes que desaparecen, entrenaremos la red usando una secuencia más larga: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "executionInfo": {
     "elapsed": 892,
     "status": "ok",
     "timestamp": 1625710146104,
     "user": {
      "displayName": "CESAR JESUS LARA AVILA",
      "photoUrl": "",
      "userId": "01059333317062820707"
     },
     "user_tz": 300
    },
    "id": "yXHxVcSqyd4l",
    "outputId": "25faa320-4837-4f97-f6b1-0609831560f2"
   },
   "outputs": [],
   "source": [
    "x = np.array([[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0]])\n",
    "y = np.array([12])\n",
    "\n",
    "losses, gradientes_u, gradientes_w = entrenamiento(x, y, epocas=150)\n",
    "plot_entrenamiento(losses, gradientes_u, gradientes_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicios\n",
    "\n",
    "1. Implementa el clipping de gradientes en una RNN simple desde cero. Usa el siguiente esqueleto de código para añadir la funcionalidad de clipping a la función backward.\n",
    "\n",
    "``` \n",
    "def backward(x, s, y, W, clip_value=1):\n",
    "    longitud_secuencia = len(x[0])\n",
    "    s_t = s[:, -1]\n",
    "    gS = 2 * (s_t - y)\n",
    "\n",
    "    gU, gW = 0, 0\n",
    "\n",
    "    for k in range(longitud_secuencia, 0, -1):\n",
    "        gU += np.sum(gS * x[:, k -1])\n",
    "        gW += np.sum(gS * s[:, k -1])\n",
    "        gS = gS * W\n",
    "\n",
    "    # Aplica clipping a los gradientes\n",
    "    gU = np.clip(gU, -clip_value, clip_value)\n",
    "    gW = np.clip(gW, -clip_value, clip_value)\n",
    "\n",
    "    return gU, gW\n",
    "\n",
    "\n",
    "```\n",
    "Ejecuta el entrenamiento con y sin clipping de gradientes para ver el efecto en la estabilidad y convergencia del entrenamiento. Puedes utilizar secuencias de entrada más largas para ver cómo maneja la RNN los gradientes potencialmente explosivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Explora cómo diferentes tasas de aprendizaje afectan el entrenamiento de una RNN. Modifica la tasa de aprendizaje en el script de entrenamiento y observa cómo cambia la convergencia y la aparición de NaNs. Prueba con tasas de aprendizaje muy pequeñas (e.g., 0.00001) y más grandes (e.g., 0.01)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Evalúa cómo el tamaño de la secuencia de entrada afecta el entrenamiento y la estabilidad de la RNN. Crea secuencias de diferentes longitudes y observa si hay una correlación entre la longitud de la secuencia y la aparición de problemas numéricos como NaNs o explosión de gradientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Amplía la función de visualización para incluir no solo los gradientes y la pérdida, sino también cómo cambian los pesos U y W con el tiempo durante el entrenamiento. Además, visualiza cómo la salida predicha por la RNN se compara con el valor objetivo y en cada época.\n",
    "\n",
    "```\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_extended(losses, gradientes_u, gradientes_w, pesos_u, pesos_w):\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "    # Plot de gradientes\n",
    "    axs[0, 0].plot(gradientes_u, label='Grad U', color='blue', linestyle=':')\n",
    "    axs[0, 0].plot(gradientes_w, label='Grad W', color='red', linestyle='--')\n",
    "    axs[0, 0].set_title('Gradientes durante el entrenamiento')\n",
    "    axs[0, 0].legend()\n",
    "\n",
    "    # Plot de pérdidas\n",
    "    axs[0, 1].plot(losses, label='Pérdida', color='green')\n",
    "    axs[0, 1].set_title('Pérdida durante el entrenamiento')\n",
    "    axs[0, 1].legend()\n",
    "\n",
    "    # Plot de pesos U\n",
    "    axs[1, 0].plot(pesos_u, label='Peso U', color='purple')\n",
    "    axs[1, 0].set_title('Pesos U durante el entrenamiento')\n",
    "    axs[1, 0].legend()\n",
    "\n",
    "    # Plot de pesos W\n",
    "    axs[1, 1].plot(pesos_w, label='Peso W', color='orange')\n",
    "    axs[1, 1].set_title('Pesos W durante el entrenamiento')\n",
    "    axs[1, 1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Experimenta añadiendo técnicas de regularización como L2 o Dropout a tu RNN. Observa si la adición de regularización ayuda a mejorar la generalización y a manejar mejor la explosión de gradientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5c_SchbFv5G"
   },
   "source": [
    "## LSTM y GRU\n",
    "\n",
    "En esta sección, implementaremos una celda LSTM con PyTorch. Primero, observemos que PyTorch ya tiene una implementación de LSTM, que está disponible en `torch.nn`. LSTM. Sin embargo, nuestro objetivo es comprender cómo funciona la celda LSTM, por lo que implementaremos la propia versión desde cero. La celda será una subclase de `torch.nn.Module` y la usaremos como bloque de construcción para modelos más grandes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1625710146108,
     "user": {
      "displayName": "CESAR JESUS LARA AVILA",
      "photoUrl": "",
      "userId": "01059333317062820707"
     },
     "user_tz": 300
    },
    "id": "nblQiEioyzOb"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import typing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZxxjXoFGz4v"
   },
   "source": [
    "A continuación, definiremos algunos parámetros de las redes y el proceso de entrenamiento: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1625710146110,
     "user": {
      "displayName": "CESAR JESUS LARA AVILA",
      "photoUrl": "",
      "userId": "01059333317062820707"
     },
     "user_tz": 300
    },
    "id": "ThalG2fQGs8C"
   },
   "outputs": [],
   "source": [
    "EPOCAS = 10 \n",
    "MUESTRAS_ENTRENAMIENTO = 10000  \n",
    "TAM_BATCH = 16  \n",
    "MUESTRAS_PRUEBAS = 1000  \n",
    "LONGITUD_SECUENCIA = 20 \n",
    "UNIDADES_OCULTAS = 20  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RpnTZN3JHdyA"
   },
   "source": [
    "A continuación, implementemos una celda LSTM básica como una subclase de `torch.nn.Module`. El proceso de implementación de la celda solo es un elemento de la secuencia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1625710146112,
     "user": {
      "displayName": "CESAR JESUS LARA AVILA",
      "photoUrl": "",
      "userId": "01059333317062820707"
     },
     "user_tz": 300
    },
    "id": "vdzAHo3qHKE6"
   },
   "outputs": [],
   "source": [
    "class celdaLSTM(torch.nn.Module):\n",
    "  def __init__(self, input_size: int, hidden_size: int):\n",
    "    super(celdaLSTM, self).__init__()\n",
    "    self.input_size = input_size\n",
    "    self.hidden_size = hidden_size\n",
    "\n",
    "  # Combinamos todas las puertas en una sola multiplicación de matriz \n",
    "    self.x_fc = torch.nn.Linear(input_size, 4 * hidden_size)\n",
    "    self.h_fc = torch.nn.Linear(hidden_size, 4 * hidden_size)\n",
    "\n",
    "    self.reset_parameters()\n",
    "\n",
    "  def reset_parameters(self):\n",
    "    \"\"\" Inicializacion de Xavier \"\"\"\n",
    "    size = math.sqrt(3.0/self.hidden_size)\n",
    "    for peso in self.parameters():\n",
    "      peso.data.uniform_(-size, size)\n",
    "\n",
    "  def forward(self,\n",
    "              x_t: torch.Tensor,\n",
    "              hidden: typing.Tuple[torch.Tensor, torch.Tensor] = (None, None)) \\\n",
    "           -> typing.Tuple[torch.Tensor, torch.Tensor]:\n",
    "    h_t_1, c_t_1 = hidden # t_1 es equivalente a t-1\n",
    "\n",
    "    # En caso de entrada de más de 2 dimensiones\n",
    "    # aplanar el tensor (similar a numpy.reshape) \n",
    "\n",
    "    x_t = x_t.view(-1, x_t.size(1))\n",
    "    h_t_1 = h_t_1.view(-1, h_t_1.size(1))\n",
    "    c_t_1 = c_t_1.view(-1, c_t_1.size(1))\n",
    "\n",
    "  #Calculamos las activaciones de todas las puertas simultáneamente \n",
    "    puertas = self.x_fc(x_t) + self.h_fc(h_t_1)\n",
    "\n",
    "  #Dividir la entrada a las 4 puertas separadas \n",
    "\n",
    "    i_t, f_t, candidato_c_t, o_t = puertas.chunk(4, 1)\n",
    "\n",
    "  # Calculamos las activaciones para todas las puertas \n",
    "    i_t, f_t, candidato_c_t, o_t = \\\n",
    "       i_t.sigmoid(), f_t.sigmoid(), candidato_c_t.tanh(), o_t.sigmoid()\n",
    "\n",
    "  # Escogemos un nuevo estado basado en las puertas de entrada y olvido \n",
    "    c_t = torch.mul(f_t, c_t_1) + torch.mul(i_t, candidato_c_t)\n",
    "  \n",
    "  # Calcular la salida de la celda\n",
    "\n",
    "    h_t = torch.mul(o_t, c_t.tanh())\n",
    "\n",
    "    return h_t, c_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M8M3NX5ETrVA"
   },
   "source": [
    "La implementación de celdaLSTM tiene dos limitaciones: \n",
    "\n",
    "- Solo cubre un paso de la secuencia.\n",
    "-  Genera el estado de la celda y el vector de salida de la red. Esta es una tarea de regresión y tenemos un solo valor de salida, pero el estado de la celda y la salida de la red tienen más dimensiones.\n",
    "\n",
    "Para resolver estos problemas, implementaremos una clase `modeloLSTM` personalizada, que amplía la celdaLSTM. Esta alimenta la instancia de la celdaLSTM con todos los elementos de la secuencia y maneja la transición del estado de la celda y la salida de la red de un elemento de la secuencia al siguiente. \n",
    "\n",
    "Una vez que se ha producido la salida final, se alimenta a una capa completamente conectada, que la transforma en un valor escalar único que representa la predicción de la red del número de unidades. \n",
    "\n",
    "El siguiente código hace esa implementación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1625710146113,
     "user": {
      "displayName": "CESAR JESUS LARA AVILA",
      "photoUrl": "",
      "userId": "01059333317062820707"
     },
     "user_tz": 300
    },
    "id": "33DiJAEAL64p"
   },
   "outputs": [],
   "source": [
    "class modeloLSTM(torch.nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, output_size):\n",
    "    super(modeloLSTM, self).__init__()\n",
    "    self.hidden_size = hidden_size\n",
    "\n",
    " # Implementacion de LSTM \n",
    "    self.lstm = celdaLSTM(input_size, hidden_size)\n",
    "\n",
    " # Capa de salida completamente conectada \n",
    "    self.fc = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "  def forward(self, x):\n",
    "    c_t = torch.zeros((x.size(0), self.hidden_size)).to(x.device)\n",
    "    h_t = torch.zeros((x.size(0), self.hidden_size)).to(x.device)\n",
    "\n",
    "  # Itera sobre todos los elementos de secuencia en todas las secuencias del mini-lote \n",
    "    for seq in range(x.size(1)):\n",
    "      h_t, c_t = self.lstm(x[:, seq, :], (h_t, c_t))\n",
    "\n",
    "  # Capa de salida final \n",
    "    return self.fc(h_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mIpgq_JgceYW"
   },
   "source": [
    "Seguiremos el mismo modelo para implementar celdaGRU y modeloGRU respectivamente. Comencemos con la implementación de celdaGRU: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1625710146114,
     "user": {
      "displayName": "CESAR JESUS LARA AVILA",
      "photoUrl": "",
      "userId": "01059333317062820707"
     },
     "user_tz": 300
    },
    "id": "d3hu15u6a4LC"
   },
   "outputs": [],
   "source": [
    "class celdaGRU(torch.nn.Module):\n",
    "  def __init__(self, input_size: int, hidden_size: int):\n",
    "    super(celdaGRU, self).__init__()\n",
    "    self.input_size = input_size\n",
    "    self.hidden_size = hidden_size\n",
    "\n",
    "    # x a la puerta reset r\n",
    "    self.x_r_fc = torch.nn.Linear(input_size, hidden_size)\n",
    "    # x a la puerta de actualizacion z \n",
    "    self.x_z_fc = torch.nn.Linear(input_size, hidden_size)\n",
    "\n",
    "    # x al estado candidato h'(t)\n",
    "    self.x_h_fc = torch.nn.Linear(input_size, hidden_size)\n",
    "\n",
    "    # salida de la red o el estado h(t -1) para reestablecer la puerta r\n",
    "    self.h_r_fc = torch.nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "    # salida de la red para actualizar la puerta z al estado de red h(t -1)\n",
    "    self.h_z_fc = torch.nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "    # salida de la red para actualizar la puerta z al estado h(t -1) a través de la puerta de reinicio r\n",
    "    self.hr_h_fc = torch.nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "  def forward(self,\n",
    "              x_t: torch.Tensor,\n",
    "              h_t_1: torch.Tensor= None)\\\n",
    "           -> torch.Tensor:\n",
    "           \n",
    "    z_t = torch.sigmoid(self.x_z_fc(x_t)+ self.h_z_fc(h_t_1)) # update gate\n",
    "           \n",
    "    r_t = torch.sigmoid(self.x_r_fc(x_t)+ self.h_r_fc(h_t_1)) # reset gate\n",
    "    candidato_h_t = torch.tanh(self.x_h_fc(x_t) + self.hr_h_fc(torch.mul(r_t, h_t_1)))# Estado candidato\n",
    "\n",
    "     # Celda de salida\n",
    "\n",
    "    h_t = torch.mul(z_t,h_t_1) + torch.mul(1 -z_t, candidato_h_t)\n",
    "\n",
    "    return h_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMmbqd1YhV_5"
   },
   "source": [
    "Continuaremos con la clase modeloGRU para procesar secuencias completas: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1625710146115,
     "user": {
      "displayName": "CESAR JESUS LARA AVILA",
      "photoUrl": "",
      "userId": "01059333317062820707"
     },
     "user_tz": 300
    },
    "id": "AdL7b1hFe9hh"
   },
   "outputs": [],
   "source": [
    "class modeloGRU(torch.nn.Module):\n",
    "\n",
    "  def __init__(self, input_size, hidden_size, output_size):\n",
    "    super(modeloGRU, self).__init__()\n",
    "    self.hidden_size = hidden_size\n",
    "\n",
    "    self.gru = celdaGRU(input_size, hidden_size)\n",
    "\n",
    "    self.fc = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "  def forward(self, x):\n",
    "    h_t = torch.zeros((x.size(0), self.hidden_size)).to(x.device)\n",
    "\n",
    "    for seq in range(x.size(1)):\n",
    "      h_t = self.gru(x[:, seq, :], h_t)\n",
    "\n",
    "   # Capa de salida final\n",
    "   \n",
    "    return self.fc(h_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2aPSwCQEhjTA"
   },
   "source": [
    "A continuación, implementaremos la función `genera_dataset`, que genera un total de muestras de secuencias binarias, cada una con una longitud de `longitud_secuencia`. La función devuelve la secuencia y su etiqueta numérica, que indica el número de unos en esa secuencia: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1625710146115,
     "user": {
      "displayName": "CESAR JESUS LARA AVILA",
      "photoUrl": "",
      "userId": "01059333317062820707"
     },
     "user_tz": 300
    },
    "id": "vAti9jCjhdfE"
   },
   "outputs": [],
   "source": [
    "def genera_dataset(longitud_secuencia: int, muestras: int):\n",
    "  secuencias = list()\n",
    "  etiquetas = list()\n",
    "  for i in range(muestras):\n",
    "    a = np.random.randint(longitud_secuencia)/longitud_secuencia\n",
    "    secuencia = list(np.random.choice(2, longitud_secuencia, p=[a, 1 - a]))\n",
    "    secuencias.append(secuencia)\n",
    "    etiquetas.append(int(np.sum(secuencia)))\n",
    "\n",
    "  secuencias = np.array(secuencias)\n",
    "  etiquetas = np.array(etiquetas, dtype=np.int8)\n",
    "\n",
    "  resultado = torch.utils.data.TensorDataset(\n",
    "      torch.from_numpy(secuencias).float().unsqueeze(-1),\n",
    "      torch.from_numpy(etiquetas).float())\n",
    "\n",
    "  return resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sH2jrTo0K3Cp"
   },
   "source": [
    "Continuaremos con la implementación del procedimiento de entrenamiento para modeloLSTM o modeloGRU. Este procedimiento es genérico y no difiere de procedimientos similares para redes MLP. La parte de recurrencia es manejada por la funcionalidad `autodiff` de PyTorch dentro de modeloLSTM y de y modeloGRU: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1625710146116,
     "user": {
      "displayName": "CESAR JESUS LARA AVILA",
      "photoUrl": "",
      "userId": "01059333317062820707"
     },
     "user_tz": 300
    },
    "id": "Kbz9ESoAjgpz"
   },
   "outputs": [],
   "source": [
    "def modelo_entrenamiento(modelo, loss_function, optimizer, data_loader):\n",
    "  modelo.train()\n",
    "  \n",
    "  loss_actual = 0.0\n",
    "  acc_actual = 0\n",
    "\n",
    "# iteramos sobre la data de entrenamiento \n",
    "  for i, (entradas, etiquetas) in enumerate(data_loader):\n",
    "    entradas = entradas.to(device)\n",
    "    etiquetas = etiquetas.to(device)\n",
    "\n",
    "# Cero a los parametros gradientes\n",
    "    modelo.zero_grad()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "# Forward\n",
    "    with torch.set_grad_enabled(True):\n",
    "      salidas = modelo(entradas).squeeze()\n",
    "      loss = loss_function(salidas, etiquetas)\n",
    "\n",
    "# Backward\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "# Estadisticas\n",
    "    loss_actual += loss.item() * entradas.size(0)\n",
    "    acc_actual += torch.sum(salidas.round() == etiquetas.data)\n",
    "\n",
    "  loss_total = loss_actual/len(data_loader.dataset)\n",
    "  acc_total = acc_actual.double()/len(data_loader.dataset)\n",
    "\n",
    "  print('Perdida de entrenamiento: {:.4f}; Exactitud: {:.4f}'.format(loss_total, acc_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g3vAXnNPPIe2"
   },
   "source": [
    "Luego, implementaremos el procedimiento de prueba. Al igual que con el entrenamiento, este es un procedimiento genérico que es similar al de las redes MLP, ya que el procesamiento de la secuencia es manejado internamente por modeloLSTM y modeloGRU: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 527,
     "status": "ok",
     "timestamp": 1625710146619,
     "user": {
      "displayName": "CESAR JESUS LARA AVILA",
      "photoUrl": "",
      "userId": "01059333317062820707"
     },
     "user_tz": 300
    },
    "id": "Ly3Z_eZhOQve"
   },
   "outputs": [],
   "source": [
    "def modelo_prueba(modelo, loss_function, data_loader):\n",
    "  modelo.eval()\n",
    "\n",
    "  loss_actual = 0.0\n",
    "  acc_actual = 0\n",
    "\n",
    "# iteramos sobre la data de entrenamiento \n",
    "  for i, (entradas, etiquetas) in enumerate(data_loader):\n",
    "    entradas = entradas.to(device)\n",
    "    etiquetas = etiquetas.to(device)\n",
    "\n",
    "# Forward\n",
    "    with torch.set_grad_enabled(False):\n",
    "      salidas = modelo(entradas).squeeze()\n",
    "      loss = loss_function(salidas, etiquetas)\n",
    "\n",
    "# Estadisticas\n",
    "    loss_actual += loss.item() * entradas.size(0)\n",
    "    acc_actual += torch.sum(salidas.round() == etiquetas.data)\n",
    "\n",
    "  loss_total = loss_actual/len(data_loader.dataset)\n",
    "  acc_total = acc_actual.double()/len(data_loader.dataset)\n",
    "\n",
    "  print('Perdida de prueba: {:.4f}; Exactitud: {:.4f}'.format(loss_total, acc_total))\n",
    "\n",
    "  return loss_total, acc_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mIbHVmHiURGH"
   },
   "source": [
    "Ahora podemos ponerlo todo junto. Comenzaremos instalando el dispositivo, `train_loader` y `test_loader`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 645,
     "status": "ok",
     "timestamp": 1625710147255,
     "user": {
      "displayName": "CESAR JESUS LARA AVILA",
      "photoUrl": "",
      "userId": "01059333317062820707"
     },
     "user_tz": 300
    },
    "id": "WnSVhJAPQ3uC"
   },
   "outputs": [],
   "source": [
    "# Dispositivo seleccionado\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Genere conjuntos de datos de entrenamiento y prueba \n",
    "train = genera_dataset(LONGITUD_SECUENCIA, MUESTRAS_ENTRENAMIENTO)\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=TAM_BATCH, shuffle=True)\n",
    "\n",
    "test = genera_dataset(LONGITUD_SECUENCIA, MUESTRAS_ENTRENAMIENTO)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=TAM_BATCH, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qACmFSwvVSbC"
   },
   "source": [
    "A continuación, creemos una instancia de un modelo LSTM con algunos parámetros:\n",
    "\n",
    "- Entrada de tamaño 1 para el dígito de la secuencia\n",
    "- Número de unidades ocultas\n",
    "- Tamaño de salida del modelo de regresión (número de unidades) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1625710147258,
     "user": {
      "displayName": "CESAR JESUS LARA AVILA",
      "photoUrl": "",
      "userId": "01059333317062820707"
     },
     "user_tz": 300
    },
    "id": "btgPFKdJU4t-"
   },
   "outputs": [],
   "source": [
    "modelo = modeloLSTM(input_size=1, hidden_size=UNIDADES_OCULTAS,\n",
    "                  output_size=1)\n",
    "\n",
    "#Transferimos el modelo a la  GPU\n",
    "modelo = modelo.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4cTG59VoXl12"
   },
   "source": [
    "A continuación, crearemos una instancia de los componentes del entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1625710147261,
     "user": {
      "displayName": "CESAR JESUS LARA AVILA",
      "photoUrl": "",
      "userId": "01059333317062820707"
     },
     "user_tz": 300
    },
    "id": "JmR41kFzXGi2"
   },
   "outputs": [],
   "source": [
    "loss_function = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(modelo.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GVBLzmbrYLVT"
   },
   "source": [
    "Ejecutaremos el entrenamiento: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42882,
     "status": "ok",
     "timestamp": 1625710190127,
     "user": {
      "displayName": "CESAR JESUS LARA AVILA",
      "photoUrl": "",
      "userId": "01059333317062820707"
     },
     "user_tz": 300
    },
    "id": "eX5QAclFX5kS",
    "outputId": "97d38870-e954-45ab-dbe3-f91a3bc15a6c"
   },
   "outputs": [],
   "source": [
    "for epoca in range(EPOCAS):\n",
    "  print(\"Epocas{}/{}\".format(epoca +1, EPOCAS))\n",
    "\n",
    "  modelo_entrenamiento(modelo, loss_function, optimizer, train_loader)\n",
    "  modelo_prueba(modelo, loss_function, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpTsSa3DYrtf"
   },
   "source": [
    "**Ejercicio**: Realiza el mismo experimento con `modeloGRU`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 64461,
     "status": "ok",
     "timestamp": 1625710254569,
     "user": {
      "displayName": "CESAR JESUS LARA AVILA",
      "photoUrl": "",
      "userId": "01059333317062820707"
     },
     "user_tz": 300
    },
    "id": "5Nh_QiI8YeiM",
    "outputId": "34a760c0-dc7f-41f2-f32d-01da4efc913b"
   },
   "outputs": [],
   "source": [
    "modelo = modeloGRU(input_size=1, hidden_size=UNIDADES_OCULTAS,\n",
    "                  output_size=1)\n",
    "\n",
    "modelo = modelo.to(device)\n",
    "\n",
    "loss_function = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(modelo.parameters())\n",
    "for epoca in range(EPOCAS):\n",
    "  print(\"Epocas{}/{}\".format(epoca +1, EPOCAS))\n",
    "\n",
    "  modelo_entrenamiento(modelo, loss_function, optimizer, train_loader)\n",
    "  modelo_prueba(modelo, loss_function, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicios\n",
    "\n",
    "1.  Modifica las clases celdaLSTM y celdaGRU para incluir dropout. PyTorch ofrece torch.nn.Dropout, que puedes añadir a las salidas de las capas antes de pasarlas a la siguiente capa o a la salida final. Experimenta con diferentes tasas de dropout para ver cómo afectan el rendimiento del modelo en el entrenamiento y la validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1625710254571,
     "user": {
      "displayName": "CESAR JESUS LARA AVILA",
      "photoUrl": "",
      "userId": "01059333317062820707"
     },
     "user_tz": 300
    },
    "id": "u5ZBuey3ZKEK"
   },
   "outputs": [],
   "source": [
    "# Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Usa la función genera_dataset para crear datasets con diferentes longitudes de secuencia, por ejemplo, 10, 20, 50 y 100.  Entrena tu modelo LSTM o GRU con estos datasets y compara su rendimiento. Observa si modelos con más unidades ocultas manejan mejor secuencias más largas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Modifica la función reset_parameters en las clases de celda para experimentar con diferentes métodos de inicialización, como la inicialización ortogonal (torch.nn.init.orthogonal_) o la inicialización normal (torch.nn.init.normal_).  Evalúa cómo cada método afecta la rapidez de convergencia y la estabilidad durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Modifica las clases celdaLSTM y celdaGRU para registrar los valores de las puertas (i.e., puertas de entrada, olvido, salida en LSTM; puertas de actualización y reinicio en GRU) durante el entrenamiento. Visualiza estos valores para diferentes tipos de entradas y observa cómo las puertas reaccionan a cambios en los datos de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Utiliza un enfoque sistemático para ajustar hiperparámetros como la tasa de aprendizaje, el tamaño del batch, y el número de unidades ocultas. Herramientas como torch.optim.lr_scheduler pueden ser útiles aquí Implementa y utiliza una búsqueda grid o búsqueda aleatoria para encontrar los mejores hiperparámetros para tu modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.Elige una tarea específica de modelado, como la predicción de series temporales o el análisis de sentimiento. Implementa y compara los modelos LSTM y GRU en esta tarea. Analiza cuál modelo es más eficiente en términos de tiempo de entrenamiento y recursos, y cuál proporciona mejores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu respuesta"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMjSpBGvPIbHPe2xXMKBdD3",
   "collapsed_sections": [],
   "name": "Actividades-RNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

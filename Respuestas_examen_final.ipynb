{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46581f61-76d7-4122-a947-d1e8b24bf1de",
   "metadata": {},
   "source": [
    "## **Respuestas del examen final**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f605bfdc-2b27-4179-a3fe-2790be786f66",
   "metadata": {},
   "source": [
    "### **Pregunta 1**\n",
    "\n",
    "#### Generación de datos sintéticos\n",
    "\n",
    "##### **Diseño del conjunto de datos**\n",
    "\n",
    "Queremos crear un conjunto de datos en $\\mathbb{R}^2$ (bidimensional) en el que dos clases se solapen parcialmente. Una forma sencilla es utilizar distribuciones gaussianas (normales) para cada clase. Por ejemplo:\n",
    "\n",
    "- **Clase 0:**  \n",
    "  $$\n",
    "  \\mathbf{x} \\sim \\mathcal{N}(\\boldsymbol{\\mu}_0, \\Sigma), \\quad \\boldsymbol{\\mu}_0 = \\begin{pmatrix}0 \\\\ 0\\end{pmatrix}\n",
    "  $$\n",
    "- **Clase 1:**  \n",
    "  $$\n",
    "  \\mathbf{x} \\sim \\mathcal{N}(\\boldsymbol{\\mu}_1, \\Sigma), \\quad \\boldsymbol{\\mu}_1 = \\begin{pmatrix}1 \\\\ 1\\end{pmatrix}\n",
    "  $$\n",
    "\n",
    "Usamos la misma matriz de covarianza para ambas clases, por ejemplo:\n",
    "$$\n",
    "\\Sigma = \\begin{pmatrix}1 & 0 \\\\ 0 & 1\\end{pmatrix}.\n",
    "$$\n",
    "Dado que la distancia entre las medias es del mismo orden que la desviación estándar, se garantiza un solapamiento parcial.\n",
    "\n",
    "##### **Pseudocódigo para la generación de datos**\n",
    "\n",
    "```plaintext\n",
    "# Número de ejemplos por clase\n",
    "N0 = 100\n",
    "N1 = 100\n",
    "\n",
    "# Parámetros de la distribución\n",
    "mu0 = [0, 0]\n",
    "mu1 = [1, 1]\n",
    "Sigma = [[1, 0], [0, 1]]  # Matriz identidad\n",
    "\n",
    "# Inicializar listas vacías para los datos y etiquetas\n",
    "datos = []\n",
    "etiquetas = []\n",
    "\n",
    "# Generar ejemplos para la clase 0\n",
    "para i de 1 hasta N0:\n",
    "    x = muestra_aleatoria_normal(mu0, Sigma)\n",
    "    datos.agregar(x)\n",
    "    etiquetas.agregar(0)\n",
    "\n",
    "# Generar ejemplos para la clase 1\n",
    "para i de 1 hasta N1:\n",
    "    x = muestra_aleatoria_normal(mu1, Sigma)\n",
    "    datos.agregar(x)\n",
    "    etiquetas.agregar(1)\n",
    "```\n",
    "\n",
    "*Nota:* La función `muestra_aleatoria_normal(mu, Sigma)` representa una muestra de una distribución normal multivariada con media $ \\mu $ y covarianza $ \\Sigma $. Esta es la idea general sin utilizar librerías externas.\n",
    "\n",
    "\n",
    "#### Modelo de regresión logística con regularización mixta (Elastic Net)\n",
    "\n",
    "El modelo de regresión logística predice la probabilidad $ p $ de pertenecer a la clase 1 mediante:\n",
    "$$\n",
    "p = \\sigma(z) = \\frac{1}{1 + e^{-z}} \\quad \\text{con} \\quad z = \\mathbf{w}^\\top \\mathbf{x} + b.\n",
    "$$\n",
    "\n",
    "##### **Función de costo con Elastic Net**\n",
    "\n",
    "La función de costo a minimizar es la suma del error de log-verosimilitud (log-loss) y el término de regularización elástico, que combina L1 y L2:\n",
    "$$\n",
    "J(\\mathbf{w}, b) = \\frac{1}{N} \\sum_{i=1}^{N} \\left[- y_i \\log \\sigma(z_i) - (1 - y_i) \\log \\bigl(1 - \\sigma(z_i)\\bigr)\\right] + \\alpha \\|\\mathbf{w}\\|_1 + \\frac{1-\\alpha}{2}\\|\\mathbf{w}\\|_2^2,\n",
    "$$\n",
    "donde:\n",
    "- $ \\|\\mathbf{w}\\|_1 = \\sum_j |w_j| $\n",
    "- $ \\|\\mathbf{w}\\|_2^2 = \\sum_j w_j^2 $\n",
    "- $ \\alpha \\in [0,1] $ controla la contribución de cada penalización.\n",
    "\n",
    "El primer término mide la discrepancia entre las predicciones y las etiquetas, mientras que el segundo y tercer término evitan el sobreajuste forzando algunas componentes a cero (L1) y limitando el tamaño global de los pesos (L2).\n",
    "\n",
    "\n",
    "##### **Introduciendo no linealidad para romper la convexidad**\n",
    "\n",
    "Si únicamente usamos una transformación fija de las features (por ejemplo, añadir $x_1^2$, $x_2^2$ y $x_1 x_2$) la regresión logística sigue siendo un modelo lineal en los parámetros y, por tanto, el problema de optimización es convexo.\n",
    "\n",
    "Para que la función de costo deje de ser convexa, se debe introducir una transformación no lineal *parametrizada*, por ejemplo, utilizando una pequeña red neuronal con una capa oculta. Una opción es la siguiente:\n",
    "\n",
    "#### Modelo no lineal (red neuronal pequeña)\n",
    "\n",
    "1. **Capa oculta:**  \n",
    "   Se calcula un vector de activación:\n",
    "   $$\n",
    "   \\mathbf{h} = \\tanh(W \\mathbf{x} + \\mathbf{c}),\n",
    "   $$\n",
    "   donde:\n",
    "   - $ W $ es la matriz de pesos de la capa oculta.\n",
    "   - $ \\mathbf{c} $ es el vector de sesgos.\n",
    "   - La función $\\tanh(\\cdot)$ introduce la no linealidad.\n",
    "\n",
    "2. **Capa de salida (logística):**  \n",
    "   La salida se calcula como:\n",
    "   $$\n",
    "   z = \\mathbf{v}^\\top \\mathbf{h} + b, \\quad \\hat{y} = \\sigma(z) = \\frac{1}{1+e^{-z}},\n",
    "   $$\n",
    "   donde:\n",
    "   - $ \\mathbf{v} $ y $ b $ son los parámetros de la capa de salida.\n",
    "\n",
    "3. **Función de costo con regularización mixta:**\n",
    "   $$\n",
    "   J(W, \\mathbf{c}, \\mathbf{v}, b) = \\frac{1}{N}\\sum_{i=1}^{N} \\left[- y_i \\log(\\hat{y}_i) - (1-y_i) \\log(1-\\hat{y}_i)\\right] + \\alpha \\left(\\|W\\|_1 + \\|\\mathbf{v}\\|_1\\right) + \\frac{1-\\alpha}{2}\\left(\\|W\\|_2^2 + \\|\\mathbf{v}\\|_2^2\\right).\n",
    "   $$\n",
    "\n",
    "En este modelo, la función $\\tanh$ y la forma en que $W$ y $\\mathbf{v}$ intervienen hacen que el costo sea **no convexo** respecto a los parámetros. Es decir, la composición de la función de activación no lineal con la función de costo (incluso si el término de regularización por sí solo es convexo) produce un paisaje de error con múltiples mínimos locales y mesetas.\n",
    "\n",
    "##### **Análisis teórico de la no convexidad**\n",
    "\n",
    "\n",
    "- **Regresión logística lineal (con transformación fija):**  \n",
    "  La función de costo es convexa respecto a los parámetros $ \\mathbf{w} $ y $ b $ cuando el modelo es lineal en las features. Incluso al agregar regularización L1 y L2, el problema sigue siendo convexo, pues ambos términos de regularización son funciones convexas.\n",
    "\n",
    "- **Incorporación de transformaciones parametrizadas no lineales:**  \n",
    "  Cuando introducimos una capa oculta con una función de activación no lineal (como $\\tanh$), la salida depende de los parámetros de $W$ y $\\mathbf{c}$ de forma no lineal. Así, la composición de la función de pérdida con estas transformaciones produce un problema de optimización **no convexo**.  \n",
    "  Además:\n",
    "  - El término L1 introduce puntos de no diferenciabilidad (por ejemplo, en $w_j = 0$), lo que añade “esquinas” en el paisaje del costo.\n",
    "  - La combinación de L1 y L2 (Elastic Net) crea una penalización mixta que, aun siendo convexa cuando se aplica a un modelo lineal, se integra en un sistema no lineal con múltiples interacciones entre parámetros.\n",
    "  - La interacción entre la no linealidad del modelo (que puede tener múltiples mínimos locales y puntos silla) y la discontinuidad en la derivada del término L1 genera una función de costo complicada, en la cual los algoritmos de optimización (como gradiente descendente) pueden quedar atrapados o tener dificultades para encontrar el óptimo global.\n",
    "\n",
    "#### Curvas de entrenamiento y dificultad en la optimización\n",
    "\n",
    "##### **Comportamiento observado en la práctica**\n",
    "\n",
    "Al entrenar el modelo (por ejemplo, la red neuronal pequeña con regularización Elastic Net) se pueden observar curvas de error vs. época con las siguientes características:\n",
    "\n",
    "- **Disminución irregular del error:**  \n",
    "  Debido a la presencia de múltiples mínimos locales y puntos de inflexión en la función de costo, la curva de error puede presentar \"saltos\" o mesetas. Esto significa que el error no decrece de forma suave y monotónica, sino que puede estancarse o incluso aumentar temporalmente antes de seguir decreciendo.\n",
    "\n",
    "- **Sensibilidad a la tasa de aprendizaje:**  \n",
    "  La combinación de L1 y L2 hace que el paisaje de la función de costo tenga zonas planas (debido al efecto \"de empuje\" de L1 para poner a cero ciertos parámetros) junto con regiones de fuerte curvatura (por L2). Esto exige una tasa de aprendizaje muy cuidadosamente ajustada para evitar que el algoritmo oscile o se atasque.\n",
    "\n",
    "- **Dificultades en la convergencia:**  \n",
    "  Los \"picos\" y \"valles\" en la función de costo pueden llevar a que el algoritmo se quede en óptimos locales que no son los globales, complicando el proceso de convergencia.\n",
    "\n",
    "### Ejemplo esquemático de una curva de error\n",
    "\n",
    "Imagina la siguiente descripción gráfica (se recomienda generar un gráfico real en una implementación práctica):\n",
    "\n",
    "```\n",
    "Error\n",
    "  │          *        *\n",
    "  │         * *      * *\n",
    "  │        *   *    *   *\n",
    "  │       *     *  *     *\n",
    "  │-----*-------**-------*-----→ Épocas\n",
    "```\n",
    "\n",
    "En este esquema se observa que, en lugar de un descenso suave, el error disminuye de forma irregular, lo que es característico en escenarios no convexos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9223d4cf-c790-4d2a-bc53-62a6e4c676d8",
   "metadata": {},
   "source": [
    "#### **Implementaciones**\n",
    "\n",
    "##### **1. Generación de datos sintéticos**\n",
    "\n",
    "Utilizaremos dos distribuciones normales multivariadas en 2D para generar dos clases con cierto solapamiento. En este ejemplo:\n",
    "\n",
    "- **Clase 0:**  \n",
    "  $ \\mathbf{x} \\sim \\mathcal{N}(\\boldsymbol{\\mu}_0, \\Sigma) $  \n",
    "  con $ \\boldsymbol{\\mu}_0 = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} $\n",
    "  \n",
    "- **Clase 1:**  \n",
    "  $ \\mathbf{x} \\sim \\mathcal{N}(\\boldsymbol{\\mu}_1, \\Sigma) $  \n",
    "  con $ \\boldsymbol{\\mu}_1 = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} $\n",
    "\n",
    "Se utiliza la matriz de covarianza $ \\Sigma = \\begin{pmatrix}1 & 0 \\\\ 0 & 1\\end{pmatrix} $.\n",
    "\n",
    "El siguiente código genera 100 muestras por clase:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe1c9b8-c15a-46c0-9aec-8145b6ca2294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_data(N0, N1):\n",
    "    # Parámetros para la distribución de cada clase\n",
    "    mu0 = np.array([0, 0])\n",
    "    mu1 = np.array([1, 1])\n",
    "    Sigma = np.array([[1, 0], [0, 1]])\n",
    "    \n",
    "    # Generar datos usando una distribución normal multivariada\n",
    "    X0 = np.random.multivariate_normal(mu0, Sigma, N0)\n",
    "    X1 = np.random.multivariate_normal(mu1, Sigma, N1)\n",
    "    \n",
    "    # Combinar datos y etiquetas\n",
    "    X = np.vstack([X0, X1])\n",
    "    y = np.hstack([np.zeros(N0), np.ones(N1)])\n",
    "    return X, y\n",
    "\n",
    "# Generamos los datos sintéticos\n",
    "np.random.seed(42)\n",
    "N0, N1 = 100, 100\n",
    "X, y = generate_data(N0, N1)\n",
    "\n",
    "# Visualizamos el conjunto de datos\n",
    "plt.scatter(X[:N0,0], X[:N0,1], label=\"Clase 0\", alpha=0.6)\n",
    "plt.scatter(X[N0:,0], X[N0:,1], label=\"Clase 1\", alpha=0.6)\n",
    "plt.legend()\n",
    "plt.title(\"Datos sintéticos 2D con solapamiento parcial\")\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8a8f7b-e482-4f07-9aef-6dbed5d6bf91",
   "metadata": {},
   "source": [
    "#### Modelo de regresión logística con regularización mixta (Elastic Net)\n",
    "\n",
    "Recordemos que en un modelo de regresión logística se calcula:\n",
    "\n",
    "$$\n",
    "p = \\sigma(z) = \\frac{1}{1+e^{-z}}, \\quad \\text{donde } z = \\mathbf{w}^\\top \\mathbf{x} + b.\n",
    "$$\n",
    "\n",
    "La función de costo con regularización mixta es\n",
    "\n",
    "$$\n",
    "J(\\mathbf{w}, b) = \\frac{1}{N} \\sum_{i=1}^{N} \\Bigl[- y_i \\log \\sigma(z_i) - (1 - y_i) \\log (1-\\sigma(z_i))\\Bigr] + \\alpha \\|\\mathbf{w}\\|_1 + \\frac{1-\\alpha}{2}\\|\\mathbf{w}\\|_2^2.\n",
    "$$\n",
    "\n",
    "En el código que sigue se implementa un modelo extendido a una **pequeña red neuronal** con una capa oculta (usando $\\tanh$) para introducir una transformación no lineal parametrizada. De esta forma, la composición de la función de activación con la función de costo hace que ésta sea **no convexa** respecto a los parámetros.\n",
    "\n",
    "\n",
    "Se implementa una red con:\n",
    "- **Capa oculta:**  \n",
    "  $\\mathbf{h} = \\tanh(W\\mathbf{x} + \\mathbf{c})$\n",
    "- **Capa de salida:**  \n",
    "  $z = \\mathbf{v}^\\top \\mathbf{h} + b$ y  \n",
    "  $\\hat{y} = \\sigma(z)$\n",
    "\n",
    "La función de costo es la log-loss más el término de regularización elastic net aplicado a $W$ y $\\mathbf{v}$. Se entrena mediante gradiente descendente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13fd827-cf3c-4403-8c35-75ae03bc960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_derivative(x):\n",
    "    # Derivada de tanh es 1 - tanh(x)^2\n",
    "    return 1 - np.tanh(x)**2\n",
    "\n",
    "def train_nn(X, y, params, alpha_reg=0.5, lr=0.01, epochs=200):\n",
    "    \"\"\"\n",
    "    Entrena una red neuronal pequeña con una capa oculta y regularización Elastic Net.\n",
    "    params: diccionario con parámetros 'W', 'c', 'v' y 'b'\n",
    "    alpha_reg: peso del término L1 (L1) en la regularización; (1-alpha_reg) para L2.\n",
    "    \"\"\"\n",
    "    N = X.shape[0]\n",
    "    loss_history = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Inicializar gradientes acumulados\n",
    "        grad_W = np.zeros_like(params['W'])\n",
    "        grad_c = np.zeros_like(params['c'])\n",
    "        grad_v = np.zeros_like(params['v'])\n",
    "        grad_b = 0.0\n",
    "        loss_epoch = 0\n",
    "        \n",
    "        # Procesamiento de cada muestra (modo \"batch\" completo)\n",
    "        for i in range(N):\n",
    "            x = X[i]   # Entrada (dimensión d)\n",
    "            yi = y[i]\n",
    "            \n",
    "            # Forward pass\n",
    "            z_hidden = np.dot(params['W'], x) + params['c']  # (H,)\n",
    "            h = tanh(z_hidden)  # Activación de la capa oculta (H,)\n",
    "            z_out = np.dot(params['v'], h) + params['b']       # Escalar\n",
    "            pred = sigmoid(z_out)\n",
    "            \n",
    "            # Cálculo del loss (log-loss)\n",
    "            loss_sample = - (yi * np.log(pred+1e-8) + (1-yi)*np.log(1-pred+1e-8))\n",
    "            loss_epoch += loss_sample\n",
    "            \n",
    "            # Backward pass\n",
    "            # Derivada de la pérdida respecto de z_out\n",
    "            dL_dz_out = pred - yi   # Escalar\n",
    "            \n",
    "            # Gradientes para la capa de salida\n",
    "            grad_v += dL_dz_out * h          # (H,)\n",
    "            grad_b += dL_dz_out              # Escalar\n",
    "            \n",
    "            # Gradientes para la capa oculta\n",
    "            dL_dh = dL_dz_out * params['v']   # (H,)\n",
    "            dL_dz_hidden = dL_dh * tanh_derivative(z_hidden)  # (H,)\n",
    "            \n",
    "            # Gradientes para W y c\n",
    "            grad_W += np.outer(dL_dz_hidden, x)  # (H, d)\n",
    "            grad_c += dL_dz_hidden               # (H,)\n",
    "        \n",
    "        # Promediar gradientes sobre todas las muestras\n",
    "        grad_W /= N\n",
    "        grad_c /= N\n",
    "        grad_v /= N\n",
    "        grad_b /= N\n",
    "        \n",
    "        # Agregar gradientes de la regularización Elastic Net\n",
    "        # Término L2: derivada es (1-alpha_reg)*parametro\n",
    "        grad_W += (1-alpha_reg) * params['W']\n",
    "        grad_v += (1-alpha_reg) * params['v']\n",
    "        # Término L1: subgradiente es alpha_reg * sign(parametro)\n",
    "        grad_W += alpha_reg * np.sign(params['W'])\n",
    "        grad_v += alpha_reg * np.sign(params['v'])\n",
    "        \n",
    "        # Actualización de parámetros con tasa de aprendizaje lr\n",
    "        params['W'] -= lr * grad_W\n",
    "        params['c'] -= lr * grad_c\n",
    "        params['v'] -= lr * grad_v\n",
    "        params['b'] -= lr * grad_b\n",
    "        \n",
    "        # Calcular el loss promedio para la época y agregar la regularización\n",
    "        loss_epoch /= N\n",
    "        L1_term = alpha_reg * (np.sum(np.abs(params['W'])) + np.sum(np.abs(params['v'])))\n",
    "        L2_term = (1-alpha_reg)/2 * (np.sum(params['W']**2) + np.sum(params['v']**2))\n",
    "        total_loss = loss_epoch + L1_term + L2_term\n",
    "        loss_history.append(total_loss)\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoca {epoch}, Loss: {total_loss}\")\n",
    "    \n",
    "    return params, loss_history\n",
    "\n",
    "# Inicialización de parámetros de la red neuronal\n",
    "d = 2    # Dimensión de la entrada\n",
    "H = 5    # Número de neuronas en la capa oculta\n",
    "\n",
    "params = {\n",
    "    'W': np.random.randn(H, d) * 0.1,  # Pesos de la capa oculta\n",
    "    'c': np.zeros(H),                  # Sesgos de la capa oculta\n",
    "    'v': np.random.randn(H) * 0.1,       # Pesos de la capa de salida\n",
    "    'b': 0.0                           # Sesgo de la capa de salida\n",
    "}\n",
    "\n",
    "# Entrenamiento de la red neuronal con regularización Elastic Net\n",
    "alpha_reg = 0.5  # Parámetro que mezcla L1 y L2\n",
    "lr = 0.01        # Tasa de aprendizaje\n",
    "epochs = 200\n",
    "\n",
    "params, loss_history = train_nn(X, y, params, alpha_reg, lr, epochs)\n",
    "\n",
    "# Visualización de la curva de error (loss vs. época)\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Curva de entrenamiento: Loss vs Épocas\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949ad6c6-df10-4c42-8c8a-a1f9364e3671",
   "metadata": {},
   "source": [
    "### **Pregunta 2**\n",
    "\n",
    "####  Definición de la función de activación personalizada\n",
    "\n",
    "Definimos la función de activación:\n",
    "$$\n",
    "\\phi(z) = z \\, \\sigma(z) + \\beta \\cdot \\sin(z)\n",
    "$$\n",
    "donde  \n",
    "- $\\sigma(z) = \\frac{1}{1+e^{-z}}$ es la función sigmoide,  \n",
    "- $\\beta$ es un parámetro entrenable adicional.\n",
    "\n",
    "##### **Derivadas**\n",
    "\n",
    "**Derivada de $\\phi(z)$ respecto a $z$:**\n",
    "\n",
    "1. Para el término $z\\,\\sigma(z)$:  \n",
    "   Utilizando la regla del producto:\n",
    "   $$\n",
    "   \\frac{d}{dz}[z\\,\\sigma(z)] = \\sigma(z) + z\\,\\sigma'(z)\n",
    "   $$\n",
    "   y recordando que\n",
    "   $$\n",
    "   \\sigma'(z) = \\sigma(z)\\bigl(1-\\sigma(z)\\bigr),\n",
    "   $$\n",
    "   obtenemos:\n",
    "   $$\n",
    "   \\frac{d}{dz}[z\\,\\sigma(z)] = \\sigma(z) + z\\,\\sigma(z)\\bigl(1-\\sigma(z)\\bigr).\n",
    "   $$\n",
    "\n",
    "2. Para el término $\\beta \\sin(z)$:  \n",
    "   Al tratarse de $\\beta$ constante respecto a $z$, su derivada es:\n",
    "   $$\n",
    "   \\frac{d}{dz}[\\beta \\sin(z)] = \\beta \\cos(z).\n",
    "   $$\n",
    "\n",
    "**Por lo tanto:**\n",
    "$$\n",
    "\\frac{\\partial \\phi}{\\partial z} = \\sigma(z) + z\\,\\sigma(z)(1-\\sigma(z)) + \\beta\\,\\cos(z).\n",
    "$$\n",
    "\n",
    "**Derivada de $\\phi(z)$ respecto a $\\beta$:**\n",
    "\n",
    "Como $\\beta$ solo aparece en el segundo término:\n",
    "$$\n",
    "\\frac{\\partial \\phi}{\\partial \\beta} = \\sin(z).\n",
    "$$\n",
    "\n",
    "\n",
    "#### Implementación de la red neuronal con activación personalizada\n",
    "\n",
    "Consideraremos una red muy simple con:\n",
    "- **Capa de entrada:** 2 neuronas.\n",
    "- **Capa oculta:** 2 neuronas que usan la función $\\phi(z)$ definida.\n",
    "- **Capa de salida:** 1 neurona (usaremos activación lineal para simplificar el ejemplo).\n",
    "\n",
    "##### **Esquema del modelo**\n",
    "\n",
    "1. **Forward:**\n",
    "\n",
    "   - **Capa oculta:**  \n",
    "     Para una entrada $ \\mathbf{x} \\in \\mathbb{R}^2 $,\n",
    "     $$\n",
    "     \\mathbf{z}^{(1)} = W^{(1)}\\mathbf{x} + \\mathbf{b}^{(1)} \\quad \\text{(dimensión: 2)}\n",
    "     $$\n",
    "     La activación es:\n",
    "     $$\n",
    "     \\mathbf{a}^{(1)} = \\phi\\bigl(\\mathbf{z}^{(1)}\\bigr) \\quad \\text{aplicada elemento a elemento}.\n",
    "     $$\n",
    "     \n",
    "   - **Capa de salida:**  \n",
    "     $$\n",
    "     z^{(2)} = W^{(2)}\\cdot \\mathbf{a}^{(1)} + b^{(2)}\n",
    "     $$\n",
    "     y la salida (por ejemplo, usando activación lineal) es:\n",
    "     $$\n",
    "     \\hat{y} = z^{(2)}.\n",
    "     $$\n",
    "     \n",
    "   - **Función de pérdida:**  \n",
    "     Usaremos el error cuadrático:\n",
    "     $$\n",
    "     L = \\frac{1}{2}\\bigl(\\hat{y} - y\\bigr)^2.\n",
    "     $$\n",
    "\n",
    "2. **Backward  (cálculo manual de gradientes):**\n",
    "\n",
    "   Sea $ \\delta^{(2)} = \\frac{\\partial L}{\\partial z^{(2)}} = \\hat{y} - y $.  \n",
    "   Los gradientes en la capa de salida son:\n",
    "   $$\n",
    "   \\frac{\\partial L}{\\partial W^{(2)}} = \\delta^{(2)} \\cdot \\mathbf{a}^{(1)} \\quad,\\quad \\frac{\\partial L}{\\partial b^{(2)}} = \\delta^{(2)}.\n",
    "   $$\n",
    "   \n",
    "   Para la capa oculta, se propaga el error:\n",
    "   $$\n",
    "   \\delta^{(1)} = \\left(W^{(2)}\\right)^T \\delta^{(2)} \\odot \\phi'(z^{(1)}),\n",
    "   $$\n",
    "   donde $\\odot$ es el producto elemento a elemento y $\\phi'(z^{(1)})$ se evalúa con la derivada definida:\n",
    "   $$\n",
    "   \\phi'(z) = \\sigma(z) + z\\,\\sigma(z)(1-\\sigma(z)) + \\beta\\,\\cos(z).\n",
    "   $$\n",
    "   \n",
    "   Los gradientes respecto a los parámetros de la capa oculta son:\n",
    "   $$\n",
    "   \\frac{\\partial L}{\\partial W^{(1)}} = \\delta^{(1)} \\cdot \\mathbf{x}^T,\\quad \\frac{\\partial L}{\\partial \\mathbf{b}^{(1)}} = \\delta^{(1)}.\n",
    "   $$\n",
    "   \n",
    "   **Importante:** Además, para el parámetro $\\beta$ se tiene\n",
    "   $$\n",
    "   \\frac{\\partial L}{\\partial \\beta} = \\sum_{i}\\delta^{(1)}_i \\cdot \\frac{\\partial \\phi(z^{(1)}_i)}{\\partial \\beta} \\quad \\text{y recordemos que} \\quad \\frac{\\partial \\phi(z)}{\\partial \\beta} = \\sin(z).\n",
    "   $$\n",
    "   En este ejemplo, se suma sobre las neuronas de la capa oculta (o se toma el promedio si se entrena con mini-batch).\n",
    "\n",
    "A continuación se muestra un ejemplo completo con un solo dato (pasos forward y backward ) para ilustrar el proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071276cf-0af5-440f-9b47-12bbe446880a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Definiciones básicas\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def phi(z, beta):\n",
    "    \"\"\"\n",
    "    Función de activación personalizada:\n",
    "    phi(z) = z * sigmoid(z) + beta * sin(z)\n",
    "    \"\"\"\n",
    "    return z * sigmoid(z) + beta * np.sin(z)\n",
    "\n",
    "def dphi_dz(z, beta):\n",
    "    \"\"\"\n",
    "    Derivada de phi(z) respecto a z:\n",
    "    dphi/dz = sigmoid(z) + z * sigmoid(z)*(1-sigmoid(z)) + beta*cos(z)\n",
    "    \"\"\"\n",
    "    s = sigmoid(z)\n",
    "    return s + z * s * (1 - s) + beta * np.cos(z)\n",
    "\n",
    "def dphi_dbeta(z):\n",
    "    \"\"\"\n",
    "    Derivada de phi(z) respecto a beta:\n",
    "    dphi/d(beta) = sin(z)\n",
    "    \"\"\"\n",
    "    return np.sin(z)\n",
    "\n",
    "# Inicialización de parámetros para la red\n",
    "np.random.seed(0)\n",
    "# Para la capa oculta (2 neuronas de entrada -> 2 neuronas ocultas)\n",
    "W1 = np.random.randn(2, 2) * 0.1  # matriz 2x2\n",
    "b1 = np.random.randn(2) * 0.1       # vector de 2\n",
    "# Parámetro beta para la activación (global para ambas neuronas ocultas)\n",
    "beta = 0.1\n",
    "\n",
    "# Para la capa de salida (2 neuronas ocultas -> 1 salida)\n",
    "W2 = np.random.randn(1, 2) * 0.1   # vector fila de 2\n",
    "b2 = 0.0\n",
    "\n",
    "# Ejemplo: Un único dato de entrada\n",
    "x = np.array([0.5, -0.5])  # Dimensión: 2\n",
    "y_true = 1.0\n",
    "\n",
    "# Paso forward\n",
    "# Capa oculta\n",
    "z1 = np.dot(W1, x) + b1         # z1: vector de 2\n",
    "a1 = phi(z1, beta)              # a1: vector de 2, activación personalizada\n",
    "\n",
    "# Capa de salida (activación lineal)\n",
    "z2 = np.dot(W2, a1) + b2        # z2: escalar\n",
    "y_pred = z2\n",
    "\n",
    "# Función de pérdida (error cuadrático)\n",
    "loss = 0.5 * (y_pred - y_true)**2\n",
    "\n",
    "print(\"Paso forward:\")\n",
    "print(\"x =\", x)\n",
    "print(\"z1 =\", z1)\n",
    "print(\"a1 =\", a1)\n",
    "print(\"z2 =\", z2)\n",
    "print(\"y_pred =\", y_pred)\n",
    "print(\"Perdida =\", loss)\n",
    "\n",
    "# Paso backward\n",
    "# Derivada de la pérdida respecto a z2\n",
    "dL_dz2 = y_pred - y_true   # Escalar\n",
    "\n",
    "# Gradientes para la capa de salida\n",
    "dL_dW2 = dL_dz2 * a1       # (1x2)\n",
    "dL_db2 = dL_dz2          # Escalar\n",
    "\n",
    "# Propagamos el gradiente a la capa oculta\n",
    "# Nota: W2 tiene forma (1,2) -> se transpone para distribuir el error a cada neurona oculta\n",
    "delta1 = (W2.T * dL_dz2).flatten()  # vector de 2\n",
    "# Multiplicamos por la derivada de la activación\n",
    "delta1 = delta1 * dphi_dz(z1, beta)  # elemento a elemento\n",
    "\n",
    "# Gradientes para la capa oculta\n",
    "dL_dW1 = np.outer(delta1, x)   # (2x2)\n",
    "dL_db1 = delta1               # (2,)\n",
    "\n",
    "# Gradiente respecto a beta (se suma la contribución de cada neurona oculta)\n",
    "dL_dbeta = np.sum(delta1 * dphi_dbeta(z1))\n",
    "\n",
    "print(\"\\nPaso backward:\")\n",
    "print(\"dL_dz2 =\", dL_dz2)\n",
    "print(\"dL_dW2 =\", dL_dW2)\n",
    "print(\"dL_db2 =\", dL_db2)\n",
    "print(\"delta1 =\", delta1)\n",
    "print(\"dL_dW1 =\", dL_dW1)\n",
    "print(\"dL_db1 =\", dL_db1)\n",
    "print(\"dL_dbeta =\", dL_dbeta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbf4622-11ac-40b0-a78b-8b3e01b388fb",
   "metadata": {},
   "source": [
    "#### Discusión sobre explosión o desvanecimiento del gradiente y estrategia de inicialización\n",
    "\n",
    "La función de activación propuesta es:\n",
    "$$\n",
    "\\phi(z) = z\\,\\sigma(z) + \\beta\\,\\sin(z).\n",
    "$$\n",
    "Observaciones:\n",
    "\n",
    "1. **Comportamiento de la parte $z\\,\\sigma(z)$:**  \n",
    "   Esta parte es similar a la función *swish*, la cual ha demostrado tener buenas propiedades para evitar el desvanecimiento del gradiente, pues su derivada se mantiene en valores razonables para un amplio rango de $z$.\n",
    "\n",
    "2. **Impacto del término $\\beta\\,\\sin(z)$:**  \n",
    "   - **Si $\\beta$ es muy grande:**  \n",
    "     La derivada de este término es $\\beta\\,\\cos(z)$. Para ciertos valores de $z$ (por ejemplo, cuando $\\cos(z)$ está cercano a 1), un valor elevado de $\\beta$ puede amplificar excesivamente el gradiente, contribuyendo a la **explosión del gradiente**.\n",
    "   - **Si $\\beta$ es muy pequeño (o cero):**  \n",
    "     La contribución del término oscilatorio se vuelve insignificante. En ese caso, el comportamiento se asemeja al de *swish*, lo que es deseable en muchos contextos, pero se pierde la potencial ventaja de la corrección oscilatoria.\n",
    "\n",
    "3. **Efecto combinado:**  \n",
    "   La presencia del término oscilatorio (debido a $\\sin(z)$) puede introducir fluctuaciones en la magnitud del gradiente. Esto significa que, dependiendo de la región en la que se encuentre $z$, se puede observar tanto un aumento como una disminución brusca del gradiente.\n",
    "\n",
    "##### **Estrategia de inicialización de $\\beta$**:\n",
    "\n",
    "Para evitar problemas de explosión del gradiente, se recomienda **inicializar $\\beta$ con un valor pequeño**. Algunas estrategias posibles son:\n",
    "- **Inicialización cercana a cero:**  \n",
    "  Por ejemplo, usar $\\beta = 0.0$ o un valor pequeño positivo como $0.01$ o $0.1$. Esto asegura que al comienzo la contribución oscilatoria no domine la dinámica del gradiente.\n",
    "- **Inicialización adaptativa:**  \n",
    "  Se puede considerar entrenar $\\beta$ con una tasa de aprendizaje separada o regularización adicional que controle su crecimiento durante el entrenamiento.\n",
    "\n",
    "Iniciar $\\beta$ con un valor pequeño (por ejemplo, $\\beta=0.1$) es una estrategia prudente para que la función de activación comience con un comportamiento similar al de *swish* y, a medida que el entrenamiento progrese, el modelo aprenda si la corrección oscilatoria aporta mejoras sin generar inestabilidad en la propagación del gradiente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05465607-66bc-41b5-b32b-6cc6975c110a",
   "metadata": {},
   "source": [
    "### **Pregunta 3**\n",
    "\n",
    "####  Función de pérdida total\n",
    "\n",
    "Supongamos que nuestro modelo tiene tres objetivos que se desean optimizar conjuntamente:\n",
    "\n",
    "1. **Cross Entropy (CE)** para clasificación:  \n",
    "   Sea la salida del modelo para clasificación $\\hat{\\mathbf{y}}$ y la etiqueta verdadera $\\mathbf{y}$ (usando one-hot encoding, por ejemplo). La pérdida se define como:\n",
    "   $$\n",
    "   L_{\\text{CE}} = - \\sum_{i} y_i \\log (\\hat{y}_i).\n",
    "   $$\n",
    "\n",
    "2. **Kullback-Leibler Divergence (KL)** para alinear distribuciones de salidas:  \n",
    "   Sea $q$ la distribución \"objetivo\" y $p$ la distribución generada por el modelo. La divergencia se define como:\n",
    "   $$\n",
    "   D_{\\text{KL}}(q \\parallel p) = \\sum_{i} q_i \\log \\frac{q_i}{p_i}.\n",
    "   $$\n",
    "   (En aplicaciones como VAEs, se usa para forzar la distribución latente a acercarse a una distribución prior).\n",
    "\n",
    "3. **Reconstruction Loss (MSE)** para forzar a una capa interna a autoencodificar parte de la representación:  \n",
    "   Sea la representación original $\\mathbf{x}$ y la reconstruida $\\hat{\\mathbf{x}}$. El MSE se define como:\n",
    "   $$\n",
    "   L_{\\text{MSE}} = \\frac{1}{N} \\sum_{j} (x_j - \\hat{x}_j)^2.\n",
    "   $$\n",
    "\n",
    "Cada uno de estos términos se pondera con un hiperparámetro distinto. Así, la función de pérdida total es:\n",
    "$$\n",
    "\\mathcal{L}_{\\text{total}} = \\lambda_{\\text{CE}} \\, L_{\\text{CE}} + \\lambda_{\\text{KL}} \\, D_{\\text{KL}} + \\lambda_{\\text{MSE}} \\, L_{\\text{MSE}},\n",
    "$$\n",
    "donde $\\lambda_{\\text{CE}}$, $\\lambda_{\\text{KL}}$ y $\\lambda_{\\text{MSE}}$ son hiperparámetros que determinan la contribución de cada término.\n",
    "\n",
    "#### Retropropagación de los gradientes\n",
    "\n",
    "El entrenamiento se realiza usando retropropagación. El flujo es el siguiente:\n",
    "\n",
    "1. **Cálculo de cada término de pérdida:**  \n",
    "   - En la rama de clasificación se computa $L_{\\text{CE}}$.\n",
    "   - En la rama de alineación de distribuciones se calcula $D_{\\text{KL}}$.\n",
    "   - En la rama de reconstrucción se evalúa $L_{\\text{MSE}}$.\n",
    "\n",
    "2. **Suma ponderada y retropropagación:**  \n",
    "   Se suma la pérdida total y, usando la regla de la cadena, se retropropaga el gradiente desde la salida del modelo hasta los parámetros internos.  \n",
    "   Es decir, para cada parámetro $\\theta$ se tiene:\n",
    "   $$\n",
    "   \\frac{\\partial \\mathcal{L}_{\\text{total}}}{\\partial \\theta} = \\lambda_{\\text{CE}} \\, \\frac{\\partial L_{\\text{CE}}}{\\partial \\theta} + \\lambda_{\\text{KL}} \\, \\frac{\\partial D_{\\text{KL}}}{\\partial \\theta} + \\lambda_{\\text{MSE}} \\, \\frac{\\partial L_{\\text{MSE}}}{\\partial \\theta}.\n",
    "   $$\n",
    "\n",
    "3. **Orden y posibles incompatibilidades:**  \n",
    "   - **Orden:**  \n",
    "     La retropropagación se realiza \"en paralelo\" en el sentido de que, en la última capa, se suman los gradientes provenientes de cada término. Si las ramas comparten parámetros (por ejemplo, en capas intermedias), cada gradiente parcial se suma y se utiliza para actualizar los parámetros.\n",
    "   - **Riesgo de incompatibilidad:**  \n",
    "     Los tres términos pueden tener escalas y comportamientos muy distintos. Por ejemplo, si el término KL tiene una magnitud mucho mayor que los otros, puede \"desviar\" el descenso de gradiente de manera que la red priorice la alineación de distribuciones en detrimento de la clasificación o la reconstrucción. Por ello es crucial ajustar los coeficientes $\\lambda$ de modo que ninguno domine excesivamente la actualización de los parámetros compartidos.\n",
    "\n",
    "#### Ejemplo numérico\n",
    "\n",
    "Consideremos un ejemplo simplificado en el que la variable de optimización es un único parámetro $x$.  \n",
    "Imaginemos que, usando solo CE y MSE, el \"mínimo ideal\" se alcanza en $x=2$. Esto lo representamos con una función de pérdida de la forma:\n",
    "$$\n",
    "L_{\\text{CE}} + L_{\\text{MSE}} = (x-2)^2 + (x-2)^2 = 2\\,(x-2)^2.\n",
    "$$\n",
    "\n",
    "Ahora, añadamos un término de KL que “empuje” $x$ hacia $3$:\n",
    "$$\n",
    "D_{\\text{KL}} = (x-3)^2.\n",
    "$$\n",
    "\n",
    "La pérdida total (con $\\lambda_{\\text{CE}}=\\lambda_{\\text{MSE}}=1$ y $\\lambda_{\\text{KL}}=1$) es:\n",
    "$$\n",
    "L_{\\text{total}}(x) = 2\\,(x-2)^2 + (x-3)^2.\n",
    "$$\n",
    "\n",
    "##### **Cálculo analítico del mínimo**\n",
    "\n",
    "Derivamos $L_{\\text{total}}(x)$ respecto a $x$:\n",
    "$$\n",
    "\\frac{dL_{\\text{total}}}{dx} = 2 \\cdot 2 (x-2) + 2 (x-3) = 4(x-2) + 2(x-3).\n",
    "$$\n",
    "Igualamos a cero:\n",
    "$$\n",
    "4(x-2) + 2(x-3) = 0 \\quad \\Rightarrow \\quad 4x - 8 + 2x - 6 = 0 \\quad \\Rightarrow \\quad 6x - 14 = 0,\n",
    "$$\n",
    "de donde:\n",
    "$$\n",
    "x = \\frac{14}{6} \\approx 2.33.\n",
    "$$\n",
    "Esto muestra que, al incluir el término KL, el óptimo se \"desvía\" de $x=2$ a $x \\approx 2.33$.\n",
    "\n",
    "\n",
    "A continuación se presenta un código en Python que ilustra este comportamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ccff5a-137b-4a82-960b-e0b861c19f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Coeficientes de ponderación\n",
    "lambda_ce = 1.0\n",
    "lambda_mse = 1.0\n",
    "lambda_kl = 1.0\n",
    "\n",
    "def loss_total(x, lambda_ce, lambda_kl, lambda_mse):\n",
    "    # Supongamos que CE y MSE \"idealmente\" minimizan en x=2 y KL en x=3\n",
    "    loss_ce = (x - 2)**2\n",
    "    loss_mse = (x - 2)**2\n",
    "    loss_kl = (x - 3)**2\n",
    "    return lambda_ce * loss_ce + lambda_kl * loss_kl + lambda_mse * loss_mse\n",
    "\n",
    "# Generar valores de x para visualizar la función de pérdida\n",
    "xs = np.linspace(0, 5, 100)\n",
    "ys = loss_total(xs, lambda_ce, lambda_kl, lambda_mse)\n",
    "\n",
    "# Identificar el mínimo\n",
    "min_x = xs[np.argmin(ys)]\n",
    "min_y = np.min(ys)\n",
    "\n",
    "# Visualización\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(xs, ys, label=\"Pérdida total\")\n",
    "plt.axvline(2, color='r', linestyle='--', label=\"Mínimo con CE+MSE (x=2)\")\n",
    "plt.axvline(min_x, color='g', linestyle='--', label=f\"Mínimo Total (x={min_x:.2f})\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"Pérdida\")\n",
    "plt.title(\"Ejemplo numérico: influencia del término KL\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"El mínimo de la pérdida total se alcanza en x =\", min_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7b7ec6-7383-410f-8fa0-1b8fd3fbe5e5",
   "metadata": {},
   "source": [
    "#### Explicación de los resultados\n",
    "\n",
    "- **Sin el término KL:**  \n",
    "  Si solo se consideran $L_{\\text{CE}}$ y $L_{\\text{MSE}}$, la función de pérdida es $2\\,(x-2)^2$ y el mínimo se alcanza en $x=2$.\n",
    "\n",
    "- **Con el término KL:**  \n",
    "  Al agregar $(x-3)^2$ (ponderado por $\\lambda_{KL}=1$), el mínimo de la pérdida total se desplaza hacia $x \\approx 2.33$. Esto ilustra que la inclusión de la divergencia KL “desvía” el óptimo de la solución que se obtendría solo con CE y MSE.\n",
    "\n",
    "En un modelo real, esta desviación puede ser beneficiosa o perjudicial según el objetivo de alinear distribuciones. Sin embargo, si no se pondera adecuadamente, el término KL puede dominar y forzar a la red a aprender representaciones que se adapten a la distribución prior en detrimento de la precisión en clasificación o reconstrucción."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eba9523-9d72-4f92-915d-f76cc510ded9",
   "metadata": {},
   "source": [
    "### **Pregunta 4**\n",
    "\n",
    "#### Descripción del procedimiento\n",
    "\n",
    "1. **Generar dataset 2D:**  \n",
    "   Se crea un conjunto de datos bidimensional en el que la etiqueta se define de forma sencilla. Por ejemplo, se puede asignar la etiqueta  \n",
    "   $$\n",
    "   y = \\begin{cases} 1 & \\text{si } x + y \\ge 0 \\\\ 0 & \\text{si } x + y < 0 \\end{cases}\n",
    "   $$\n",
    "   para cada punto $(x,y)$.\n",
    "\n",
    "2. **Entrenar un perceptrón multicapa:**  \n",
    "   Se construye una red con, por ejemplo, dos capas ocultas (usando 10 neuronas cada una) y una salida con activación sigmoidea (para clasificación binaria). La arquitectura es:\n",
    "   - **Entrada:** 2 unidades  \n",
    "   - **Capa oculta 1:** 10 neuronas con función de activación *tanh*  \n",
    "   - **Capa oculta 2:** 10 neuronas con función de activación *tanh*  \n",
    "   - **Salida:** 1 neurona con activación sigmoidea  \n",
    "   Se usa la *cross entropy* como función de pérdida.\n",
    "\n",
    "3. **Visualizar la región de decisión:**  \n",
    "   Se genera una malla de puntos sobre el plano. Para cada punto se calcula la salida del modelo y se traza la frontera (por ejemplo, usando un diagrama de contorno) de la región en la que el modelo predice la clase 1 versus 0.\n",
    "\n",
    "4. **Cálculo de gradientes y mapa de calor:**  \n",
    "   Para cada punto de la malla se realiza un forward pass y se computa la pérdida (suponiendo la etiqueta \"verdadera\" determinada por la función de generación, es decir, 1 si $x+y\\ge0$ y 0 en otro caso). Luego se hace un backward pass *manualmente* para obtener el gradiente de la pérdida con respecto a los pesos de la primera capa. Finalmente se calcula la magnitud (por ejemplo, la norma L2) de este gradiente y se representa en un mapa de calor superpuesto al diagrama del plano.\n",
    "\n",
    "A continuación se muestra el código que implementa este procedimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0f2b04-b54f-4e30-b6d4-f53aca500dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Generar dataset 2D\n",
    "def generate_dataset(n_samples=200, lim=3.0, random_seed=42):\n",
    "    np.random.seed(random_seed)\n",
    "    # Generamos puntos uniformemente en [-lim, lim]\n",
    "    X = np.random.uniform(-lim, lim, (n_samples, 2))\n",
    "    # Etiqueta: 1 si x+y>=0, 0 de lo contrario\n",
    "    y = (X[:, 0] + X[:, 1] >= 0).astype(np.float32)\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = generate_dataset(n_samples=300)\n",
    "\n",
    "# Visualizamos el dataset\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(X_train[y_train==0, 0], X_train[y_train==0, 1], color='red', label=\"Clase 0\")\n",
    "plt.scatter(X_train[y_train==1, 0], X_train[y_train==1, 1], color='blue', label=\"Clase 1\")\n",
    "plt.legend()\n",
    "plt.title(\"Conjunto de datos 2D\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()\n",
    "\n",
    "# 2. Definir y entrenar la red neuronal\n",
    "# Arquitectura: 2 -> 10 -> 10 -> 1\n",
    "# Usaremos activación tanh en las capas ocultas y sigmoid en la salida.\n",
    "# Funciones de activación y sus derivadas\n",
    "def tanh(z):\n",
    "    return np.tanh(z)\n",
    "\n",
    "def dtanh(z):\n",
    "    return 1 - np.tanh(z)**2\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def dsigmoid(z):\n",
    "    s = sigmoid(z)\n",
    "    return s * (1-s)\n",
    "\n",
    "# Inicialización de pesos (usamos inicialización sencilla tipo Xavier para tanh)\n",
    "def init_weights(n_in, n_out):\n",
    "    bound = np.sqrt(6 / (n_in + n_out))\n",
    "    return np.random.uniform(-bound, bound, (n_out, n_in))\n",
    "\n",
    "# Dimensiones\n",
    "n_input = 2\n",
    "n_hidden1 = 10\n",
    "n_hidden2 = 10\n",
    "n_output = 1\n",
    "\n",
    "# Inicializamos pesos y sesgos\n",
    "W1 = init_weights(n_input, n_hidden1)   # (10,2)\n",
    "b1 = np.zeros((n_hidden1, 1))             # (10,1)\n",
    "W2 = init_weights(n_hidden1, n_hidden2)   # (10,10)\n",
    "b2 = np.zeros((n_hidden2, 1))             # (10,1)\n",
    "W3 = init_weights(n_hidden2, n_output)    # (1,10)\n",
    "b3 = np.zeros((n_output, 1))              # (1,1)\n",
    "\n",
    "# Función forward para un solo ejemplo (x es vector columna de shape (2,1))\n",
    "def forward(x):\n",
    "    z1 = np.dot(W1, x) + b1       # (10,1)\n",
    "    a1 = tanh(z1)\n",
    "    z2 = np.dot(W2, a1) + b2      # (10,1)\n",
    "    a2 = tanh(z2)\n",
    "    z3 = np.dot(W3, a2) + b3      # (1,1)\n",
    "    a3 = sigmoid(z3)\n",
    "    cache = (x, z1, a1, z2, a2, z3, a3)\n",
    "    return a3, cache\n",
    "\n",
    "# Función de pérdida: Cross Entropy para clasificación binaria\n",
    "def loss_fn(y_pred, y_true):\n",
    "    # Para evitar log(0), sumamos una pequeña constante\n",
    "    eps = 1e-8\n",
    "    return - (y_true * np.log(y_pred+eps) + (1 - y_true)*np.log(1-y_pred+eps))\n",
    "\n",
    "# Entrenamiento sencillo con gradiente descendente (por lotes)\n",
    "learning_rate = 0.01\n",
    "epochs = 200\n",
    "\n",
    "# Convertimos X_train a shape (2, n_samples) y y_train a (1, n_samples)\n",
    "X_train_T = X_train.T  # (2, n_samples)\n",
    "y_train_T = y_train.reshape(1, -1)  # (1, n_samples)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    # Gradientes acumulados (inicializados en cero)\n",
    "    dW1 = np.zeros_like(W1)\n",
    "    db1 = np.zeros_like(b1)\n",
    "    dW2 = np.zeros_like(W2)\n",
    "    db2 = np.zeros_like(b2)\n",
    "    dW3 = np.zeros_like(W3)\n",
    "    db3 = np.zeros_like(b3)\n",
    "    \n",
    "    n_samples = X_train_T.shape[1]\n",
    "    for i in range(n_samples):\n",
    "        # Extraer el ejemplo i-esimo\n",
    "        x = X_train_T[:, i].reshape(-1,1)   # (2,1)\n",
    "        y_true = y_train_T[:, i].reshape(1,1) # (1,1)\n",
    "        \n",
    "        # Forward pass\n",
    "        a3, cache = forward(x)\n",
    "        total_loss += loss_fn(a3, y_true)\n",
    "        \n",
    "        # Backward pass (derivadas manuales)\n",
    "        x, z1, a1, z2, a2, z3, a3 = cache\n",
    "        \n",
    "        # Gradiente de la pérdida con respecto a z3\n",
    "        dz3 = a3 - y_true  # (1,1)  ; derivada de cross entropy con sigmoid\n",
    "        dW3 += np.dot(dz3, a2.T)   # (1,10)\n",
    "        db3 += dz3\n",
    "        \n",
    "        # Propagar a la capa 2\n",
    "        da2 = np.dot(W3.T, dz3)    # (10,1)\n",
    "        dz2 = da2 * dtanh(z2)      # (10,1)\n",
    "        dW2 += np.dot(dz2, a1.T)   # (10,10)\n",
    "        db2 += dz2\n",
    "        \n",
    "        # Propagar a la capa 1 (pesos principales)\n",
    "        da1 = np.dot(W2.T, dz2)    # (10,1)\n",
    "        dz1 = da1 * dtanh(z1)      # (10,1)\n",
    "        dW1 += np.dot(dz1, x.T)    # (10,2)\n",
    "        db1 += dz1\n",
    "        \n",
    "    # Actualización de parámetros (dividiendo por el número de muestras)\n",
    "    W1 -= learning_rate * dW1 / n_samples\n",
    "    b1 -= learning_rate * db1 / n_samples\n",
    "    W2 -= learning_rate * dW2 / n_samples\n",
    "    b2 -= learning_rate * db2 / n_samples\n",
    "    W3 -= learning_rate * dW3 / n_samples\n",
    "    b3 -= learning_rate * db3 / n_samples\n",
    "    \n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoca {epoch}, Loss: {(total_loss/n_samples).item():.4f}\")\n",
    "\n",
    "# Se asume que la red ya está entrenada.\n",
    "# 3. Visualización de la región de decisión\n",
    "# Generamos una malla de puntos en el plano\n",
    "xx, yy = np.meshgrid(np.linspace(-3,3,200), np.linspace(-3,3,200))\n",
    "grid_points = np.c_[xx.ravel(), yy.ravel()]  # (n_points, 2)\n",
    "\n",
    "# Función de predicción\n",
    "def predict(x):\n",
    "    a3, _ = forward(x.reshape(-1,1))\n",
    "    return a3[0,0]\n",
    "\n",
    "Z = np.array([predict(pt) for pt in grid_points])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "# Diagrama de contorno de la región de decisión\n",
    "plt.contourf(xx, yy, Z, levels=np.linspace(0,1,20), cmap='coolwarm', alpha=0.6)\n",
    "plt.colorbar(label=\"Probabilidad predicha\")\n",
    "# Superponer el dataset de entrenamiento\n",
    "plt.scatter(X_train[y_train==0, 0], X_train[y_train==0, 1], color='red', edgecolor='k', label=\"Clase 0\")\n",
    "plt.scatter(X_train[y_train==1, 0], X_train[y_train==1, 1], color='blue', edgecolor='k', label=\"Clase 1\")\n",
    "plt.legend()\n",
    "plt.title(\"Región de decisión del MLP\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()\n",
    "\n",
    "# 4. Cálculo del gradiente (magnitud) respecto a W1 en cada punto de la malla\n",
    "def grad_W1_norm(x, y):\n",
    "    \"\"\"\n",
    "    Para un punto (x,y) se computa la magnitud (norma L2) del gradiente de la pérdida\n",
    "    (cross entropy) respecto a los pesos de la primera capa (W1).\n",
    "    Se asume la etiqueta verdadera según la regla: y_true=1 si x+y>=0, 0 si no.\n",
    "    \"\"\"\n",
    "    x_vec = np.array([x, y]).reshape(-1,1)  # (2,1)\n",
    "    # Etiqueta verdadera (según la regla de generación)\n",
    "    y_true = np.array([[1.0]]) if (x+y >= 0) else np.array([[0.0]])\n",
    "    # Forward pass\n",
    "    a3, cache = forward(x_vec)\n",
    "    loss = loss_fn(a3, y_true)\n",
    "    \n",
    "    # Backward pass para obtener gradiente de W1 (igual que en el entrenamiento, pero para un único ejemplo)\n",
    "    x_in, z1, a1, z2, a2, z3, a3 = cache\n",
    "    dz3 = a3 - y_true  # (1,1)\n",
    "    # Propagación hacia la capa 2\n",
    "    da2 = np.dot(W3.T, dz3)    # (10,1)\n",
    "    dz2 = da2 * dtanh(z2)      # (10,1)\n",
    "    # Propagación hacia la capa 1 (pesos principales)\n",
    "    da1 = np.dot(W2.T, dz2)    # (10,1)\n",
    "    dz1 = da1 * dtanh(z1)      # (10,1)\n",
    "    # Gradiente de W1 para este ejemplo: dW1 = dz1 * x^T, de forma (10,2)\n",
    "    dW1_local = np.dot(dz1, x_in.T)\n",
    "    # Retornamos la norma L2 de este gradiente\n",
    "    return np.linalg.norm(dW1_local)\n",
    "\n",
    "# Computamos la magnitud del gradiente para cada punto de la malla\n",
    "grad_norms = np.array([grad_W1_norm(pt[0], pt[1]) for pt in grid_points])\n",
    "grad_norms = grad_norms.reshape(xx.shape)\n",
    "\n",
    "# Mapa de calor del gradiente superpuesto a la región de decisión\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.contourf(xx, yy, Z, levels=np.linspace(0,1,20), cmap='coolwarm', alpha=0.6)\n",
    "heatmap = plt.contourf(xx, yy, grad_norms, levels=50, cmap='viridis', alpha=0.5)\n",
    "plt.colorbar(heatmap, label=\"Norma del gradiente (W1)\")\n",
    "plt.scatter(X_train[y_train==0, 0], X_train[y_train==0, 1], color='red', edgecolor='k', label=\"Clase 0\")\n",
    "plt.scatter(X_train[y_train==1, 0], X_train[y_train==1, 1], color='blue', edgecolor='k', label=\"Clase 1\")\n",
    "plt.legend()\n",
    "plt.title(\"Mapa de calor de la norma del gradiente respecto a W1\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()\n",
    "\n",
    "# 5. Análisis\n",
    "\n",
    "print(\"\"\"\n",
    "Análisis:\n",
    "- En zonas donde la red está muy segura (por ejemplo, donde la probabilidad predicha se acerca a 0 o 1) \n",
    "  el gradiente de la cross entropy tiende a ser pequeño, lo que indica saturación de la función de activación \n",
    "  (en particular, tanh o sigmoide saturan para valores extremos).\n",
    "- En las regiones cercanas a la frontera de decisión, la salida varía más rápidamente y la pérdida es mayor, \n",
    "  generando gradientes de mayor magnitud.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3810ac1-e896-414b-b8d1-f622f450ead3",
   "metadata": {},
   "source": [
    "#### Discusión sobre la inicialización de pesos y la elección de la función de activación\n",
    "\n",
    "- **Inicialización de pesos:**  \n",
    "  - Una **inicialización adecuada** (por ejemplo, Xavier o He) asegura que los valores de activación en las capas intermedias no se dispersen en zonas de saturación.  \n",
    "  - Si los pesos se inicializan con valores muy grandes, las activaciones (por ejemplo, tanh o sigmoide) tienden a saturarse (valores muy cercanos a 1 o -1, o 0 y 1 en el caso de sigmoide), y la derivada (y por ende el gradiente) se vuelve muy pequeña. Esto se reflejará en el mapa de calor como zonas de gradiente casi nulo.  \n",
    "  - Una inicialización inadecuada (por ejemplo, con valores demasiado pequeños) puede provocar que la señal se debilite desde la entrada, lo que también afecta el aprendizaje.\n",
    "\n",
    "- **Elección de la función de activación:**  \n",
    "  - **Funciones saturantes (sigmoide, tanh):**  \n",
    "    Estas funciones tienden a “aplanarse” para entradas muy positivas o muy negativas. Esto causa que en estas regiones la derivada sea muy pequeña y, en consecuencia, se produzca el *desvanecimiento del gradiente*. En el mapa de calor se verán áreas con gradientes bajos.  \n",
    "  - **Funciones no saturantes (ReLU, Leaky ReLU):**  \n",
    "    Estas funciones, en particular para valores positivos, no saturan (o lo hacen de forma moderada). Esto favorece que el gradiente se mantenga en niveles adecuados en gran parte del dominio, lo que se reflejará en un mapa de calor con regiones de gradiente más “uniforme” (aunque pueden aparecer zonas muertas en ReLU si muchos neuronas quedan en 0).\n",
    "\n",
    "Tanto la correcta inicialización de los pesos como la elección de la función de activación son factores cruciales que determinan en qué zonas del espacio de entrada el modelo aprende de forma efectiva (con gradientes significativos) y en cuáles se produce saturación (con gradientes muy pequeños). Ajustar estos aspectos ayuda a evitar problemas de desvanecimiento o explosión de gradientes y a lograr una convergencia más estable durante el entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f855136-3791-47f9-b5d8-e0bcace18e8e",
   "metadata": {},
   "source": [
    "### **Pregunta 5**\n",
    "\n",
    "#### Escenario propuesto\n",
    "\n",
    "Imaginemos un escenario en el que cada muestra del dataset tiene dos componentes:\n",
    "- **Texto:** Una secuencia de oraciones cortas. Cada oración se tokeniza y se proyecta a un espacio de embeddings, de dimensión $d_{\\text{model}}$.\n",
    "- **Imagen:** Una imagen asociada que se procesa (por ejemplo, mediante una CNN o un extractor de características) para obtener descriptores o *features*. Supongamos que se extraen $M$ vectores (por ejemplo, regiones o patches) de dimensión $d_{\\text{img}}$.\n",
    "\n",
    "Para fusionar ambos modos, se puede utilizar un **mecanismo de auto-atención** en cada rama (texto e imagen) y luego aplicar un **mecanismo de cross-attention** para que una modalidad aprenda a \"atender\" a la otra.\n",
    "\n",
    "#### Self-Attention para cada modalidad\n",
    "\n",
    "##### **Para el texto**\n",
    "\n",
    "Sea $X_{\\text{text}} \\in \\mathbb{R}^{T \\times d_{\\text{model}}}$ la matriz de embeddings de una secuencia de $T$ tokens. Se proyecta a un espacio compartido (de dimensión $d_k$) para calcular queries, keys y values:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Q_{\\text{text}} &= X_{\\text{text}} W_{\\text{text}}^Q \\quad &&\\in \\mathbb{R}^{T \\times d_k} \\\\\n",
    "K_{\\text{text}} &= X_{\\text{text}} W_{\\text{text}}^K \\quad &&\\in \\mathbb{R}^{T \\times d_k} \\\\\n",
    "V_{\\text{text}} &= X_{\\text{text}} W_{\\text{text}}^V \\quad &&\\in \\mathbb{R}^{T \\times d_v}\n",
    "\\end{aligned}\n",
    "$$\n",
    "La atención se calcula como:\n",
    "$$\n",
    "\\text{Attention}(X_{\\text{text}}) = \\text{softmax}\\left(\\frac{Q_{\\text{text}}K_{\\text{text}}^\\top}{\\sqrt{d_k}}\\right) V_{\\text{text}}\n",
    "$$\n",
    "\n",
    "##### **Para la imagen**\n",
    "\n",
    "Sea $X_{\\text{img}} \\in \\mathbb{R}^{M \\times d_{\\text{img}}}$ la matriz de características extraídas de $M$ regiones o patches. De forma similar, se proyecta:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Q_{\\text{img}} &= X_{\\text{img}} W_{\\text{img}}^Q \\quad &&\\in \\mathbb{R}^{M \\times d_k} \\\\\n",
    "K_{\\text{img}} &= X_{\\text{img}} W_{\\text{img}}^K \\quad &&\\in \\mathbb{R}^{M \\times d_k} \\\\\n",
    "V_{\\text{img}} &= X_{\\text{img}} W_{\\text{img}}^V \\quad &&\\in \\mathbb{R}^{M \\times d_v}\n",
    "\\end{aligned}\n",
    "$$\n",
    "Y se calcula la auto-atención:\n",
    "$$\n",
    "\\text{Attention}(X_{\\text{img}}) = \\text{softmax}\\left(\\frac{Q_{\\text{img}}K_{\\text{img}}^\\top}{\\sqrt{d_k}}\\right) V_{\\text{img}}\n",
    "$$\n",
    "\n",
    "> **Nota sobre las dimensiones:**  \n",
    "> Para que la multiplicación $Q K^\\top$ sea válida, ambas matrices deben compartir la dimensión $d_k$. Por ello, en ambos casos (texto e imagen) se proyecta a un espacio de dimensión $d_k$. Esto es clave para el mecanismo de cross-attention, pues se requiere que queries y keys provenientes de distintas modalidades sean compatibles.\n",
    "\n",
    "#### Cross-attention para la interacción entre modalidades\n",
    "\n",
    "El cross-attention permite que una modalidad (por ejemplo, el texto) \"atenga\" a la otra (la imagen) para obtener una representación enriquecida.\n",
    "\n",
    "Utilizando los queries del texto y los keys y values de la imagen, la atención cruzada se define como:\n",
    "$$\n",
    "\\text{Attention}(X_{\\text{text}}, X_{\\text{img}}) = \\text{softmax}\\left(\\frac{Q_{\\text{text}}K_{\\text{img}}^\\top}{\\sqrt{d_k}}\\right) V_{\\text{img}}\n",
    "$$\n",
    "\n",
    "\n",
    "De forma análoga, para que la imagen se beneficie de la información textual:\n",
    "$$\n",
    "\\text{Attention}(X_{\\text{img}}, X_{\\text{text}}) = \\text{softmax}\\left(\\frac{Q_{\\text{img}}K_{\\text{text}}^\\top}{\\sqrt{d_k}}\\right) V_{\\text{text}}\n",
    "$$\n",
    "\n",
    "> **Dimensiones involucradas:**  \n",
    "> - $X_{\\text{text}}$ tiene forma $(T, d_{\\text{model}})$ y se proyecta a $(T, d_k)$.  \n",
    "> - $X_{\\text{img}}$ tiene forma $(M, d_{\\text{img}})$ y se proyecta a $(M, d_k)$.  \n",
    ">  \n",
    "> Para que la operación de dot product entre $Q_{\\text{text}}$ y $K_{\\text{img}}^\\top$ sea posible, ambas deben tener $d_k$ como dimensión final. De allí que se asuma un $d_k$ compartido entre las dos modalidades (o, en su defecto, se transforman para alcanzar dicha compatibilidad).\n",
    "\n",
    "\n",
    "A continuación se muestra un ejemplo de cómo implementar estos mecanismos en PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629acbb0-3505-44a7-b0ac-7846b9d4d269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiModalAttention(nn.Module):\n",
    "    def __init__(self, d_text, d_img, d_k, d_v):\n",
    "        super(MultiModalAttention, self).__init__()\n",
    "        # Proyecciones para el texto\n",
    "        self.Wq_text = nn.Linear(d_text, d_k)\n",
    "        self.Wk_text = nn.Linear(d_text, d_k)\n",
    "        self.Wv_text = nn.Linear(d_text, d_v)\n",
    "        \n",
    "        # Proyecciones para la imagen\n",
    "        self.Wq_img = nn.Linear(d_img, d_k)\n",
    "        self.Wk_img = nn.Linear(d_img, d_k)\n",
    "        self.Wv_img = nn.Linear(d_img, d_v)\n",
    "    \n",
    "    def self_attention(self, Q, K, V):\n",
    "        # Calcula la atención escalada\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / torch.sqrt(torch.tensor(Q.size(-1), dtype=torch.float32))\n",
    "        attn = F.softmax(scores, dim=-1)\n",
    "        return torch.matmul(attn, V)\n",
    "    \n",
    "    def self_attention_text(self, x_text):\n",
    "        Q = self.Wq_text(x_text)\n",
    "        K = self.Wk_text(x_text)\n",
    "        V = self.Wv_text(x_text)\n",
    "        return self.self_attention(Q, K, V)\n",
    "    \n",
    "    def self_attention_img(self, x_img):\n",
    "        Q = self.Wq_img(x_img)\n",
    "        K = self.Wk_img(x_img)\n",
    "        V = self.Wv_img(x_img)\n",
    "        return self.self_attention(Q, K, V)\n",
    "    \n",
    "    def cross_attention(self, Q, K, V):\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / torch.sqrt(torch.tensor(Q.size(-1), dtype=torch.float32))\n",
    "        attn = F.softmax(scores, dim=-1)\n",
    "        return torch.matmul(attn, V)\n",
    "    \n",
    "    def cross_attention_text_to_img(self, x_text, x_img):\n",
    "        Q_text = self.Wq_text(x_text)\n",
    "        K_img = self.Wk_img(x_img)\n",
    "        V_img = self.Wv_img(x_img)\n",
    "        return self.cross_attention(Q_text, K_img, V_img)\n",
    "    \n",
    "    def cross_attention_img_to_text(self, x_img, x_text):\n",
    "        Q_img = self.Wq_img(x_img)\n",
    "        K_text = self.Wk_text(x_text)\n",
    "        V_text = self.Wv_text(x_text)\n",
    "        return self.cross_attention(Q_img, K_text, V_text)\n",
    "\n",
    "# Ejemplo de uso\n",
    "# Supongamos que:\n",
    "# - Las secuencias de texto tienen 10 tokens, cada uno con dimensión 512.\n",
    "# - Las imágenes tienen 20 patches, cada uno con dimensión 1024.\n",
    "# - Queremos proyectar a un espacio de dimensión d_k=64 y d_v=64.\n",
    "batch_size = 2\n",
    "T, d_text = 10, 512\n",
    "M, d_img = 20, 1024\n",
    "d_k, d_v = 64, 64\n",
    "    \n",
    "x_text = torch.randn(batch_size, T, d_text)\n",
    "x_img = torch.randn(batch_size, M, d_img)\n",
    "    \n",
    "modelo = MultiModalAttention(d_text, d_img, d_k, d_v)\n",
    "    \n",
    "# Auto-atención para cada modalidad\n",
    "out_text = modelo.self_attention_text(x_text)\n",
    "out_img = modelo.self_attention_img(x_img)\n",
    "    \n",
    "# Cross-attention: texto atendiendo a imagen\n",
    "cross_text_to_img = modelo.cross_attention_text_to_img(x_text, x_img)\n",
    "    \n",
    "# Cross-attention: imagen atendiendo a texto\n",
    "cross_img_to_text = modelo.cross_attention_img_to_text(x_img, x_text)\n",
    "    \n",
    "print(\"Salida auto-atención texto:\", out_text.shape)\n",
    "print(\"Salida auto-atención imagen:\", out_img.shape)\n",
    "print(\"Salida cross-attention texto->imagen:\", cross_text_to_img.shape)\n",
    "print(\"Salida cross-attention imagen->texto:\", cross_img_to_text.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee74442-3bed-4ce7-9ce3-1ad99108671a",
   "metadata": {},
   "source": [
    "Este código demuestra cómo se pueden calcular las atenciones propias (self-attention) para cada modalidad y cómo implementar la atención cruzada (cross-attention)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9b22f2-1961-4319-a2c0-48632444b696",
   "metadata": {},
   "source": [
    "#### **Ajuste del factor $\\sqrt{d_k}$**\n",
    "\n",
    "En la ecuación de atención escalada se utiliza el factor $\\sqrt{d_k}$ para evitar que los productos escalares (dot products) crezcan demasiado al aumentar la dimensión, lo que puede llevar a que el softmax se sature y la distribución de probabilidades se vuelva muy \"puntiaguda\". \n",
    "Sin embargo, existen casos en los que podría justificarse ajustar este factor de forma distinta para cada modalidad:\n",
    "\n",
    "1. **Diferentes distribuciones de características:**  \n",
    "   Si las características del texto y de la imagen tienen distribuciones distintas (por ejemplo, varianzas diferentes) tras la proyección, el rango de los valores resultantes de los dot products también puede diferir.  \n",
    "   - **Circunstancia:** Cuando los embeddings de imagen presentan mayor varianza (o están en una escala distinta) en comparación con los embeddings de texto.  \n",
    "   - **Justificación:** Ajustar el factor $\\sqrt{d_k}$ (o incluso aprender un factor de escala) para cada modalidad ayuda a normalizar las magnitudes y evita que una modalidad domine la otra en la atención cruzada.\n",
    "\n",
    "2. **Dimensiones proyectadas diferentes:**  \n",
    "   Si, por alguna razón, se decide proyectar cada modalidad a dimensiones $d_k^{\\text{text}}$ y $d_k^{\\text{img}}$ diferentes, se debería usar $\\sqrt{d_k^{\\text{text}}}$ o $\\sqrt{d_k^{\\text{img}}}$ según corresponda.  \n",
    "   - **Circunstancia:** En modelos multimodales donde se cree que cada modalidad requiere una representación con distinta capacidad, por ejemplo, si se considera que la imagen tiene información más compleja y se usa un $d_k$ mayor.\n",
    "   - **Justificación:** Esto asegura que la escala de los dot products se normalice adecuadamente en cada caso.\n",
    "\n",
    "3. **Ajuste fino y aprendizaje del escalado:**  \n",
    "   En algunos modelos, se pueden introducir parámetros aprendibles que modulan este factor de escala para cada modalidad o incluso para cada cabecera en la atención multi-cabecera.  \n",
    "   - **Circunstancia:** Cuando se dispone de datos suficientes para aprender la escala óptima que permita equilibrar la contribución de cada modalidad.\n",
    "   - **Justificación:** Un factor de escala ajustado (o aprendido) puede mejorar la convergencia y el rendimiento del modelo al equilibrar adecuadamente las diferencias intrínsecas entre los modos.\n",
    "\n",
    "En resumen, aunque el factor $\\sqrt{d_k}$ se introduce originalmente para normalizar los dot products en función de la dimensión, en escenarios multimodales donde las características de texto e imagen pueden tener escalas o distribuciones diferentes (o incluso dimensiones proyectadas distintas), ajustar (o aprender) este factor de forma separada puede ayudar a obtener una atención más equilibrada y estable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d95db45-3e99-4d4d-a06c-ca756c5de1ad",
   "metadata": {},
   "source": [
    "### **Pregunta 6**\n",
    "\n",
    "#### Diseño de la arquitectura\n",
    "\n",
    "En una red recurrente “estándar” tenemos una dependencia de la forma:  \n",
    "$$\n",
    "h_t = f(x_t, h_{t-1})\n",
    "$$\n",
    "donde $h_t$ es el estado oculto en el tiempo $t$ y $x_t$ la entrada en ese instante.\n",
    "\n",
    "Para introducir una conexión **no estándar** que forme un ciclo en el grafo computacional, podemos agregar un **módulo iterativo interno** en cada paso temporal que refina el estado oculto. Es decir, luego de calcular el estado inicial $h_t^0$ con la recurrencia clásica, se ejecuta una iteración interna que retroalimenta la misma salida hasta converger o hasta un número fijo de iteraciones. Así, la actualización se puede escribir como:\n",
    "\n",
    "1. **Paso recurrente estándar:**  \n",
    "   $$\n",
    "   h_t^0 = \\tanh(W_x x_t + W_h h_{t-1})\n",
    "   $$\n",
    "2. **Ciclo interno (iterativo):**  \n",
    "   $$\n",
    "   h_t^{(i+1)} = \\tanh\\Big(h_t^{(i)} + W_c\\, h_t^{(i)}\\Big) \\quad \\text{para } i=0,1,\\ldots, N-1\n",
    "   $$\n",
    "   Finalmente, se toma:\n",
    "   $$\n",
    "   h_t = h_t^{(N)}\n",
    "   $$\n",
    "\n",
    "Esta conexión adicional $W_c\\, h_t^{(i)}$ dentro de un bucle introduce un **ciclo** en el grafo computacional porque la misma variable $h_t$ se actualiza reiteradamente de forma recursiva durante el mismo paso temporal.\n",
    "\n",
    "##### **Diagrama de bloques**\n",
    "\n",
    "A continuación se muestra un diagrama esquemático en el que se ilustra la arquitectura:\n",
    "\n",
    "```\n",
    "              x_t\n",
    "               │\n",
    "               ▼\n",
    "       +-----------------+\n",
    "       |  Capa de Input  |\n",
    "       +-----------------+\n",
    "               │\n",
    "               ▼\n",
    "       +-----------------+\n",
    "       | RNN Cell Standard| <-- h_{t-1}\n",
    "       +-----------------+\n",
    "               │\n",
    "               ▼\n",
    "            h_t^0\n",
    "               │\n",
    "         ┌─────┴─────┐\n",
    "         │  Módulo   │  ←─────+\n",
    "         │  Ciclo    │        │\n",
    "         │ Iterativo │        │\n",
    "         └─────┬─────┘        │\n",
    "               │              │\n",
    "          (Iteración interna) │\n",
    "               │              │\n",
    "               +──────────────+\n",
    "               │\n",
    "               ▼\n",
    "             h_t  (Salida final)\n",
    "```\n",
    "\n",
    "> **Nota:**  \n",
    "> El módulo ciclo iterativo puede ejecutarse un número fijo de veces (por ejemplo, $N=3$) o hasta que se cumpla una condición de convergencia. Esta conexión interna no lineal introduce un ciclo en el grafo que debe resolverse de forma iterativa.\n",
    "\n",
    "##### **Diferencias entre frameworks de grafo estático y dinámico**\n",
    "\n",
    "- **Grafos estáticos:**  \n",
    "  Frameworks como TensorFlow 1.x requieren definir de antemano toda la estructura del grafo computacional. Las conexiones cíclicas o iteraciones cuyo número de pasos depende de la entrada deben \"desenrollarse\" de forma fija. Esto implica:\n",
    "  - Un mayor esfuerzo en la definición manual del bucle.\n",
    "  - La necesidad de utilizar estructuras como `tf.while_loop` con límites fijos o condiciones predefinidas.\n",
    "  - La dificultad de manejar ciclos cuyo comportamiento dependa dinámicamente de la ejecución.\n",
    "\n",
    "- **Grafos dinámicos (Eager Mode, PyTorch, JAX):**  \n",
    "  En estos frameworks, el grafo se construye sobre la marcha durante la ejecución (modo \"eager\"). Esto permite:\n",
    "  - Programar ciclos o iteraciones internas de forma natural utilizando estructuras de control de Python (como `for` o `while`).\n",
    "  - Ajustar de forma dinámica el número de iteraciones en función de la condición de convergencia u otros criterios.\n",
    "  - Mayor flexibilidad para modelar dependencias cíclicas en el grafo computacional sin tener que \"desenrollar\" previamente el ciclo.\n",
    "\n",
    "\n",
    "El siguiente código implementa una celda recurrente que, en cada paso temporal, realiza una iteración interna (ciclo) para refinar el estado oculto:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3732e6f-2413-49f4-9040-928c29f88db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CycleRNNCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, cycle_steps=3):\n",
    "        \"\"\"\n",
    "        Parámetros:\n",
    "          - input_size: Dimensión de la entrada x_t.\n",
    "          - hidden_size: Dimensión del estado oculto h_t.\n",
    "          - cycle_steps: Número de iteraciones internas para el ciclo.\n",
    "        \"\"\"\n",
    "        super(CycleRNNCell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.cycle_steps = cycle_steps\n",
    "        \n",
    "        # Recurrencia estándar: de x_t y h_{t-1} a h_t^0\n",
    "        self.Wx = nn.Linear(input_size, hidden_size)\n",
    "        self.Wh = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "        # Conexión adicional para el ciclo interno\n",
    "        self.Wc = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "    def forward(self, x, h_prev):\n",
    "        # Paso recurrente estándar\n",
    "        h = torch.tanh(self.Wx(x) + self.Wh(h_prev))\n",
    "        # Ciclo interno de refinamiento\n",
    "        for _ in range(self.cycle_steps):\n",
    "            h = torch.tanh(h + self.Wc(h))\n",
    "        return h\n",
    "\n",
    "class CycleRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, cycle_steps=3):\n",
    "        super(CycleRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.cell = CycleRNNCell(input_size, hidden_size, cycle_steps)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        inputs: Tensor de forma (seq_len, batch_size, input_size)\n",
    "        \"\"\"\n",
    "        seq_len, batch_size, _ = inputs.size()\n",
    "        # Inicializamos h0 en cero\n",
    "        h = torch.zeros(batch_size, self.hidden_size, device=inputs.device)\n",
    "        outputs = []\n",
    "        for t in range(seq_len):\n",
    "            x_t = inputs[t]\n",
    "            h = self.cell(x_t, h)\n",
    "            outputs.append(h.unsqueeze(0))\n",
    "        outputs = torch.cat(outputs, dim=0)\n",
    "        return outputs\n",
    "\n",
    "# Ejemplo de uso:\n",
    "seq_len = 5\n",
    "batch_size = 2\n",
    "input_size = 10\n",
    "hidden_size = 20\n",
    "cycle_steps = 3\n",
    "    \n",
    "# Crear una secuencia de entrada aleatoria\n",
    "sample_input = torch.randn(seq_len, batch_size, input_size)\n",
    "rnn_model = CycleRNN(input_size, hidden_size, cycle_steps)\n",
    "output = rnn_model(sample_input)\n",
    "print(\"Forma de la salida:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bd6c68-fc85-4b9a-8921-b973480c86a0",
   "metadata": {},
   "source": [
    "En este ejemplo se observa cómo se introduce un ciclo interno en la celda recurrente. Gracias al modo dinámico (eager mode) de PyTorch, el bucle `for` se ejecuta de forma natural durante la ejecución, sin necesidad de definir previamente un grafo estático.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f295ae6b-bea6-45f4-90d3-87eb42257a6f",
   "metadata": {},
   "source": [
    "#### Inconvenientes y estrategias de mitigación en ciclos dinámicos\n",
    "\n",
    "##### **Inconvenientes o riesgos**\n",
    "\n",
    "1. **Inestabilidad numérica y explosión/desvanecimiento de gradientes:**\n",
    "   - **Riesgo:**  \n",
    "     La presencia de ciclos internos iterativos puede provocar que los gradientes se acumulen de forma excesiva (explosión) o se atenúen demasiado (desvanecimiento) a través de las iteraciones, lo que afecta el proceso de entrenamiento.\n",
    "   - **Estrategias de nitigación:**\n",
    "     - **Recorte de gradientes (gradient clipping):** Limitar el valor máximo de los gradientes para evitar explosiones.\n",
    "     - **Normalización de activaciones:** Usar técnicas como batch normalization o layer normalization dentro del ciclo para estabilizar las activaciones.\n",
    "     - **Inicialización adecuada:** Escoger inicializaciones de parámetros que eviten la amplificación excesiva o la atenuación de la señal.\n",
    "\n",
    "2. **Aumento en la complejidad computacional y en el uso de memoria:**\n",
    "   - **Riesgo:**  \n",
    "     Los ciclos dinámicos implican múltiples iteraciones internas en cada paso temporal, lo que incrementa el costo computacional y la memoria necesaria para almacenar las activaciones y gradientes durante la retropropagación.\n",
    "   - **Estrategias de mitigación:**\n",
    "     - **Limitar el número de iteraciones:** Establecer un número fijo y moderado de pasos iterativos en el ciclo para balancear refinamiento y costo computacional.\n",
    "     - **Detección de convergencia:** Implementar un criterio de parada temprana basado en la convergencia de las activaciones, de modo que se realicen únicamente las iteraciones necesarias.\n",
    "     - **Truncamiento de backpropagation through time (BPTT):** En contextos recurrentes, limitar la propagación de gradientes a un número fijo de pasos para evitar el almacenamiento excesivo de información."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e917bd-4c83-4caa-b3de-98cd392d9bbe",
   "metadata": {},
   "source": [
    "### **Pregunta 7**\n",
    "\n",
    "En *knowledge distillation* se transfiere el conocimiento de un modelo complejo y grande (*teacher*) a uno más pequeño (*student*). El procedimiento es el siguiente:\n",
    "\n",
    "1. **Generación de distribuciones suaves:**  \n",
    "   El *teacher* procesa una entrada y genera unos logits $ z_i^{(T)} $ para cada una de las 10 clases. Para convertir estos logits en una distribución de probabilidad \"suave\", se utiliza la función *softmax* con un parámetro de temperatura $\\tau$. Esto se escribe como:\n",
    "   $$\n",
    "   p_i^{(T)} = \\frac{\\exp\\left(z_i^{(T)}/\\tau\\right)}{\\sum_{j=1}^{10} \\exp\\left(z_j^{(T)}/\\tau\\right)}.\n",
    "   $$\n",
    "   El efecto de $\\tau > 1$ es suavizar la distribución, revelando relaciones entre clases que no se notarían con una temperatura de 1.\n",
    "\n",
    "2. **Imitación por el student:**  \n",
    "   El *student* genera sus propios logits $ z_i^{(S)} $ y se le aplica la misma función *softmax* con la misma temperatura:\n",
    "   $$\n",
    "   p_i^{(S)} = \\frac{\\exp\\left(z_i^{(S)}/\\tau\\right)}{\\sum_{j=1}^{10} \\exp\\left(z_j^{(S)}/\\tau\\right)}.\n",
    "   $$\n",
    "\n",
    "3. **Cálculo de la pérdida:**  \n",
    "   El objetivo es que la salida del *student* imite la del *teacher*. Para ello se utiliza la *Cross Entropy* entre la distribución del *teacher* (soft labels) y la del *student*. La fórmula exacta de la pérdida es:\n",
    "   $$\n",
    "   L_{KD} = -\\tau^2 \\sum_{i=1}^{10} p_i^{(T)} \\log\\left(p_i^{(S)}\\right).\n",
    "   $$\n",
    "   Aquí, el factor $\\tau^2$ se incluye para compensar la escala de los gradientes cuando se utiliza una temperatura alta. Esta pérdida mide cuán cercana es la distribución predicha por el *student* a la distribución \"suave\" del *teacher*.\n",
    "\n",
    "\n",
    "El siguiente fragmento de código ilustra el cálculo de la pérdida en un entorno de PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fbeaa2-45d8-495c-a048-f1929e5eac48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def knowledge_distillation_loss(student_logits, teacher_logits, temperature):\n",
    "    \"\"\"\n",
    "    Calcula la pérdida de distillation usando la entropía cruzada entre las distribuciones suavizadas.\n",
    "    \n",
    "    Args:\n",
    "        student_logits (Tensor): Logits del modelo student de tamaño (B, 10).\n",
    "        teacher_logits (Tensor): Logits del modelo teacher de tamaño (B, 10).\n",
    "        temperature (float): Parámetro de temperatura τ.\n",
    "    \n",
    "    Returns:\n",
    "        Tensor: Valor de la pérdida.\n",
    "    \"\"\"\n",
    "    # Obtener las distribuciones de probabilidad suaves\n",
    "    teacher_probs = F.softmax(teacher_logits / temperature, dim=1)\n",
    "    student_log_probs = F.log_softmax(student_logits / temperature, dim=1)\n",
    "    \n",
    "    # Calcular la pérdida (KL Divergence equivale a la Cross Entropy en este caso)\n",
    "    loss = F.kl_div(student_log_probs, teacher_probs, reduction='batchmean') * (temperature ** 2)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98289b9e-aa16-4552-86f3-33b08a04e94e",
   "metadata": {},
   "source": [
    "En este ejemplo se usa la divergencia KL, que es equivalente a minimizar la entropía cruzada cuando se proporcionan las distribuciones suaves del teacher."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c077885d-d850-462e-91bb-632fe55ec2d3",
   "metadata": {},
   "source": [
    "#### Estimación de memoria en el paso forward y backward\n",
    "\n",
    "Supongamos que el modelo *student* tiene $ M_s $ parámetros y se evalúa en *minibatches* de tamaño $ B $. Es importante distinguir entre la memoria ocupada por los parámetros y la memoria utilizada para almacenar las activaciones y gradientes durante el entrenamiento.\n",
    "\n",
    "##### **El paso forward  (activaciones):**\n",
    "\n",
    "- **Parámetros:**  \n",
    "  El modelo *student* tiene $ M_s $ parámetros, y cada uno (suponiendo 32 bits, o 4 bytes) ocupará:\n",
    "  $$\n",
    "  \\text{Memoria de parámetros} \\approx M_s \\times 4 \\quad \\text{(bytes)}.\n",
    "  $$\n",
    "\n",
    "- **Activaciones:**  \n",
    "  Durante el forward pass, se deben almacenar las activaciones intermedias de cada capa para cada muestra del minibatch. Si bien el tamaño exacto depende de la arquitectura, se puede asumir que la memoria para activaciones es proporcional al tamaño del minibatch y a la “complejidad” del modelo. De forma simplificada:\n",
    "  $$\n",
    "  \\text{Memoria activaciones} \\sim B \\times \\alpha \\, M_s,\n",
    "  $$\n",
    "  donde $\\alpha$ es un factor que depende del número de capas y la arquitectura (por ejemplo, si cada parámetro tiene una activación asociada o si se deben almacenar activaciones intermedias de mayor dimensión).\n",
    "\n",
    "##### **El paso backward (gradientes):**\n",
    "\n",
    "Durante el backward pass se deben almacenar:\n",
    "- Los gradientes de cada parámetro (del mismo orden que $ M_s $).\n",
    "- Los gradientes de las activaciones intermedias, lo que puede duplicar (o aumentar) el requerimiento de memoria respecto al forward.\n",
    "\n",
    "En términos aproximados:\n",
    "$$\n",
    "\\text{Memoria backward} \\sim \\text{Memoria activaciones} + \\text{Memoria gradientes} \\approx 2 \\times (B \\times \\alpha \\, M_s).\n",
    "$$\n",
    "Es decir, se puede estimar que el backward pass requiere aproximadamente el doble de la memoria que el forward pass, aunque este factor puede variar según la implementación y la arquitectura.\n",
    "\n",
    "##### Comparación con el modelo *teacher*\n",
    "\n",
    "Si el modelo *teacher* tiene $ M_t $ parámetros, y dado que $ M_t \\gg M_s $:\n",
    "- **Paso forward :**  \n",
    "  La memoria para almacenar activaciones se escala aproximadamente como:\n",
    "  $$\n",
    "  \\text{Memoria activaciones (teacher)} \\sim B \\times \\alpha \\, M_t,\n",
    "  $$\n",
    "  lo que es mucho mayor que para el *student*.\n",
    "  \n",
    "- **Paso backward:**  \n",
    "  Similarmente, el requerimiento de memoria para almacenar gradientes se escala con $ M_t $. Por lo tanto:\n",
    "  $$\n",
    "  \\text{Memoria backward (teacher)} \\sim 2 \\times (B \\times \\alpha \\, M_t).\n",
    "  $$\n",
    "\n",
    "##### Relación entre reducción de memoria e inferencia\n",
    "\n",
    "Reducir el número de parámetros de $ M_t $ a $ M_s $ implica:\n",
    "- **Menor almacenamiento de activaciones y gradientes:**  \n",
    "  La memoria requerida para el forward y backward pass se reduce proporcionalmente al factor $ \\frac{M_s}{M_t} $.\n",
    "\n",
    "- **Inferencia más rápida:**  \n",
    "  Un modelo con menos parámetros no solo requiere menos memoria, sino que también necesita menos operaciones de cómputo durante la inferencia. Esto se traduce en tiempos de respuesta más rápidos y en una menor demanda de recursos computacionales, lo cual es fundamental para la implementación en dispositivos con recursos limitados.\n",
    "\n",
    "A modo de ejemplo, supongamos que cada parámetro ocupa 4 bytes. Podemos definir una función para estimar la memoria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4a5287-15ee-4bc5-ba44-2f35916900c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimar_memoria(M, B, factor_activacion=1.0, bytes_por_param=4):\n",
    "    \"\"\"\n",
    "    Estima la memoria necesaria para un modelo con M parámetros y un minibatch de tamaño B.\n",
    "    \n",
    "    Args:\n",
    "        M (int): Número de parámetros del modelo.\n",
    "        B (int): Tamaño del minibatch.\n",
    "        factor_activacion (float): Factor para estimar el tamaño relativo de las activaciones respecto a M.\n",
    "        bytes_por_param (int): Bytes por parámetro (por defecto 4 para 32 bits).\n",
    "        \n",
    "    Returns:\n",
    "        dict: Memoria estimada en bytes para parámetros, activaciones (forward) y backward.\n",
    "    \"\"\"\n",
    "    mem_parametros = M * bytes_por_param\n",
    "    mem_forward = B * factor_activacion * M * bytes_por_param\n",
    "    mem_backward = 2 * mem_forward  # Aproximación: doble de activaciones (para activaciones y gradientes)\n",
    "    \n",
    "    return {\n",
    "        \"parametros\": mem_parametros,\n",
    "        \"forward\": mem_forward,\n",
    "        \"backward\": mem_backward\n",
    "    }\n",
    "\n",
    "# Ejemplo:\n",
    "Ms = 10**6      # Modelo student con 1 millón de parámetros\n",
    "Mt = 10**8      # Modelo teacher con 100 millones de parámetros\n",
    "B = 32          # Tamaño del minibatch\n",
    "\n",
    "mem_student = estimar_memoria(Ms, B)\n",
    "mem_teacher = estimar_memoria(Mt, B)\n",
    "\n",
    "print(\"Memoria estimada para el modelo student:\")\n",
    "print(mem_student)\n",
    "print(\"\\nMemoria estimada para el modelo teacher:\")\n",
    "print(mem_teacher)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4e1d8d-28e6-423e-8148-add76171f4dd",
   "metadata": {},
   "source": [
    "En este ejemplo se puede observar cómo la memoria para el modelo teacher es sustancialmente mayor que para el student, tanto en el paso forward como en el paso backward.\n",
    "\n",
    "> Nota: La memoria requerida durante el paso forward  es proporcional al tamaño del minibatch $B$ y al número de parámetros $M$ del modelo, es decir, aproximadamente $B \\times \\alpha \\, M$. \n",
    "Durante el paso backward  se requiere almacenar además los gradientes, lo que puede duplicar la memoria necesaria. Comparando un modelo teacher con $M_t$ parámetros con un modelo student de $M_s$ parámetros, la reducción de memoria es aproximadamente proporcional a $\\frac{M_s}{M_t}$, lo que repercute en inferencias más rápidas y en una menor demanda de recursos computacionales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10944a1d-9af8-43c4-a23f-c7faada9f9f2",
   "metadata": {},
   "source": [
    "### **Pregunta 8**\n",
    "\n",
    "#### **Diseño del modelo Seq2Seq**\n",
    "\n",
    "Un modelo **Seq2Seq** clásico para traducción (o tareas similares) consta de dos módulos:\n",
    "\n",
    "- **Encoder:** Una red recurrente (por ejemplo, LSTM) que procesa la secuencia de entrada y genera una serie de estados ocultos.  \n",
    "- **Decoder:** Otra red recurrente que, paso a paso, genera la secuencia de salida. En cada paso se utiliza la información del *encoder* para mejorar la generación.\n",
    "\n",
    "El *encoder* transforma la entrada $ \\mathbf{x} = (x_1, x_2, \\dots, x_{T_{enc}}) $ en una secuencia de estados ocultos:\n",
    "$$\n",
    "\\{h_1, h_2, \\dots, h_{T_{enc}}\\}.\n",
    "$$\n",
    "El *decoder* genera la secuencia de salida $ \\mathbf{y} = (y_1, y_2, \\dots, y_{T_{dec}}) $ utilizando su estado oculto y, en este caso, un **mecanismo de atención**.\n",
    "\n",
    "### 2. Implementación del mecanismo de atención\n",
    "\n",
    "Entre los esquemas más conocidos se encuentran el de **Luong** y el de **Bahdanau**. En este ejemplo se usa la **atención de Luong** (global) con la variante *general*.\n",
    "\n",
    "#### Fórmulas de cálculo\n",
    "\n",
    "- **Puntuación (score) de atención:**  \n",
    "  Para cada paso de decodificación $t$ y cada estado del encoder $ h_i $, se calcula:\n",
    "  $$\n",
    "  \\text{score}(s_t, h_i) = s_t^\\top W_a h_i,\n",
    "  $$\n",
    "  donde:\n",
    "  - $ s_t $ es el estado oculto del decoder en el paso $ t $.\n",
    "  - $ h_i $ es el estado oculto del encoder en la posición $ i $.\n",
    "  - $ W_a $ es una matriz de parámetros a aprender.\n",
    "\n",
    "- **Normalización (distribución atencional):**  \n",
    "  Se aplica la función *softmax* a los scores para obtener los pesos:\n",
    "  $$\n",
    "  \\alpha_{t,i} = \\frac{\\exp\\left(\\text{score}(s_t, h_i)\\right)}{\\sum_{j=1}^{T_{enc}} \\exp\\left(\\text{score}(s_t, h_j)\\right)}.\n",
    "  $$\n",
    "\n",
    "- **Vector de contexto:**  \n",
    "  Se calcula como la suma ponderada de los estados del encoder:\n",
    "  $$\n",
    "  c_t = \\sum_{i=1}^{T_{enc}} \\alpha_{t,i} h_i.\n",
    "  $$\n",
    "\n",
    "- **Integración en el decodificador:**  \n",
    "  El vector de contexto se concatena con el estado del decoder (o con el embedding de la entrada) para generar la predicción. Una forma común es:\n",
    "  $$\n",
    "  \\tilde{s_t} = \\tanh(W_c [c_t; s_t]),\n",
    "  $$\n",
    "  y la predicción final se obtiene aplicando una capa lineal y *softmax*:\n",
    "  $$\n",
    "  y_t = \\text{softmax}(W_o \\tilde{s_t}).\n",
    "  $$\n",
    "\n",
    "\n",
    "El siguiente código ilustra un modelo Seq2Seq con atención de Luong:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967cfca1-f781-4939-8e68-f0c91af394ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# --- Encoder ---\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hidden_dim, n_layers=1, dropout=0.5):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, hidden_dim, n_layers, dropout=dropout)\n",
    "    \n",
    "    def forward(self, src):\n",
    "        # src: (src_len, batch_size)\n",
    "        embedded = self.embedding(src)  # (src_len, batch_size, emb_dim)\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        # outputs: (src_len, batch_size, hidden_dim)\n",
    "        return outputs, hidden, cell\n",
    "\n",
    "# --- Atención de Luong ---\n",
    "class LuongAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(LuongAttention, self).__init__()\n",
    "        # Usamos una proyección lineal para la versión \"general\"\n",
    "        self.attn = nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "    def forward(self, decoder_hidden, encoder_outputs):\n",
    "        # decoder_hidden: (1, batch_size, hidden_dim)\n",
    "        # encoder_outputs: (src_len, batch_size, hidden_dim)\n",
    "        # Transformamos los estados del encoder\n",
    "        encoder_transformed = self.attn(encoder_outputs)  # (src_len, batch_size, hidden_dim)\n",
    "        # Preparamos el estado del decoder\n",
    "        decoder_hidden = decoder_hidden.squeeze(0)  # (batch_size, hidden_dim)\n",
    "        # Transponemos encoder_transformed para bmm\n",
    "        encoder_transformed = encoder_transformed.permute(1, 2, 0)  # (batch_size, hidden_dim, src_len)\n",
    "        # Reshape del estado del decoder para bmm: (batch_size, 1, hidden_dim)\n",
    "        decoder_hidden = decoder_hidden.unsqueeze(1)\n",
    "        # Cálculo de scores: (batch_size, 1, src_len)\n",
    "        scores = torch.bmm(decoder_hidden, encoder_transformed).squeeze(1)  # (batch_size, src_len)\n",
    "        \n",
    "        # Normalización para obtener distribución atencional\n",
    "        attn_weights = F.softmax(scores, dim=1)  # (batch_size, src_len)\n",
    "        \n",
    "        # Cálculo del vector de contexto: suma ponderada de los estados del encoder\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 1)  # (batch_size, src_len, hidden_dim)\n",
    "        attn_weights = attn_weights.unsqueeze(1)  # (batch_size, 1, src_len)\n",
    "        context = torch.bmm(attn_weights, encoder_outputs).squeeze(1)  # (batch_size, hidden_dim)\n",
    "        \n",
    "        return context, attn_weights\n",
    "\n",
    "# --- Decoder ---\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hidden_dim, n_layers=1, dropout=0.5):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim + hidden_dim, hidden_dim, n_layers, dropout=dropout)\n",
    "        self.attention = LuongAttention(hidden_dim)\n",
    "        # La capa final combina el estado del decoder y el contexto\n",
    "        self.fc_out = nn.Linear(hidden_dim * 2, output_dim)\n",
    "    \n",
    "    def forward(self, input, hidden, cell, encoder_outputs):\n",
    "        # input: (batch_size) token de entrada en el paso actual\n",
    "        input = input.unsqueeze(0)  # (1, batch_size)\n",
    "        embedded = self.embedding(input)  # (1, batch_size, emb_dim)\n",
    "        \n",
    "        # Se calcula la atención usando el último estado del decoder\n",
    "        context, attn_weights = self.attention(hidden[-1].unsqueeze(0), encoder_outputs)\n",
    "        context = context.unsqueeze(0)  # (1, batch_size, hidden_dim)\n",
    "        \n",
    "        # Concatenamos el embedding y el vector de contexto\n",
    "        lstm_input = torch.cat((embedded, context), dim=2)  # (1, batch_size, emb_dim + hidden_dim)\n",
    "        output, (hidden, cell) = self.lstm(lstm_input, (hidden, cell))\n",
    "        \n",
    "        # Combinamos la salida del decoder y el contexto para predecir la siguiente palabra\n",
    "        output = output.squeeze(0)   # (batch_size, hidden_dim)\n",
    "        context = context.squeeze(0) # (batch_size, hidden_dim)\n",
    "        prediction = self.fc_out(torch.cat((output, context), dim=1))  # (batch_size, output_dim)\n",
    "        \n",
    "        return prediction, hidden, cell, attn_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605fcc24-5e71-43d9-b7d4-6ff70288849c",
   "metadata": {},
   "source": [
    "**Proceso de decodificación con atención**\n",
    "\n",
    ">1. **Entrada del token:** Se toma el token actual (ya sea la palabra real en *teacher forcing* o la generada en pasos previos).\n",
    ">2. **Embedding:** Se obtiene su representación embebida.\n",
    ">3. **Cálculo de atención:**  \n",
    "    - Se utiliza el último estado del decoder $ s_t $ para calcular los scores con cada estado $ h_i $ del encoder mediante:\n",
    "     $$\n",
    "     \\text{score}(s_t, h_i) = s_t^\\top W_a h_i.\n",
    "     $$\n",
    "    - Se normalizan estos scores con softmax:\n",
    "     $$\n",
    "     \\alpha_{t,i} = \\frac{\\exp(\\text{score}(s_t, h_i))}{\\sum_{j=1}^{T_{enc}} \\exp(\\text{score}(s_t, h_j))}.\n",
    "     $$\n",
    "    - Se obtiene el vector de contexto:\n",
    "     $$\n",
    "     c_t = \\sum_{i=1}^{T_{enc}} \\alpha_{t,i} h_i.\n",
    "     $$\n",
    "> 4. **Integración en el LSTM del decoder:**  \n",
    "   Se concatena el embedding del token y $ c_t $ para alimentar la LSTM y actualizar el estado.\n",
    ">5. **Predicción:** Finalmente, se combina la salida del decoder y el contexto para predecir el siguiente token."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b946e756-24f3-4834-918d-22181cf65b3a",
   "metadata": {},
   "source": [
    "#### Reducción del desvanecimiento de gradiente\n",
    "\n",
    "El mecanismo de atención ayuda a mitigar el **desvanecimiento de gradiente** en redes recurrentes largas cuando:\n",
    "\n",
    "- **Secuencias largas:** Al permitir al decoder acceder directamente a cualquier estado del encoder, se evita la dependencia exclusiva del estado final del encoder. Esto facilita que el gradiente fluya a lo largo de la secuencia, mejorando la propagación del error en pasos lejanos.\n",
    "\n",
    "#### Ventajas en tareas multimodales\n",
    "\n",
    "1. **Focalización selectiva:**  \n",
    "   En tareas como la descripción de imágenes, la atención permite al modelo concentrarse en regiones específicas de la imagen relevantes para cada palabra generada, mejorando la coherencia y relevancia de la descripción.\n",
    "\n",
    "2. **Interpretabilidad:**  \n",
    "   Los pesos de atención ofrecen una pista sobre qué partes de la entrada (por ejemplo, regiones de la imagen) influyen en la salida, lo que permite visualizar y entender el proceso de toma de decisiones del modelo.\n",
    "\n",
    "#### Limitación concreta\n",
    "\n",
    "- **Complejidad computacional:**  \n",
    "  En tareas multimodales con entradas de alta dimensión (como imágenes de alta resolución o videos), el cálculo de la atención (especialmente si se realiza de forma global) puede resultar costoso en términos de tiempo de cómputo y memoria. Esto puede dificultar la implementación en entornos con recursos limitados o en aplicaciones en tiempo real.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0a1d661",
   "metadata": {},
   "source": [
    "### Seq2seq\n",
    "\n",
    "Un modelo secuencia a secuencia (Seq2Seq) es una arquitectura de red neuronal diseñada para transformar una secuencia de entrada en una secuencia de salida, y es especialmente útil para tareas donde la longitud de las secuencias de entrada y salida puede diferir. Los modelos Seq2Seq son comúnmente utilizados en aplicaciones como traducción automática, resumen de texto, y generación de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c74e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# S: Símbolo que muestra el inicio de la entrada de decodificación\n",
    "# E: Símbolo que muestra el inicio de la salida de decodificación\n",
    "# P: Símbolo que llenará la secuencia en blanco si el tamaño de los datos del lote actual es menor que los pasos de tiempo\n",
    "\n",
    "def make_batch():\n",
    "    input_batch, output_batch, target_batch = [], [], []\n",
    "\n",
    "    for seq in seq_data:\n",
    "        for i in range(2):\n",
    "            seq[i] = seq[i] + 'P' * (n_step - len(seq[i]))\n",
    "\n",
    "        input_seq = [num_dic[n] for n in seq[0]]\n",
    "        output_seq = [num_dic[n] for n in ('S' + seq[1])]\n",
    "        target = [num_dic[n] for n in (seq[1] + 'E')]\n",
    "\n",
    "        input_batch.append(np.eye(n_class)[input_seq])\n",
    "        output_batch.append(np.eye(n_class)[output_seq])\n",
    "        target_batch.append(target)  # no es one-hot\n",
    "\n",
    "    # Convertir listas a numpy arrays antes de convertir a tensores\n",
    "    input_batch = np.array(input_batch)\n",
    "    output_batch = np.array(output_batch)\n",
    "    target_batch = np.array(target_batch)\n",
    "\n",
    "    # crear tensor\n",
    "    return torch.FloatTensor(input_batch), torch.FloatTensor(output_batch), torch.LongTensor(target_batch)\n",
    "\n",
    "# crear lote de prueba\n",
    "def make_testbatch(input_word):\n",
    "    input_w = input_word + 'P' * (n_step - len(input_word))\n",
    "    input_seq = [num_dic[n] for n in input_w]\n",
    "    output_seq = [num_dic[n] for n in 'S' + 'P' * n_step]\n",
    "\n",
    "    input_batch = np.eye(n_class)[input_seq]\n",
    "    output_batch = np.eye(n_class)[output_seq]\n",
    "\n",
    "    # Convertir a numpy arrays antes de convertir a tensores\n",
    "    input_batch = np.array(input_batch)\n",
    "    output_batch = np.array(output_batch)\n",
    "\n",
    "    return torch.FloatTensor(input_batch).unsqueeze(0), torch.FloatTensor(output_batch).unsqueeze(0)\n",
    "\n",
    "# Modelo\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.enc_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, num_layers=2, dropout=0.5)\n",
    "        self.dec_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, num_layers=2, dropout=0.5)\n",
    "        self.fc = nn.Linear(n_hidden, n_class)\n",
    "\n",
    "    def forward(self, enc_input, enc_hidden, dec_input):\n",
    "        enc_input = enc_input.transpose(0, 1)  # [n_step, tamaño_lote, n_class]\n",
    "        dec_input = dec_input.transpose(0, 1)  # [n_step, tamaño_lote, n_class]\n",
    "\n",
    "        _, enc_states = self.enc_cell(enc_input, enc_hidden)\n",
    "        outputs, _ = self.dec_cell(dec_input, enc_states)\n",
    "\n",
    "        modelo = self.fc(outputs)  # [n_step+1, tamaño_lote, n_class]\n",
    "        return modelo\n",
    "\n",
    "# Parámetros y datos\n",
    "n_step = 5\n",
    "n_hidden = 128\n",
    "\n",
    "char_arr = [c for c in 'SEPabcdefghijklmnopqrstuvwxyz']\n",
    "num_dic = {n: i for i, n in enumerate(char_arr)}\n",
    "seq_data = [['man', 'women'], ['black', 'white'], ['king', 'queen'], ['girl', 'boy'], ['up', 'down'], ['high', 'low']]\n",
    "\n",
    "n_class = len(num_dic)\n",
    "tamaño_lote = len(seq_data)\n",
    "\n",
    "# Crear modelo, criterio y optimizador\n",
    "modelo = Seq2Seq()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(modelo.parameters(), lr=0.001)\n",
    "\n",
    "# Crear batch de entrenamiento\n",
    "input_batch, output_batch, target_batch = make_batch()\n",
    "\n",
    "# Entrenamiento\n",
    "for epoch in range(5000):\n",
    "    # Crear estado oculto [num_layers, tamaño_lote, n_hidden]\n",
    "    hidden = torch.zeros(2, tamaño_lote, n_hidden)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    output = modelo(input_batch, hidden, output_batch)\n",
    "    output = output.transpose(0, 1)  # [tamaño_lote, n_step+1, n_class]\n",
    "    loss = 0\n",
    "    for i in range(len(target_batch)):\n",
    "        loss += criterion(output[i], target_batch[i])\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print('Época:', '%04d' % (epoch + 1), 'costo =', '{:.6f}'.format(loss.item()))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Función para traducir una palabra\n",
    "def translate(word):\n",
    "    input_batch, output_batch = make_testbatch(word)\n",
    "    hidden = torch.zeros(2, 1, n_hidden)\n",
    "    output = modelo(input_batch, hidden, output_batch)\n",
    "    predict = output.data.max(2, keepdim=True)[1]\n",
    "    decoded = [char_arr[i] for i in predict]\n",
    "    end = decoded.index('E')\n",
    "    translated = ''.join(decoded[:end])\n",
    "    return translated.replace('P', '')\n",
    "\n",
    "# Pruebas\n",
    "print('test')\n",
    "print('man ->', translate('man'))\n",
    "print('mans ->', translate('mans'))\n",
    "print('king ->', translate('king'))\n",
    "print('black ->', translate('black'))\n",
    "print('upp ->', translate('upp'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5ae88d",
   "metadata": {},
   "source": [
    "### Greedy, beam search y selección aleatoria con temperatura\n",
    "\n",
    "Podemos implementar las estrategias de decodificación greedy, beam search y selección aleatoria con temperatura, podemos modificar el código dado agregando funciones específicas para cada método de decodificación.\n",
    "\n",
    "**Estrategia greedy**\n",
    "\n",
    "La estrategia Greedy selecciona el token con la mayor probabilidad en cada paso de decodificación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6b79a4-579b-4ed9-9573-b8bb2cb8caf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# S: Símbolo que muestra el inicio de la entrada de decodificación\n",
    "# E: Símbolo que muestra el inicio de la salida de decodificación\n",
    "# P: Símbolo que llenará la secuencia en blanco si el tamaño de los datos del lote actual es menor que los pasos de tiempo\n",
    "\n",
    "def make_batch():\n",
    "    input_batch, output_batch, target_batch = [], [], []\n",
    "\n",
    "    for seq in seq_data:\n",
    "        for i in range(2):\n",
    "            seq[i] = seq[i] + 'P' * (n_step - len(seq[i]))\n",
    "\n",
    "        input_seq = [num_dic[n] for n in seq[0]]\n",
    "        output_seq = [num_dic[n] for n in ('S' + seq[1])]\n",
    "        target = [num_dic[n] for n in (seq[1] + 'E')]\n",
    "\n",
    "        input_batch.append(np.eye(n_class)[input_seq])\n",
    "        output_batch.append(np.eye(n_class)[output_seq])\n",
    "        target_batch.append(target)  # no es one-hot\n",
    "\n",
    "    # Convertir listas a numpy arrays antes de convertir a tensores\n",
    "    input_batch = np.array(input_batch)\n",
    "    output_batch = np.array(output_batch)\n",
    "    target_batch = np.array(target_batch)\n",
    "\n",
    "    # Crear tensor\n",
    "    return torch.FloatTensor(input_batch), torch.FloatTensor(output_batch), torch.LongTensor(target_batch)\n",
    "\n",
    "# Crear lote de prueba\n",
    "def make_testbatch(input_word):\n",
    "    input_batch, output_batch = [], []\n",
    "\n",
    "    input_w = input_word + 'P' * (n_step - len(input_word))\n",
    "    input_seq = [num_dic[n] for n in input_w]\n",
    "    output_seq = [num_dic[n] for n in 'S' + 'P' * n_step]\n",
    "\n",
    "    input_batch = np.eye(n_class)[input_seq]\n",
    "    output_batch = np.eye(n_class)[output_seq]\n",
    "\n",
    "    # Convertir a numpy arrays antes de convertir a tensores\n",
    "    input_batch = np.array(input_batch)\n",
    "    output_batch = np.array(output_batch)\n",
    "\n",
    "    return torch.FloatTensor(input_batch).unsqueeze(0), torch.FloatTensor(output_batch).unsqueeze(0)\n",
    "\n",
    "# Modelo\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.enc_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, num_layers=2, dropout=0.5)\n",
    "        self.dec_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, num_layers=2, dropout=0.5)\n",
    "        self.fc = nn.Linear(n_hidden, n_class)\n",
    "\n",
    "    def forward(self, enc_input, enc_hidden, dec_input):\n",
    "        enc_input = enc_input.transpose(0, 1)  # [max_len, tamaño_lote, n_class]\n",
    "        dec_input = dec_input.transpose(0, 1)  # [max_len, tamaño_lote, n_class]\n",
    "\n",
    "        # enc_states : [num_layers, tamaño_lote, n_hidden]\n",
    "        _, enc_states = self.enc_cell(enc_input, enc_hidden)\n",
    "        # outputs : [max_len, tamaño_lote, n_hidden]\n",
    "        outputs, _ = self.dec_cell(dec_input, enc_states)\n",
    "\n",
    "        modelo = self.fc(outputs)  # [max_len, tamaño_lote, n_class]\n",
    "        return modelo, enc_states\n",
    "\n",
    "# Parámetros, diccionarios y datos\n",
    "n_step = 5\n",
    "n_hidden = 128\n",
    "\n",
    "char_arr = [c for c in 'SEPabcdefghijklmnopqrstuvwxyz']\n",
    "num_dic = {n: i for i, n in enumerate(char_arr)}\n",
    "seq_data = [['man', 'women'], ['black', 'white'], ['king', 'queen'], ['girl', 'boy'], ['up', 'down'], ['high', 'low']]\n",
    "\n",
    "n_class = len(num_dic)\n",
    "tamaño_lote = len(seq_data)\n",
    "\n",
    "# Crear modelo, criterio y optimizador\n",
    "modelo = Seq2Seq()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(modelo.parameters(), lr=0.001)\n",
    "\n",
    "input_batch, output_batch, target_batch = make_batch()\n",
    "\n",
    "# Entrenamiento\n",
    "for epoch in range(5000):\n",
    "    modelo.train()\n",
    "    # Crear forma oculta [num_layers, tamaño_lote, n_hidden]\n",
    "    hidden = torch.zeros(2, tamaño_lote, n_hidden)  # 2 capas\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    # Forward pass\n",
    "    output, _ = modelo(input_batch, hidden, output_batch)\n",
    "    # output : [max_len, tamaño_lote, n_class]\n",
    "    output = output.transpose(0, 1)  # [tamaño_lote, max_len, n_class]\n",
    "    loss = 0\n",
    "    for i in range(tamaño_lote):\n",
    "        loss += criterion(output[i], target_batch[i])\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print('Época:', '%04d' % (epoch + 1), 'costo =', '{:.6f}'.format(loss.item()))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Prueba con decodificación greedy\n",
    "def translate(word):\n",
    "    modelo.eval()  # Modo evaluación\n",
    "    with torch.no_grad():  # Desactivar cálculo de gradientes\n",
    "        input_w = word + 'P' * (n_step - len(word))\n",
    "        input_seq = [num_dic[n] for n in input_w]\n",
    "        input_batch = np.eye(n_class)[input_seq]\n",
    "        input_batch = torch.FloatTensor(input_batch).unsqueeze(0)  # [1, max_len, n_class]\n",
    "\n",
    "        # Inicializar el estado oculto del codificador\n",
    "        hidden = torch.zeros(2, 1, n_hidden)  # 2 capas\n",
    "\n",
    "        # Codificar la entrada\n",
    "        enc_input = input_batch.transpose(0, 1)  # [max_len, 1, n_class]\n",
    "        _, enc_states = modelo.enc_cell(enc_input, hidden)\n",
    "\n",
    "        # Inicializar la entrada del decodificador con el símbolo de inicio 'S'\n",
    "        decoder_input = torch.zeros(1, 1, n_class)  # [1, 1, n_class]\n",
    "        decoder_input[0, 0, num_dic['S']] = 1.0\n",
    "\n",
    "        decoded = []\n",
    "        for _ in range(n_step + 1):  # +1 para incluir 'E'\n",
    "            # Decodificar paso a paso\n",
    "            output, enc_states = modelo.dec_cell(decoder_input, enc_states)\n",
    "            output = modelo.fc(output.squeeze(0))  # [1, n_class]\n",
    "\n",
    "            # Seleccionar el token con mayor probabilidad\n",
    "            _, topi = output.topk(1)  # [1]\n",
    "            next_token = topi.item()\n",
    "\n",
    "            # Obtener el carácter correspondiente\n",
    "            char = char_arr[next_token]\n",
    "            if char == 'E':\n",
    "                break\n",
    "            if char != 'P':  # Ignorar los rellenos\n",
    "                decoded.append(char)\n",
    "\n",
    "            # Preparar la siguiente entrada del decodificador\n",
    "            decoder_input = torch.zeros(1, 1, n_class)\n",
    "            decoder_input[0, 0, next_token] = 1.0\n",
    "\n",
    "        translated = ''.join(decoded)\n",
    "        return translated\n",
    "\n",
    "print('Prueba de decodificación greedy:')\n",
    "print('man ->', translate('man'))\n",
    "print('mans ->', translate('mans'))\n",
    "print('king ->', translate('king'))\n",
    "print('black ->', translate('black'))\n",
    "print('upp ->', translate('upp'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae18962-1071-4a87-9f6b-63d27d47cced",
   "metadata": {},
   "source": [
    "**Estrategia beam search**\n",
    "\n",
    "Beam Search mantiene las mejores k secuencias en cada paso, lo que permite explorar múltiples caminos en la decodificación y seleccionar la secuencia más probable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f34097-8d29-4b32-9301-fca30e49c2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# S: Símbolo que muestra el inicio de la entrada de decodificación\n",
    "# E: Símbolo que muestra el fin de la salida de decodificación\n",
    "# P: Símbolo que llenará la secuencia en blanco si el tamaño de los datos del lote actual es menor que los pasos de tiempo\n",
    "\n",
    "def make_batch():\n",
    "    input_batch, output_batch, target_batch = [], [], []\n",
    "\n",
    "    for seq in seq_data:\n",
    "        for i in range(2):\n",
    "            # Rellenar las secuencias con 'P' para alcanzar n_step\n",
    "            seq[i] = seq[i] + 'P' * (n_step - len(seq[i]))\n",
    "\n",
    "        input_seq = [num_dic[n] for n in seq[0]]\n",
    "        output_seq = [num_dic[n] for n in ('S' + seq[1])]\n",
    "        target = [num_dic[n] for n in (seq[1] + 'E')]\n",
    "\n",
    "        input_batch.append(np.eye(n_class)[input_seq])\n",
    "        output_batch.append(np.eye(n_class)[output_seq])\n",
    "        target_batch.append(target)  # No es one-hot\n",
    "\n",
    "    # Convertir listas a numpy arrays antes de convertir a tensores\n",
    "    input_batch = np.array(input_batch)\n",
    "    output_batch = np.array(output_batch)\n",
    "    target_batch = np.array(target_batch)\n",
    "\n",
    "    # Crear tensor\n",
    "    return torch.FloatTensor(input_batch), torch.FloatTensor(output_batch), torch.LongTensor(target_batch)\n",
    "\n",
    "# Crear lote de prueba\n",
    "def make_testbatch(input_word):\n",
    "    input_batch, output_batch = [], []\n",
    "\n",
    "    input_w = input_word + 'P' * (n_step - len(input_word))\n",
    "    input_seq = [num_dic[n] for n in input_w]\n",
    "    output_seq = [num_dic[n] for n in 'S' + 'P' * n_step]\n",
    "\n",
    "    input_batch = np.eye(n_class)[input_seq]\n",
    "    output_batch = np.eye(n_class)[output_seq]\n",
    "\n",
    "    # Convertir a numpy arrays antes de convertir a tensores\n",
    "    input_batch = np.array(input_batch)\n",
    "    output_batch = np.array(output_batch)\n",
    "\n",
    "    return torch.FloatTensor(input_batch).unsqueeze(0), torch.FloatTensor(output_batch).unsqueeze(0)\n",
    "\n",
    "# Modelo\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.enc_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, num_layers=2, dropout=0.5)\n",
    "        self.dec_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, num_layers=2, dropout=0.5)\n",
    "        self.fc = nn.Linear(n_hidden, n_class)\n",
    "\n",
    "    def forward(self, enc_input, enc_hidden, dec_input):\n",
    "        enc_input = enc_input.transpose(0, 1)  # [max_len, tamaño_lote, n_class]\n",
    "        dec_input = dec_input.transpose(0, 1)  # [max_len, tamaño_lote, n_class]\n",
    "\n",
    "        # enc_states : [num_layers, tamaño_lote, n_hidden]\n",
    "        _, enc_states = self.enc_cell(enc_input, enc_hidden)\n",
    "        # outputs : [max_len, tamaño_lote, n_hidden]\n",
    "        outputs, _ = self.dec_cell(dec_input, enc_states)\n",
    "\n",
    "        modelo = self.fc(outputs)  # [max_len, tamaño_lote, n_class]\n",
    "        return modelo, enc_states\n",
    "\n",
    "# Parámetros, diccionarios y datos\n",
    "n_step = 5\n",
    "n_hidden = 128\n",
    "\n",
    "char_arr = [c for c in 'SEPabcdefghijklmnopqrstuvwxyz']\n",
    "num_dic = {n: i for i, n in enumerate(char_arr)}\n",
    "seq_data = [['man', 'women'], ['black', 'white'], ['king', 'queen'],\n",
    "            ['girl', 'boy'], ['up', 'down'], ['high', 'low']]\n",
    "\n",
    "n_class = len(num_dic)\n",
    "tamaño_lote = len(seq_data)\n",
    "\n",
    "# Crear modelo, criterio y optimizador\n",
    "modelo = Seq2Seq()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(modelo.parameters(), lr=0.001)\n",
    "\n",
    "input_batch, output_batch, target_batch = make_batch()\n",
    "\n",
    "# Entrenamiento\n",
    "for epoch in range(5000):\n",
    "    modelo.train()\n",
    "    # Crear forma oculta [num_layers, tamaño_lote, n_hidden] (2 capas)\n",
    "    hidden = torch.zeros(2, tamaño_lote, n_hidden)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    # Forward pass\n",
    "    output, _ = modelo(input_batch, hidden, output_batch)\n",
    "    # output : [max_len, tamaño_lote, n_class] -> [tamaño_lote, max_len, n_class]\n",
    "    output = output.transpose(0, 1)\n",
    "    loss = 0\n",
    "    for i in range(tamaño_lote):\n",
    "        loss += criterion(output[i], target_batch[i])\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print('Época:', '%04d' % (epoch + 1), 'costo =', '{:.6f}'.format(loss.item()))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Prueba con decodificación beam search\n",
    "def translate_beam_search(word, beam_size=3, max_dec_steps=10):\n",
    "    modelo.eval()  # Modo evaluación\n",
    "    with torch.no_grad():  # Desactivar cálculo de gradientes\n",
    "        input_w = word + 'P' * (n_step - len(word))\n",
    "        input_seq = [num_dic.get(n, num_dic['P']) for n in input_w]\n",
    "        input_batch = np.eye(n_class)[input_seq]\n",
    "        input_batch = torch.FloatTensor(input_batch).unsqueeze(0)  # [1, max_len, n_class]\n",
    "\n",
    "        # Inicializar el estado oculto del codificador\n",
    "        hidden = torch.zeros(2, 1, n_hidden)  # 2 capas\n",
    "\n",
    "        # Codificar la entrada\n",
    "        enc_input = input_batch.transpose(0, 1)  # [max_len, 1, n_class]\n",
    "        _, enc_states = modelo.enc_cell(enc_input, hidden)\n",
    "\n",
    "        # Inicializar el haz con la secuencia inicial [S]\n",
    "        beam = [{\n",
    "            'sequence': [num_dic['S']],\n",
    "            'hidden': enc_states.clone(),\n",
    "            'score': 0.0\n",
    "        }]\n",
    "\n",
    "        completed_sequences = []\n",
    "\n",
    "        for _ in range(max_dec_steps):\n",
    "            new_beam = []\n",
    "            for seq in beam:\n",
    "                last_token = seq['sequence'][-1]\n",
    "                if last_token == num_dic['E']:\n",
    "                    completed_sequences.append(seq)\n",
    "                    continue\n",
    "\n",
    "                # Preparar la entrada del decodificador (one-hot)\n",
    "                decoder_input = torch.zeros(1, 1, n_class)\n",
    "                decoder_input[0, 0, last_token] = 1.0\n",
    "\n",
    "                # Obtener la salida del decodificador\n",
    "                dec_output, dec_hidden = modelo.dec_cell(decoder_input, seq['hidden'])\n",
    "                logits = modelo.fc(dec_output.squeeze(0))  # [1, n_class]\n",
    "                log_probs = nn.functional.log_softmax(logits, dim=1)  # [1, n_class]\n",
    "\n",
    "                topk_log_probs, topk_indices = torch.topk(log_probs, beam_size, dim=1)\n",
    "\n",
    "                for i in range(beam_size):\n",
    "                    token = topk_indices[0, i].item()\n",
    "                    score = seq['score'] + topk_log_probs[0, i].item()\n",
    "                    new_seq = seq['sequence'] + [token]\n",
    "                    new_hidden = dec_hidden.clone()\n",
    "                    new_beam.append({\n",
    "                        'sequence': new_seq,\n",
    "                        'hidden': new_hidden,\n",
    "                        'score': score\n",
    "                    })\n",
    "\n",
    "            # Ordenar y seleccionar las mejores secuencias del haz\n",
    "            new_beam = sorted(new_beam, key=lambda x: x['score'], reverse=True)\n",
    "            beam = new_beam[:beam_size]\n",
    "\n",
    "            # Si ya hay suficientes secuencias completadas, detener la búsqueda\n",
    "            if len(completed_sequences) >= beam_size:\n",
    "                break\n",
    "\n",
    "        # Si no hay secuencias completadas, se usan las actuales\n",
    "        if not completed_sequences:\n",
    "            completed_sequences = beam\n",
    "\n",
    "        # Seleccionar la mejor secuencia completada\n",
    "        completed_sequences = sorted(completed_sequences, key=lambda x: x['score'], reverse=True)\n",
    "        best_sequence = completed_sequences[0]['sequence']\n",
    "\n",
    "        # Convertir la secuencia de índices a caracteres\n",
    "        decoded = [char_arr[i] for i in best_sequence]\n",
    "\n",
    "        # Encontrar el índice del símbolo de fin 'E'\n",
    "        if 'E' in decoded:\n",
    "            end = decoded.index('E')\n",
    "            decoded = decoded[:end]\n",
    "\n",
    "        translated = ''.join([char for char in decoded if char not in ['S', 'P']])\n",
    "        return translated\n",
    "\n",
    "print('\\nPrueba de decodificación beam search:')\n",
    "print('man ->', translate_beam_search('man'))\n",
    "print('mans ->', translate_beam_search('mans'))\n",
    "print('king ->', translate_beam_search('king'))\n",
    "print('black ->', translate_beam_search('black'))\n",
    "print('upp ->', translate_beam_search('upp'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e705b50c-920d-4c30-89fe-0a2bcf1f7d36",
   "metadata": {},
   "source": [
    "**Selección aleatoria con temperatura**\n",
    "\n",
    "La selección aleatoria con temperatura ajusta las probabilidades de los tokens antes de muestrear de la distribución, permitiendo más exploración en la generación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeff0976",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# S: Símbolo que muestra el inicio de la entrada de decodificación\n",
    "# E: Símbolo que muestra el inicio de la salida de decodificación\n",
    "# P: Símbolo que llenará la secuencia en blanco si el tamaño de los datos del lote actual es menor que los pasos de tiempo\n",
    "\n",
    "def make_batch():\n",
    "    input_batch, output_batch, target_batch = [], [], []\n",
    "\n",
    "    for seq in seq_data:\n",
    "        for i in range(2):\n",
    "            seq[i] = seq[i] + 'P' * (n_step - len(seq[i]))\n",
    "\n",
    "        input_seq = [num_dic[n] for n in seq[0]]\n",
    "        output_seq = [num_dic[n] for n in ('S' + seq[1])]\n",
    "        target = [num_dic[n] for n in (seq[1] + 'E')]\n",
    "\n",
    "        input_batch.append(np.eye(n_class)[input_seq])\n",
    "        output_batch.append(np.eye(n_class)[output_seq])\n",
    "        target_batch.append(target)  # no es one-hot\n",
    "\n",
    "    # Convertir listas a numpy arrays antes de convertir a tensores\n",
    "    input_batch = np.array(input_batch)\n",
    "    output_batch = np.array(output_batch)\n",
    "    target_batch = np.array(target_batch)\n",
    "\n",
    "    # Crear tensor\n",
    "    return torch.FloatTensor(input_batch), torch.FloatTensor(output_batch), torch.LongTensor(target_batch)\n",
    "\n",
    "# Crear lote de prueba\n",
    "def make_testbatch(input_word):\n",
    "    input_batch, output_batch = [], []\n",
    "\n",
    "    input_w = input_word + 'P' * (n_step - len(input_word))\n",
    "    input_seq = [num_dic[n] for n in input_w]\n",
    "    output_seq = [num_dic[n] for n in 'S' + 'P' * n_step]\n",
    "\n",
    "    input_batch = np.eye(n_class)[input_seq]\n",
    "    output_batch = np.eye(n_class)[output_seq]\n",
    "\n",
    "    # Convertir a numpy arrays antes de convertir a tensores\n",
    "    input_batch = np.array(input_batch)\n",
    "    output_batch = np.array(output_batch)\n",
    "\n",
    "    return torch.FloatTensor(input_batch).unsqueeze(0), torch.FloatTensor(output_batch).unsqueeze(0)\n",
    "\n",
    "# Modelo\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.enc_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, num_layers=2, dropout=0.5)\n",
    "        self.dec_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, num_layers=2, dropout=0.5)\n",
    "        self.fc = nn.Linear(n_hidden, n_class)\n",
    "\n",
    "    def forward(self, enc_input, enc_hidden, dec_input):\n",
    "        # enc_input: [max_len (n_step), tamaño_lote, n_class]\n",
    "        # dec_input: [max_len (n_step), tamaño_lote, n_class]\n",
    "        enc_input = enc_input.transpose(0, 1)\n",
    "        dec_input = dec_input.transpose(0, 1)\n",
    "\n",
    "        # enc_states : [num_layers * num_directions, tamaño_lote, n_hidden]\n",
    "        _, enc_states = self.enc_cell(enc_input, enc_hidden)\n",
    "        # outputs : [max_len+1, tamaño_lote, n_hidden]\n",
    "        outputs, _ = self.dec_cell(dec_input, enc_states)\n",
    "\n",
    "        modelo = self.fc(outputs)  # [max_len+1, tamaño_lote, n_class]\n",
    "        return modelo\n",
    "\n",
    "# Parámetros, diccionarios y datos\n",
    "n_step = 5\n",
    "n_hidden = 128\n",
    "\n",
    "char_arr = [c for c in 'SEPabcdefghijklmnopqrstuvwxyz']\n",
    "num_dic = {n: i for i, n in enumerate(char_arr)}\n",
    "seq_data = [['man', 'women'], ['black', 'white'], ['king', 'queen'],\n",
    "            ['girl', 'boy'], ['up', 'down'], ['high', 'low']]\n",
    "\n",
    "n_class = len(num_dic)\n",
    "tamaño_lote = len(seq_data)\n",
    "\n",
    "# Crear modelo, criterio y optimizador\n",
    "modelo = Seq2Seq()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(modelo.parameters(), lr=0.001)\n",
    "\n",
    "input_batch, output_batch, target_batch = make_batch()\n",
    "\n",
    "# Entrenamiento\n",
    "for epoch in range(5000):\n",
    "    # Crear forma oculta [num_layers * num_directions, tamaño_lote, n_hidden] (2 capas)\n",
    "    hidden = torch.zeros(2, tamaño_lote, n_hidden)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    # input_batch: [tamaño_lote, n_step, n_class]\n",
    "    # output_batch: [tamaño_lote, n_step+1, n_class]\n",
    "    # target_batch: [tamaño_lote, n_step+1] (no es one-hot)\n",
    "    output = modelo(input_batch, hidden, output_batch)\n",
    "    # output: [n_step+1, tamaño_lote, n_class] -> [tamaño_lote, n_step+1, n_class]\n",
    "    output = output.transpose(0, 1)\n",
    "    loss = 0\n",
    "    for i in range(len(target_batch)):\n",
    "        loss += criterion(output[i], target_batch[i])\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print('Epoca:', '%04d' % (epoch + 1), 'costo =', '{:.6f}'.format(loss.item()))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Estrategias de Decodificación\n",
    "def greedy_decode(input_batch, hidden, output_batch):\n",
    "    output = modelo(input_batch, hidden, output_batch)\n",
    "    predict = output.data.max(2, keepdim=True)[1]  # Seleccionar dimensión n_class\n",
    "    return predict\n",
    "\n",
    "def beam_search_decode(input_batch, hidden, output_batch, beam_width=3):\n",
    "    output = modelo(input_batch, hidden, output_batch)\n",
    "    output = F.softmax(output, dim=2)  # Aplicar softmax para obtener probabilidades\n",
    "    sequences = [[list(), 1.0]]  # (secuencia, score)\n",
    "\n",
    "    for row in output.squeeze(1):  # Procesar la salida correspondiente\n",
    "        all_candidates = list()\n",
    "        for seq, score in sequences:\n",
    "            for j in range(len(row)):\n",
    "                candidate = [seq + [j], score * row[j].item()]  # Multiplicar probabilidades\n",
    "                all_candidates.append(candidate)\n",
    "        # Ordenar candidatos por score descendente\n",
    "        ordered = sorted(all_candidates, key=lambda tup: tup[1], reverse=True)\n",
    "        sequences = ordered[:beam_width]\n",
    "\n",
    "    best_sequence = sequences[0][0]\n",
    "    return torch.tensor(best_sequence, dtype=torch.long).view(1, -1, 1)\n",
    "\n",
    "def random_sample_with_temperature(output, temperature=1.0):\n",
    "    output = output.div(temperature).exp()\n",
    "    probs = F.softmax(output, dim=-1)\n",
    "    return torch.multinomial(probs.view(-1, probs.size(-1)), 1).view(output.size(0), output.size(1), -1)\n",
    "\n",
    "def decode_with_temperature(input_batch, hidden, output_batch, temperature=1.0):\n",
    "    output = modelo(input_batch, hidden, output_batch)\n",
    "    sampled_output = random_sample_with_temperature(output, temperature)\n",
    "    return sampled_output\n",
    "\n",
    "def translate(word, strategy='greedy', beam_width=3, temperature=1.0):\n",
    "    input_batch, output_batch = make_testbatch(word)\n",
    "    hidden = torch.zeros(2, 1, n_hidden)  # 2 capas\n",
    "\n",
    "    if strategy == 'greedy':\n",
    "        predict = greedy_decode(input_batch, hidden, output_batch)\n",
    "    elif strategy == 'beam_search':\n",
    "        predict = beam_search_decode(input_batch, hidden, output_batch, beam_width)\n",
    "    elif strategy == 'temperature':\n",
    "        predict = decode_with_temperature(input_batch, hidden, output_batch, temperature)\n",
    "\n",
    "    decoded = [char_arr[i] for i in predict.squeeze()]\n",
    "    if 'E' in decoded:\n",
    "        end = decoded.index('E')\n",
    "        translated = ''.join(decoded[:end])\n",
    "    else:\n",
    "        translated = ''.join(decoded)\n",
    "\n",
    "    return translated.replace('P', '')\n",
    "\n",
    "# Comparativa de decodificación\n",
    "words = ['man', 'mans', 'king', 'black', 'upp']\n",
    "\n",
    "print('Comparativa de decodificación:\\n')\n",
    "\n",
    "for word in words:\n",
    "    print(f'Palabra: {word}')\n",
    "    print(f'Greedy: {translate(word, strategy=\"greedy\")}')\n",
    "    print(f'Beam Search: {translate(word, strategy=\"beam_search\", beam_width=3)}')\n",
    "    print(f'Temperatura (T=1.0): {translate(word, strategy=\"temperature\", temperature=1.0)}')\n",
    "    print('---------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9d8228",
   "metadata": {},
   "source": [
    "### Ejercicios\n",
    "\n",
    "1 .Implementa un mecanismo de atención en el modelo Seq2Seq para mejorar la traducción.\n",
    "\n",
    "Instrucciones:\n",
    "\n",
    "- Añade una capa de atención al modelo Seq2Seq.\n",
    "- Modifica el método forward para incorporar la atención.\n",
    "- Entrena el modelo y compara el rendimiento con el modelo original.\n",
    "\n",
    "Pistas:\n",
    "\n",
    "- Utiliza la clase nn.Linear para calcular los pesos de atención.\n",
    "- Multiplica los pesos de atención con los estados ocultos del codificador para obtener el contexto.\n",
    "- Concatena el contexto con la entrada del decodificador en cada paso de tiempo.\n",
    "\n",
    "2 . Compara el rendimiento de las estrategias de decodificación Greedy, Beam Search y Temperatura en diferentes configuraciones de entrenamiento.\n",
    "\n",
    "Instrucciones:\n",
    "\n",
    "- Entrena el modelo con diferentes tamaños de conjunto de datos y configuraciones de hiperparámetros (por ejemplo, diferentes tamaños de hidden_size y num_layers).\n",
    "- Aplica las tres estrategias de decodificación a cada modelo entrenado.\n",
    "- Evalúa y compara la calidad de las traducciones utilizando métricas como la precisión y el BLEU score.\n",
    "\n",
    "Pistas:\n",
    "\n",
    "- Usa conjuntos de datos grandes y pequeños para ver cómo cambia el rendimiento.\n",
    "- Experimenta con diferentes beam_width y temperatures.\n",
    "\n",
    "3 . Implementa una variante de Beam Search que penalice secuencias más largas para evitar repeticiones innecesarias.\n",
    "\n",
    "Instrucciones:\n",
    "\n",
    "- Modifica la función beam_search_decode para incluir una penalización de longitud.\n",
    "- Ajusta el cálculo de las puntuaciones de las secuencias para penalizar las secuencias más largas.\n",
    "- Compara los resultados con el Beam Search estándar.\n",
    "\n",
    "Pistas:\n",
    "\n",
    "- Multiplica la puntuación de cada secuencia por una función de penalización basada en su longitud.\n",
    "- Puedes usar una función de penalización lineal o exponencial.\n",
    "\n",
    "4 . Implementa una estrategia de decodificación por temperatura que ajuste dinámicamente la temperatura en cada paso de tiempo.\n",
    "\n",
    "Instrucciones:\n",
    "\n",
    "- Modifica la función decode_with_temperature para ajustar la temperatura en cada paso de tiempo.\n",
    "- Implementa una función que disminuya la temperatura a medida que avanza la decodificación, incentivando exploración al principio y explotación al final.\n",
    "- Evalúa el impacto de la temperatura dinámica en la calidad de las traducciones.\n",
    "\n",
    "Pistas:\n",
    "\n",
    "- Usa una función de decremento lineal o exponencial para la temperatura.\n",
    "- Compara los resultados con una temperatura fija.\n",
    "\n",
    "5 . Analiza la complejidad computacional y el rendimiento de las diferentes estrategias de decodificación.\n",
    "\n",
    "Instrucciones:\n",
    "\n",
    "- Mide el tiempo de ejecución de las estrategias Greedy, Beam Search y Temperatura para diferentes tamaños de vocabulario y longitudes de secuencia.\n",
    "- Analiza cómo cambia la complejidad computacional con respecto a beam_width y temperature.\n",
    "- Discute los trade-offs entre la calidad de la traducción y el tiempo de ejecución.\n",
    "\n",
    "Pistas:\n",
    "\n",
    "- Usa la biblioteca time para medir el tiempo de ejecución.\n",
    "- Realiza pruebas con diferentes configuraciones y grafica los resultados.\n",
    "\n",
    "\n",
    "6 .Mejora la generalización del modelo incorporando técnicas de regularización y dropout.\n",
    "\n",
    "Instrucciones:\n",
    "\n",
    "- Añade capas de dropout adicionales al modelo Seq2Seq.\n",
    "- Implementa técnicas de regularización como L2.\n",
    "- Entrena el modelo con estas técnicas y compara el rendimiento con el modelo original.\n",
    "\n",
    "Pistas:\n",
    "\n",
    "- Usa nn.Dropout en las capas RNN y totalmente conectadas.\n",
    "- Ajusta los hiperparámetros de regularización y dropout para encontrar la configuración óptima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efe5f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

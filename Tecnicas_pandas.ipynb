{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e8cc2a7-7b2c-433b-8e5a-13f30ed8d983",
   "metadata": {},
   "source": [
    "## Ejemplos avanzados de selección y filtrado\n",
    "\n",
    "#### 1. Uso de `loc`\n",
    "\n",
    "El método `loc` se utiliza para seleccionar datos por **etiquetas** (nombres de índices o columnas). Es especialmente útil cuando se tiene un DataFrame con índices personalizados.\n",
    "\n",
    "##### Ejemplo 1: Seleccionar filas por rango de etiquetas\n",
    "\n",
    "Supongamos que tenemos el siguiente DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1726951a-d477-45b4-a709-08ddf30d7e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creación de un DataFrame con índices personalizados\n",
    "data = {\n",
    "    'Nombre': ['Ana', 'Luis', 'Carlos', 'Marta', 'Elena'],\n",
    "    'Edad': [23, 35, 45, 29, 40],\n",
    "    'Ciudad': ['Madrid', 'Barcelona', 'Valencia', 'Sevilla', 'Bilbao']\n",
    "}\n",
    "df = pd.DataFrame(data, index=['a', 'b', 'c', 'd', 'e'])\n",
    "print(\"DataFrame original:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7b39f5-ed6a-4fc4-a744-d536eafbc266",
   "metadata": {},
   "source": [
    "Para seleccionar las filas que van desde el índice 'b' hasta 'd', se utiliza:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb580e5d-38bf-4232-8de1-a16b36dd91ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecciona filas del índice 'b' hasta 'd' (inclusive)\n",
    "subset = df.loc['b':'d']\n",
    "print(\"\\nFilas de 'b' a 'd':\")\n",
    "print(subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db297851-9561-48ec-a99d-ebb087b61472",
   "metadata": {},
   "source": [
    "##### Ejemplo 2: Seleccionar filas y columnas específicas\n",
    "\n",
    "Si queremos obtener las filas con índices 'b' y 'c' y solo las columnas \"Nombre\" y \"Ciudad\", se puede hacer de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017b1fa3-f70b-4188-bb8c-164753f4a26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_cols = df.loc[['b', 'c'], ['Nombre', 'Ciudad']]\n",
    "print(\"\\nFilas 'b' y 'c' con columnas 'Nombre' y 'Ciudad':\")\n",
    "print(subset_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a1d66f-e52d-4c24-a102-97c06b536767",
   "metadata": {},
   "source": [
    "##### Ejemplo 3: Filtrado condicional utilizando loc\n",
    "\n",
    "Podemos combinar `loc` con condiciones para filtrar datos. Por ejemplo, para seleccionar todas las filas donde la edad sea mayor a 30:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b9b4f7-2974-4ed4-8b93-c6eddd405289",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtro = df.loc[df['Edad'] > 30]\n",
    "print(\"\\nFilas con Edad > 30:\")\n",
    "print(filtro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b46b4b-fe73-4f7b-b73a-43e762a1b764",
   "metadata": {},
   "source": [
    "#### 2. Uso de `iloc`\n",
    "\n",
    "El método `iloc` permite acceder a los datos por **posición entera**. Es útil cuando se desconoce o no se utiliza el índice por etiquetas.\n",
    "\n",
    "##### Ejemplo 1: Seleccionar filas por posición\n",
    "\n",
    "Supongamos el mismo DataFrame `df`. Para obtener las dos primeras filas (índices 0 y 1 en base a la posición):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccc9e57-d984-4425-aa6c-c1400c9f725d",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_iloc = df.iloc[0:2]\n",
    "print(\"\\nPrimeras 2 filas utilizando iloc:\")\n",
    "print(subset_iloc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3767d77e-3548-4583-92ea-5f9e0364d48f",
   "metadata": {},
   "source": [
    "##### Ejemplo 2: Seleccionar filas y columnas por posición\n",
    "\n",
    "Para obtener la primera y segunda fila y la primera y tercera columna (teniendo en cuenta que la posición es 0-indexada):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689fd368-084f-41f6-99b8-b2e81d3eca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_iloc2 = df.iloc[0:2, [0, 2]]\n",
    "print(\"\\nPrimeras 2 filas y columnas 0 y 2:\")\n",
    "print(subset_iloc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4085c46-894c-4962-9f26-b10f7416c48a",
   "metadata": {},
   "source": [
    "##### Ejemplo 3: Uso de listas de posiciones\n",
    "\n",
    "Si se desea seleccionar filas en posiciones específicas, por ejemplo, la fila 1 y la fila 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74caa719-649c-4c7c-ac58-4c4d60cbb701",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_iloc3 = df.iloc[[1, 3]]\n",
    "print(\"\\nFilas en posiciones 1 y 3:\")\n",
    "print(subset_iloc3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbaf273-2dad-40b4-ac78-0b3efd4b27cf",
   "metadata": {},
   "source": [
    "#### 3. Uso de `iat`\n",
    "\n",
    "El método `iat` es similar a `iloc` pero está optimizado para obtener un **único valor escalar** de manera muy rápida.\n",
    "\n",
    "##### Ejemplo: Obtener un valor puntual\n",
    "\n",
    "Para obtener, por ejemplo, el valor de la columna \"Edad\" en la fila que se encuentra en la posición 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7156b732-9577-43cc-a29a-fdd96a55dbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "valor = df.iat[2, 1]  # fila en posición 2, columna en posición 1 ('Edad')\n",
    "print(\"\\nValor escalar obtenido con iat (fila 2, columna 'Edad'):\")\n",
    "print(valor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b2d334-4d39-4210-bae2-7c7154c7c12a",
   "metadata": {},
   "source": [
    "Este método es muy eficiente cuando se requiere acceder a un único elemento del DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c819e3-588b-4093-b11c-748607fa282f",
   "metadata": {},
   "source": [
    "#### Ejemplos avanzados de Reshape en Pandas\n",
    "\n",
    "El **reshape** se refiere a la reorganización o transformación de la forma de los datos. En Pandas se pueden usar varias técnicas para lograrlo, tales como `pivot()`, `melt()`, `stack()` y `unstack()`. También se puede usar `reshape` de NumPy para arrays, lo que es complementario en el análisis de datos.\n",
    "\n",
    "##### 1. Uso de NumPy reshape\n",
    "\n",
    "Antes de trabajar en Pandas, es útil ver cómo funciona `reshape` en NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b210c76b-36e6-48b1-8a80-665322d805ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Crea un array unidimensional\n",
    "array = np.array([1, 2, 3, 4, 5, 6])\n",
    "print(\"Array original:\")\n",
    "print(array)\n",
    "\n",
    "# Cambia la forma a una matriz de 2 filas y 3 columnas\n",
    "array_reshaped = array.reshape((2, 3))\n",
    "print(\"\\nArray reestructurado (2x3):\")\n",
    "print(array_reshaped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cbb519-4438-44c0-a377-6978fc88eb4f",
   "metadata": {},
   "source": [
    "##### 2. Uso de `pivot` en Pandas\n",
    "\n",
    "El método `pivot` transforma datos de formato largo a formato ancho. Imagina que tienes un DataFrame con información de ventas por producto y mes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974e056a-0443-4e50-9e12-26dd053fcaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame de ejemplo\n",
    "data = {\n",
    "    'Producto': ['A', 'A', 'B', 'B'],\n",
    "    'Mes': ['Enero', 'Febrero', 'Enero', 'Febrero'],\n",
    "    'Ventas': [100, 150, 200, 250]\n",
    "}\n",
    "df_ventas = pd.DataFrame(data)\n",
    "print(\"DataFrame de ventas:\")\n",
    "print(df_ventas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357a088d-1239-4460-ade1-158adacd73da",
   "metadata": {},
   "source": [
    "Para reorganizar el DataFrame de forma que cada mes sea una columna, se utiliza `pivot`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b088c0a3-4afb-441a-8d5d-f5e2e6fabd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = df_ventas.pivot(index='Producto', columns='Mes', values='Ventas')\n",
    "print(\"\\nDataFrame tras aplicar pivot:\")\n",
    "print(df_pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6a630c-8a40-466e-beff-dedd3243cc1c",
   "metadata": {},
   "source": [
    "Ahora, el índice son los productos y las columnas son los meses, con los valores correspondientes de ventas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51eb8004-9c58-4044-b02b-be8a5e97a609",
   "metadata": {},
   "source": [
    "##### 3. Uso de `melt` en Pandas\n",
    "\n",
    "El método `melt` realiza la operación inversa a `pivot`, transformando un DataFrame ancho a un formato largo. Esto es muy útil para preparar datos para ciertas visualizaciones o análisis.\n",
    "\n",
    "Supongamos que tenemos el DataFrame de ventas pivotado del ejemplo anterior:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afa6ab9-d6b2-4385-a931-443ed0b3fe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDataFrame pivotado:\")\n",
    "print(df_pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcf87fb-3902-43b6-9541-a63b729fdcf4",
   "metadata": {},
   "source": [
    "Podemos volver a la forma larga:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366d7360-f3b4-4c2d-b1e3-d01b6e44dda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melt = pd.melt(df_pivot.reset_index(), id_vars='Producto', value_vars=['Enero', 'Febrero'], \n",
    "                  var_name='Mes', value_name='Ventas')\n",
    "print(\"\\nDataFrame tras aplicar melt:\")\n",
    "print(df_melt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a591acaa-46f3-471c-97d2-d8e867bef4c1",
   "metadata": {},
   "source": [
    "Aquí, se utiliza `reset_index()` para que \"Producto\" vuelva a ser una columna y no un índice, facilitando la operación de melting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd96633-ba92-4673-9ce0-476346a1b65c",
   "metadata": {},
   "source": [
    "##### 4. Uso de `stack` y `unstack`\n",
    "\n",
    "Estos métodos permiten pivotear niveles del índice. Son muy útiles cuando se trabaja con DataFrames multiíndice.\n",
    "\n",
    "##### Ejemplo con `stack`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3342ba73-d65a-49d4-8a22-ee3c6311c313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea un DataFrame con un índice simple\n",
    "df_simple = pd.DataFrame({\n",
    "    'A': [1, 2],\n",
    "    'B': [3, 4]\n",
    "}, index=['X', 'Y'])\n",
    "print(\"\\nDataFrame simple:\")\n",
    "print(df_simple)\n",
    "\n",
    "# Aplica stack para apilar columnas y convertirlas en un nivel adicional de índice\n",
    "df_stacked = df_simple.stack()\n",
    "print(\"\\nDataFrame tras aplicar stack:\")\n",
    "print(df_stacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8385fa0-7546-4af7-a9c2-74fe46f25e06",
   "metadata": {},
   "source": [
    "El resultado de `stack` es una Serie donde las columnas se han convertido en un nivel del índice. Por ejemplo, el valor en la posición ('X', 'A') corresponde al 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc9bef4-8950-4ce9-9bbd-290b20be931a",
   "metadata": {},
   "source": [
    "##### Ejemplo con `unstack`\n",
    "\n",
    "Para revertir la operación, se puede utilizar `unstack`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6777cf-f1f8-443c-a1c8-ad432892ec52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revierte la operación de stack\n",
    "df_unstacked = df_stacked.unstack()\n",
    "print(\"\\nDataFrame tras aplicar unstack (vuelve a la forma original):\")\n",
    "print(df_unstacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f352c1-caef-4c16-bb9d-2a6bd57fd01d",
   "metadata": {},
   "source": [
    "##### 5. Ejemplo completo de transformación de datos\n",
    "\n",
    "Imaginemos un escenario en el que se dispone de un DataFrame de encuestas con múltiples columnas que se deben transformar para un análisis posterior. Supongamos el siguiente DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b0a457-a341-4543-9713-e303dd726e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encuesta = {\n",
    "    'ID': [1, 2, 3],\n",
    "    'Edad': [25, 30, 35],\n",
    "    'Genero': ['F', 'M', 'F'],\n",
    "    'Respuesta_A': [5, 3, 4],\n",
    "    'Respuesta_B': [3, 4, 2]\n",
    "}\n",
    "df_encuesta = pd.DataFrame(data_encuesta)\n",
    "print(\"\\nDataFrame de encuesta original:\")\n",
    "print(df_encuesta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed53849-3963-4942-838a-e01f41d7cbe3",
   "metadata": {},
   "source": [
    "Si queremos transformar este DataFrame para que cada respuesta se encuentre en filas separadas (formato largo), utilizamos `melt`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d326ded2-d2f4-4ed5-b87f-3d1c9a297b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encuesta_melt = pd.melt(df_encuesta, id_vars=['ID', 'Edad', 'Genero'], \n",
    "                           value_vars=['Respuesta_A', 'Respuesta_B'], \n",
    "                           var_name='Pregunta', value_name='Respuesta')\n",
    "print(\"\\nDataFrame de encuesta tras aplicar melt:\")\n",
    "print(df_encuesta_melt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea4e6d8-c29a-46c6-859c-3d437ccc8451",
   "metadata": {},
   "source": [
    "Con este formato largo, es más sencillo, por ejemplo, agrupar respuestas por género o edad y analizar las tendencias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd418b31-721c-4daf-83dc-e4ef15b82b65",
   "metadata": {},
   "source": [
    "#### Buenas prácticas y consejos\n",
    "\n",
    "- **Definir índices significativos:**  \n",
    "  Al utilizar `loc` es muy útil tener índices con nombres descriptivos en lugar de simples enteros. Esto mejora la legibilidad y facilita la selección por etiquetas.\n",
    "\n",
    "- **Utilizar slicing con cuidado:**  \n",
    "  Con `loc`, el slicing **incluye** el último valor, a diferencia de `iloc` que es no inclusivo en el límite superior.  \n",
    "  Por ejemplo:\n",
    "  \n",
    "  ```python\n",
    "  # Con loc: se incluye la etiqueta 'd'\n",
    "  print(df.loc['b':'d'])\n",
    "  \n",
    "  # Con iloc: se excluye la posición final\n",
    "  print(df.iloc[1:4])\n",
    "  ```\n",
    "\n",
    "- **Conversión entre formatos:**  \n",
    "  Las funciones `melt` y `pivot` son herramientas muy poderosas para convertir datos entre formatos anchos y largos. Esto es particularmente útil cuando se trabaja con librerías de visualización que requieren un formato de datos específico.\n",
    "\n",
    "- **Verificar el DataFrame resultante:**  \n",
    "  Después de realizar operaciones de reshape (stack, unstack, melt, pivot), es recomendable imprimir una parte del DataFrame (usando `head()` o `info()`) para asegurarse de que la transformación se realizó correctamente.\n",
    "\n",
    "- **Evitar el uso de `ix`:**  \n",
    "  Aunque algunos ejemplos históricos muestran su uso, es importante recordar que `ix` ha sido descontinuado y puede producir errores o comportamientos inesperados en versiones recientes de Pandas.\n",
    "\n",
    "- **Acceso rápido a valores escalares con `iat`:**  \n",
    "  Cuando se necesite obtener un solo valor, `iat` es la opción preferida por su eficiencia. Este método es muy útil dentro de bucles o en operaciones donde el rendimiento es crítico.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029fb02e-3b17-4e20-88eb-ad6e8f719714",
   "metadata": {},
   "source": [
    "#### 1. Método **map()**\n",
    "\n",
    "**map()** se aplica principalmente a **Series**. Este método itera sobre cada elemento de la Serie y permite transformar o sustituir los valores de acuerdo a una función, diccionario o una correspondencia definida.\n",
    "\n",
    "#### Ejemplos de map()\n",
    "\n",
    "**Ejemplo 1: Sumar 1 a cada elemento de una Serie**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e66b73-c9fb-450c-ba85-654ae571d59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Crea una Serie de ejemplo\n",
    "serie = pd.Series([10, 20, 30, 40])\n",
    "# Utiliza map para sumar 1 a cada elemento\n",
    "serie_modificada = serie.map(lambda x: x + 1)\n",
    "print(\"Serie original:\")\n",
    "print(serie)\n",
    "print(\"\\nSerie con 1 sumado a cada elemento:\")\n",
    "print(serie_modificada)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a4d5e7-ef42-4d84-9ceb-3fc05aee0ba2",
   "metadata": {},
   "source": [
    "**Ejemplo 2: Reemplazar valores utilizando un diccionario**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1ee077-420b-4e3c-b848-6a0f1696af5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supongamos que tenemos una Serie de nombres cortos\n",
    "nombres = pd.Series(['M', 'F', 'F', 'M', 'M'])\n",
    "# Usamos un diccionario para mapear 'M' a 'Masculino' y 'F' a 'Femenino'\n",
    "mapa_genero = {'M': 'Masculino', 'F': 'Femenino'}\n",
    "nombres_completos = nombres.map(mapa_genero)\n",
    "print(\"\\nSerie de géneros (original):\")\n",
    "print(nombres)\n",
    "print(\"\\nSerie de géneros (transformada):\")\n",
    "print(nombres_completos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d66399-81af-4c63-83de-089c8d3e84e3",
   "metadata": {},
   "source": [
    "#### 2. Método **apply()**\n",
    "\n",
    "**apply()** se utiliza tanto en **Series** como en **DataFrames** para aplicar una función a lo largo de un eje (filas o columnas). En un DataFrame, el método puede aplicarse a cada columna (por defecto) o a cada fila (especificando `axis=1`).\n",
    "\n",
    "#### Ejemplos de apply()\n",
    "\n",
    "**Ejemplo 1: Aplicar una función a cada elemento de una Serie**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8b4a4e-693f-43fa-9b1e-3cb72f0c7fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "serie = pd.Series([15, 30, 45, 50])\n",
    "# Aplica una función para multiplicar cada elemento por 2\n",
    "serie_modificada = serie.apply(lambda x: x * 2)\n",
    "print(\"\\nSerie original:\")\n",
    "print(serie)\n",
    "print(\"\\nSerie con cada elemento multiplicado por 2:\")\n",
    "print(serie_modificada)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78add964-098f-43ba-8ef4-0cc6e190cd14",
   "metadata": {},
   "source": [
    "**Ejemplo 2: Aplicar una función a cada columna de un DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa82652-0eb9-476a-aa77-f00e39f82844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea un DataFrame de ejemplo\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [10, 20, 30]\n",
    "})\n",
    "# Aplica una función que calcule el promedio de cada columna\n",
    "promedios = df.apply(lambda x: x.mean())\n",
    "print(\"\\nDataFrame original:\")\n",
    "print(df)\n",
    "print(\"\\nPromedio de cada columna:\")\n",
    "print(promedios)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c78d93-7fe7-454f-be78-cf75eaf8d2a7",
   "metadata": {},
   "source": [
    "#### 3. Método **applymap()**\n",
    "\n",
    "**applymap()** es exclusivo para **DataFrames** y se utiliza para aplicar una función a **cada elemento individual** del DataFrame, de forma similar a map() pero en un contexto bidimensional.\n",
    "\n",
    "#### Ejemplos de applymap()\n",
    "\n",
    "**Ejemplo: Convertir todos los valores a cadenas**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0e200c-6c2e-4309-bd47-1b314e7e89a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_str = df.applymap(str)\n",
    "print(\"\\nDataFrame con valores convertidos a cadena:\")\n",
    "print(df_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e8c358-2c7e-41ce-8712-2ab0b668a9b6",
   "metadata": {},
   "source": [
    "#### Resumen comparativo\n",
    "\n",
    "- **map()**:  \n",
    "  - **Nivel:** Serie (unidimensional).  \n",
    "  - **Función:** Transforma o reemplaza cada elemento de la Serie según una función o un diccionario.  \n",
    "  - **Ejemplo:** Cambiar códigos de género ('M', 'F') a palabras completas o sumar 1 a cada valor.\n",
    "\n",
    "- **apply()**:  \n",
    "  - **Nivel:** Puede aplicarse a Series o DataFrames.  \n",
    "  - **Función:** Aplica una función a lo largo de un eje (columnas por defecto o filas si se especifica `axis=1`).\n",
    "  - **Ejemplo:** Calcular la media de cada columna o la suma de cada fila en un DataFrame.\n",
    "\n",
    "- **applymap()**:  \n",
    "  - **Nivel:** DataFrame (bidimensional).  \n",
    "  - **Función:** Aplica una función a cada elemento individual del DataFrame.\n",
    "  - **Ejemplo:** Sumar 1 a cada celda o convertir todos los valores a cadenas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f225bc-194f-4be5-9211-bd9a634d6e0b",
   "metadata": {},
   "source": [
    "#### Ejemplo Completo: Transformación de un DataFrame de ventas\n",
    "\n",
    "Supongamos que tenemos un DataFrame con información de ventas y queremos realizar varias transformaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176f0d50-a3ed-4292-b8de-dfc5cb229314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea un DataFrame de ejemplo\n",
    "df_ventas = pd.DataFrame({\n",
    "    'Producto': ['A', 'B', 'C', 'A'],\n",
    "    'Unidades': [5, 3, 8, 2],\n",
    "    'Precio': [100, 150, 200, 100]\n",
    "})\n",
    "print(\"DataFrame original:\")\n",
    "print(df_ventas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a832b7-1f61-4fa0-a955-e6854c58eb7b",
   "metadata": {},
   "source": [
    "##### Paso 1: Usar **map()** para cambiar etiquetas de producto\n",
    "\n",
    "Supongamos que queremos transformar las etiquetas de los productos usando un diccionario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e73aa58-2ad3-498f-b89b-427c6d9789e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario para renombrar productos\n",
    "mapa_productos = {'A': 'Producto_A', 'B': 'Producto_B', 'C': 'Producto_C'}\n",
    "df_ventas['Producto'] = df_ventas['Producto'].map(mapa_productos)\n",
    "print(\"\\nDataFrame con productos renombrados:\")\n",
    "print(df_ventas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3052156d-608f-43e5-a771-cf8af23ba755",
   "metadata": {},
   "source": [
    "##### Paso 2: Usar **apply()** para calcular una nueva columna de ingresos\n",
    "\n",
    "Queremos crear una nueva columna que sea el producto de `Unidades` y `Precio`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0187a338-5163-4359-8462-a26649f5dd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas['Ingresos'] = df_ventas.apply(lambda row: row['Unidades'] * row['Precio'], axis=1)\n",
    "print(\"\\nDataFrame con columna 'Ingresos':\")\n",
    "print(df_ventas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11d2eed-ef26-478d-b72a-b2fc81400947",
   "metadata": {},
   "source": [
    "##### Paso 3: Usar **applymap()** para formatear valores numéricos\n",
    "\n",
    "Si deseamos, por ejemplo, redondear a dos decimales todos los valores numéricos del DataFrame:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612544be-39d3-4d95-a8b2-344414ef3411",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_formateado = df_ventas.applymap(lambda x: round(x, 2) if isinstance(x, float) or isinstance(x, int) else x)\n",
    "print(\"\\nDataFrame con valores redondeados:\")\n",
    "print(df_formateado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9914e3e-de6f-4e19-9d1c-f2197a6bb834",
   "metadata": {},
   "source": [
    "### Merge y join\n",
    "\n",
    "Las funciones de *merge* y *join* en pandas son esenciales para combinar conjuntos de datos que comparten columnas o índices comunes. Estas operaciones son comparables a los *joins* de SQL y permiten unir DataFrames de manera flexible.\n",
    "\n",
    "- **merge:**  \n",
    "La función `pd.merge()` se utiliza para combinar dos DataFrames en función de una o varias columnas comunes. Se pueden especificar distintos tipos de uniones, como *inner join*, *left join*, *right join* y *outer join*.  \n",
    "\n",
    "  - **Inner join:** Retorna solo las filas con valores coincidentes en ambos DataFrames.  \n",
    "  - **Left join:** Retorna todas las filas del DataFrame izquierdo y, cuando hay coincidencias, añade las columnas correspondientes del DataFrame derecho.  \n",
    "  - **Right join:** Es lo opuesto a left join, devolviendo todas las filas del DataFrame derecho.  \n",
    "  - **Outer join:** Retorna todas las filas de ambos DataFrames, completando con NaN los valores faltantes.  \n",
    "\n",
    "*Ejemplo básico:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46228526-ea99-46ab-9760-6559c3cd1deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.DataFrame({\n",
    "      'id': [1, 2, 3],\n",
    "      'valor': ['A', 'B', 'C']\n",
    "  })\n",
    "  \n",
    "df2 = pd.DataFrame({\n",
    "      'id': [2, 3, 4],\n",
    "      'detalle': ['X', 'Y', 'Z']\n",
    "  })\n",
    "resultado = pd.merge(df1, df2, on='id', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afa1b9c-9691-43e8-aa25-356b033164f7",
   "metadata": {},
   "source": [
    "En este ejemplo, el resultado contendrá únicamente las filas con `id` 2 y 3, ya que son las que existen en ambos DataFrames.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fb64f7-910a-4018-86c9-5517849b2687",
   "metadata": {},
   "source": [
    "- **join:**  \n",
    "\n",
    "El método `join()` es similar a `merge()`, pero se basa en los índices en lugar de columnas explícitas, lo que puede ser muy útil cuando los DataFrames tienen índices que son claves significativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5252c8-47cd-4a2e-96b0-214f2afd2009",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.set_index('id')\n",
    "df2 = df2.set_index('id')\n",
    "resultado = df1.join(df2, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da547aa8-a538-44a4-ba25-3e52c578253a",
   "metadata": {},
   "source": [
    "Aquí se realiza una unión externa en base al índice, obteniendo todas las filas de ambos DataFrames y combinando los datos de acuerdo a sus índices.\n",
    "\n",
    "Estas operaciones permiten integrar datos provenientes de diferentes fuentes, una necesidad frecuente en la ingeniería de datos, donde la información suele estar dispersa en múltiples sistemas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ab106b-7c3f-47d5-9bdb-022d5ea99ae3",
   "metadata": {},
   "source": [
    "### Grouping (Group By)\n",
    "\n",
    "El método `groupby()` de pandas es fundamental para realizar operaciones de agregación, segmentando datos según una o varias claves y aplicando funciones estadísticas o de transformación sobre cada grupo.\n",
    "\n",
    "- **Concepto básico:**  \n",
    "`groupby()` permite dividir un DataFrame en grupos basados en los valores de una o más columnas. Una vez agrupados, se pueden aplicar funciones como `sum()`, `mean()`, `count()`, entre otras, para resumir o transformar los datos.\n",
    "  \n",
    "*Ejemplo:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142acbe9-8ad9-4c86-af0f-d60b320ce4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "      'categoria': ['A', 'B', 'A', 'B', 'C'],\n",
    "      'valor': [10, 20, 30, 40, 50]\n",
    "  })\n",
    "agrupado = df.groupby('categoria')['valor'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bebf828-12f7-4631-94d9-a8b7b0128e70",
   "metadata": {},
   "source": [
    "En este caso, se agrupan los datos por la columna `categoria` y se suma el valor de la columna `valor` para cada grupo. El resultado sería una Serie con la suma para cada categoría.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6862906-74bb-40c4-a0b8-098fadb0de7b",
   "metadata": {},
   "source": [
    "- **Agregaciones múltiples y personalizadas:**  \n",
    "  Además de aplicar funciones predefinidas, pandas permite aplicar funciones personalizadas a cada grupo.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6f57ec-5be9-47c9-85a8-8556c93f0919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_function(x):\n",
    "      return x.max() - x.min()  \n",
    "resultado = df.groupby('categoria').agg({'valor': ['mean', custom_function]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae27e1e-048d-4ca4-9eeb-31058a22bd8d",
   "metadata": {},
   "source": [
    "Esta sintaxis aplica dos funciones a la columna `valor`: el promedio y una función personalizada que calcula la diferencia entre el valor máximo y mínimo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb02c59c-56e8-4158-8c0a-41e22effccde",
   "metadata": {},
   "source": [
    "- **Transformación y filtrado:**  \n",
    "  Con `groupby()` se pueden transformar datos a nivel de grupo sin perder la estructura original del DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fe60ea-6d8c-4bce-986a-6efc167850dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['valor_normalizado'] = df.groupby('categoria')['valor'].transform(lambda x: (x - x.mean()) / x.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b2b08b-415b-45b1-86bb-f8770c14c02b",
   "metadata": {},
   "source": [
    "Aquí se normalizan los valores de cada grupo, de forma que se conserva la alineación original de los datos.\n",
    "\n",
    "En ingeniería de datos, el agrupamiento es crucial para resumir grandes volúmenes de información y obtener insights a nivel agregado, como promedios por grupo, totales, conteos y otras estadísticas relevantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bad72bf-9663-451c-ada9-01b833987faa",
   "metadata": {},
   "source": [
    "#### Tablas Pivot\n",
    "\n",
    "Las tablas pivot son una herramienta poderosa para reorganizar y resumir datos de manera interactiva, permitiendo transformar columnas en filas y viceversa. La función `pivot_table()` en pandas permite crear tablas dinámicas que agrupan datos y aplican funciones de agregación.\n",
    "\n",
    "- **Definición y uso:**  \n",
    "Una tabla pivot toma una columna para definir las filas, otra para las columnas y otra para los valores. Se puede especificar la función de agregación a aplicar (por defecto es `mean`).\n",
    "  \n",
    "*Ejemplo:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0197e8-baae-4a59-98c4-b8edde74b56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "      'fecha': ['2025-01-01', '2025-01-01', '2025-01-02', '2025-01-02'],\n",
    "      'categoria': ['A', 'B', 'A', 'B'],\n",
    "      'ventas': [100, 150, 200, 250]\n",
    "  })\n",
    "  \n",
    "pivot = pd.pivot_table(df, values='ventas', index='fecha', columns='categoria', aggfunc='sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756870c1-e1fa-49fb-ba46-14f74aa63d15",
   "metadata": {},
   "source": [
    "En este ejemplo, se agrupan las ventas por fecha y categoría, obteniendo la suma de las ventas para cada combinación. El resultado es una matriz que permite ver de forma rápida la distribución de ventas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a82050-c628-4183-be65-15ac89db9060",
   "metadata": {},
   "source": [
    "- **Flexibilidad y complejidad:**  \n",
    "Las tablas pivot pueden incluir múltiples funciones de agregación y permitir la inclusión de varios niveles en índices y columnas. Esto es especialmente útil cuando se trabaja con datos multidimensionales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb4aba0-84e8-4bee-99d0-3431a364c883",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = pd.pivot_table(df, values='ventas', index=['fecha'], columns=['categoria'], aggfunc=[\"mean\", \"sum\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade48673-1de2-4730-93ad-26da23603a81",
   "metadata": {},
   "source": [
    "Con este enfoque, se obtienen tanto la media como la suma de ventas para cada combinación de fecha y categoría, lo que permite análisis comparativos más profundos.\n",
    "\n",
    "Las tablas pivot son extremadamente útiles en el análisis exploratorio de datos y en la generación de reportes resumidos, permitiendo a los ingenieros de datos transformar conjuntos de datos complejos en formatos de fácil interpretación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8e5e4e-5682-47be-a071-6c5348b29589",
   "metadata": {},
   "source": [
    "### Otras técnicas avanzadas en Pandas para ingeniería de datos\n",
    "\n",
    "Además de las operaciones de merge/join, group by y pivot, pandas ofrece una amplia gama de herramientas y técnicas para el procesamiento de datos, entre las que destacan:\n",
    "\n",
    "- **Manejo de datos faltantes:**  \n",
    "  La limpieza de datos es una tarea crítica en la ingeniería de datos. Pandas proporciona métodos como `isnull()`, `dropna()` y `fillna()` para identificar y tratar valores nulos o faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273f218f-d97d-4242-b3e4-627570a24b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)  # Elimina filas con datos faltantes\n",
    "df.fillna(0, inplace=True)  # Sustituye datos nulos por cero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cd9788-dc71-4c1f-ab07-4761f6492ccd",
   "metadata": {},
   "source": [
    "Estas funciones permiten mantener la integridad de los datos antes de realizar análisis o modelado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f58b5a-c058-44b2-a03f-876793f3d416",
   "metadata": {},
   "source": [
    "- **Aplicación de funciones con apply y lambda:**  \n",
    "La función `apply()` es fundamental para aplicar funciones a lo largo de filas o columnas, ofreciendo una manera flexible de transformar datos sin tener que escribir bucles explícitos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e299fc-4468-4c4f-b114-0cdbdf693b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['nueva_columna'] = df['columna_existente'].apply(lambda x: x * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27db2b47-b1ca-4761-aaba-06f0f2c5e446",
   "metadata": {},
   "source": [
    "Este enfoque es útil para realizar transformaciones personalizadas en los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3229dd-7a6b-42e9-b3ff-b29286c56b6b",
   "metadata": {},
   "source": [
    "- **Reshape y transformación de datos:**  \n",
    "Además de pivotar, pandas permite cambiar la estructura de los datos con métodos como `melt()`, que convierte datos de formato ancho a formato largo, facilitando el análisis de datos categóricos o series temporales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9160582c-1030-432b-a4fe-09c070fdc4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_melted = pd.melt(df, id_vars=['id'], value_vars=['col1', 'col2'], var_name='variable', value_name='valor')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9164b5d-1dc6-4bd4-868f-82d63e180f6c",
   "metadata": {},
   "source": [
    "Esta transformación es particularmente útil para preparar datos antes de aplicar técnicas de machine learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffadf05a-575d-4b4f-babe-4a47d20483cd",
   "metadata": {},
   "source": [
    "- **Optimización y manejo de grandes volúmenes de datos:**  \n",
    "En proyectos de ingeniería de datos, es común trabajar con conjuntos de datos muy grandes. Pandas, en combinación con bibliotecas como Dask o PySpark, permite paralelizar operaciones y gestionar la memoria de forma eficiente.\n",
    "\n",
    "- **Dask:** Proporciona una API similar a pandas pero permite el procesamiento en paralelo y distribuido, ideal para datasets que no caben en memoria.\n",
    "\n",
    "- **PySpark:** Integra el procesamiento de datos distribuidos utilizando el framework Apache Spark, facilitando la manipulación de datos a gran escala.\n",
    "\n",
    "- **Operaciones de time series:**  \n",
    "Para trabajar con datos temporales, pandas ofrece herramientas específicas que facilitan la conversión de fechas, el re-muestreo (resampling) y el manejo de índices temporales.\n",
    "  ```python\n",
    "  df['fecha'] = pd.to_datetime(df['fecha'])\n",
    "  df.set_index('fecha', inplace=True)\n",
    "  df_resampled = df.resample('M').sum()  # Agrega datos por mes\n",
    "  ```\n",
    "Estas operaciones permiten analizar tendencias, patrones estacionales y otros aspectos cruciales en series temporales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aa6817-9126-4473-905a-0fe763ee8b89",
   "metadata": {},
   "source": [
    "- **Integración con otras herramientas:**  \n",
    "Pandas se integra de manera fluida con otras bibliotecas de Python, como NumPy para operaciones numéricas, Matplotlib y Seaborn para visualización, y Scikit-Learn para modelado y análisis predictivo. Esta interoperabilidad permite crear pipelines de datos completos y robustos que abordan desde la extracción y transformación hasta la visualización y modelado.\n",
    "\n",
    "- **Optimización del rendimiento:**  \n",
    "Para maximizar la eficiencia, es recomendable utilizar operaciones vectorizadas en lugar de bucles explícitos. Las funciones de pandas están optimizadas en C y pueden procesar datos de manera mucho más rápida que las iteraciones tradicionales en Python. Además, es importante utilizar tipos de datos adecuados, como categoricals, para reducir el uso de memoria y mejorar el rendimiento en operaciones de agrupación y combinación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b551232-1d37-458d-b5df-ee182829f684",
   "metadata": {},
   "source": [
    "### Pandas y SQL\n",
    "\n",
    "Pandas y SQL comparten muchas similitudes en términos de manipulación y análisis de datos. Mientras que SQL es un lenguaje especializado para gestionar y consultar bases de datos relacionales, pandas es una biblioteca de Python que ofrece herramientas para transformar, limpiar y analizar datos en estructuras como DataFrames. Algunas de las relaciones y paralelismos entre ambos son:\n",
    "\n",
    "- **Operaciones de combinación:**  \n",
    "  Las operaciones de *merge* y *join* en pandas son equivalentes a los *JOINs* en SQL, permitiendo combinar datos de diferentes tablas o DataFrames basándose en claves comunes.\n",
    "\n",
    "- **Agrupación y agregación:**  \n",
    "  La función `groupby()` de pandas es similar a la cláusula `GROUP BY` en SQL, lo que permite agrupar datos y aplicar funciones de agregación (como suma, promedio, etc.) a cada grupo.\n",
    "\n",
    "- **Transformación de datos:**  \n",
    "  Al igual que en SQL se pueden utilizar funciones de agregación y subconsultas para transformar datos, pandas ofrece funciones como `pivot_table()` para reorganizar y resumir datos, similar a las tablas pivot que se pueden generar con consultas SQL avanzadas.\n",
    "\n",
    "- **Extracción de datos:**  \n",
    "  Pandas permite conectarse a bases de datos SQL y ejecutar consultas directamente con funciones como `read_sql()`, facilitando la integración de consultas SQL y análisis en Python.\n",
    "\n",
    "En resumen, mientras SQL se centra en la gestión y consulta de datos en bases de datos relacionales, pandas proporciona una interfaz más flexible y orientada a la manipulación en memoria, lo que permite realizar operaciones similares a SQL con mayor facilidad y adaptabilidad en entornos de análisis y ciencia de datos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

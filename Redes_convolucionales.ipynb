{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cba41524-a1be-4244-9057-95b5d601bbd3",
   "metadata": {},
   "source": [
    "## 1. Introducción a las redes neuronales convolucionales (CNN)\n",
    "\n",
    "Las redes neuronales convolucionales, o CNN (del inglés *Convolutional Neural Networks*), son un tipo de arquitectura de red neuronal específicamente diseñada para procesar datos que tienen una estructura de cuadrícula, como las imágenes. Surgieron a partir del trabajo pionero de Yann LeCun con **LeNet** en la década de 1990, y posteriormente se convirtieron en uno de los enfoques más relevantes para tareas de visión por computadora como clasificación, detección de objetos, segmentación semántica, entre otras.\n",
    "\n",
    "La clave del éxito de las CNN radica en su capacidad para extraer y aprender características jerárquicas: los primeros filtros convolucionales detectan patrones de bajo nivel (bordes, texturas simples), mientras que las capas más profundas combinan estas características para reconocer formas más complejas. Este aprendizaje **jerárquico** elimina la necesidad de diseñar manualmente \"descriptores\" o \"features\" para las imágenes, como sucedía en técnicas clásicas de la visión por computador.\n",
    "\n",
    "A grandes rasgos, una CNN consiste en una secuencia de capas convolucionales, capas de activación (como ReLU), capas de *pooling* (para reducir la dimensionalidad) y, opcionalmente, capas totalmente conectadas (fully connected), seguidas de una capa de salida. El entrenamiento de una CNN es supervisado y se realiza a través del procedimiento de retropropagación del error (*backpropagation*), con un optimizador como SGD, Adam, o variantes de estos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3533a55-f862-4ef7-b1ab-814e07c59ba6",
   "metadata": {},
   "source": [
    "### 2. Conceptos fundamentales\n",
    "\n",
    "#### 2.1 Operación de convolución\n",
    "\n",
    "La **convolución** en el contexto de las CNN consiste en hacer pasar un \"filtro\" (también llamado *kernel*) de tamaño fijo sobre la imagen o entrada anterior. Cada posición del filtro realiza una multiplicación punto a punto con los valores de la región de la imagen y produce un valor de salida. El valor resultante forma parte de un nuevo mapa de características (*feature map*).\n",
    "\n",
    "- **Filtros**: Típicamente se utilizan filtros de tamaños 3×3 o 5×5, aunque hay variantes con tamaños 1×1 o 7×7, dependiendo de la arquitectura.\n",
    "- **Stride**: Es el paso con el que se mueve el kernel sobre la imagen. Un *stride* mayor a 1 reduce la resolución de la salida, ya que se \"salta\" píxeles.\n",
    "- **Padding**: Se añaden ceros (o algún otro valor) en los bordes de la imagen antes de aplicar la convolución para controlar el tamaño de la salida.\n",
    "\n",
    "#### 2.2 Funciones de activación\n",
    "\n",
    "Luego de cada convolución se aplica típicamente una función de activación no lineal. La más común en CNN es la **ReLU** (Rectified Linear Unit), definida como:\n",
    "\n",
    "$$\n",
    "\\mathrm{ReLU}(x) = \\max(0, x)\n",
    "$$\n",
    "\n",
    "La ReLU ayuda a que la red aprenda representaciones de mayor complejidad al introducir no linealidades y reducir el problema del *vanishing gradient* (gradiente que se vuelve demasiado pequeño en redes profundas). Existen variantes como **Leaky ReLU**, **ELU**, **GELU**, entre otras.\n",
    "\n",
    "#### 2.3 Pooling\n",
    "\n",
    "Las capas de *pooling* (o submuestreo) se usan para reducir el tamaño espacial de los mapas de características, con el fin de:\n",
    "1. Disminuir la dimensionalidad de la salida, lo que conlleva una reducción en el número de parámetros y del costo computacional.\n",
    "2. Hacer la red más robusta a pequeñas traslaciones o distorsiones en la imagen.\n",
    "\n",
    "Existen diferentes tipos de *pooling*:\n",
    "\n",
    "- **Max pooling**: Toma el valor máximo dentro de cada ventana de submuestreo.\n",
    "- **Average pooling**: Toma el promedio de los valores dentro de cada ventana.\n",
    "\n",
    "#### 2.4 Capas completamente conectadas\n",
    "\n",
    "Tras secuencias de capas convolucionales y *pooling*, algunas arquitecturas añaden capas completamente conectadas (*fully connected layers*), generalmente hacia el final de la red, para mapear las características extraídas a clases o a valores de salida concretos.\n",
    "\n",
    "#### 2.5 Batch normalization\n",
    "\n",
    "Introducida en 2015, **batch normalization** normaliza las activaciones de la capa previa, reduciendo problemas de covariate shift y acelerando significativamente el entrenamiento. Suele colocarse después de la convolución y antes de la activación ReLU, aunque también hay variantes donde se coloca después de la activación.\n",
    "\n",
    "#### 2.6 Regularización\n",
    "\n",
    "Para evitar sobreajuste (overfitting), es común utilizar:\n",
    "- **Dropout**: Apaga aleatoriamente neuronas (con cierta probabilidad $p$) durante el entrenamiento.\n",
    "- **Weight decay** (o regularización L2): Penaliza los valores altos de los pesos en la función de costo.\n",
    "- **Data augmentation**: Transformaciones aleatorias (rotaciones, recortes, espejado) sobre las imágenes para incrementar el tamaño efectivo del conjunto de entrenamiento y mejorar la capacidad de generalización."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadb9c33-b888-470b-9aed-71735cb8ffae",
   "metadata": {},
   "source": [
    "### 3. Transfer learning\n",
    "\n",
    "El *transfer learning* consiste en aprovechar una red previamente entrenada (generalmente en un dataset grande como ImageNet) para adaptarla a otra tarea diferente, con menor cantidad de datos disponibles. Esto ofrece varias ventajas:\n",
    "\n",
    "- **Menor tiempo de entrenamiento**: Aprovechamos los parámetros ya aprendidos en tareas de visión genéricas.\n",
    "- **Regularización implícita**: Evitamos el sobreajuste, aprovechando filtros que ya capturan rasgos visuales fundamentales (bordes, esquinas, texturas) aprendidos con grandes volúmenes de datos.\n",
    "- **Eficiencia de datos**: Funciona especialmente bien cuando el conjunto de datos para la nueva tarea es reducido.\n",
    "\n",
    "Existen dos estrategias principales en *transfer learning*:\n",
    "\n",
    "1. **Feature extraction** (Extracción de características): \n",
    "   - Se utiliza la red preentrenada como extractor de características fijas, congelando (o \"freezing\") todas o casi todas las capas, para luego entrenar solo la capa final (o algunas capas finales) en el nuevo dataset.\n",
    "\n",
    "2. **Fine-tuning** (Ajuste Fino):\n",
    "   - Se cargan los pesos preentrenados y se permite entrenar (descongelar) al menos un subconjunto de capas (generalmente las más profundas). Así, la red ajusta parámetros a la nueva tarea, pero sin perder las características básicas ya aprendidas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260137b9-6d87-4169-a527-c52c0a590bdf",
   "metadata": {},
   "source": [
    "### 4. Arquitecturas relevantes\n",
    "\n",
    "A continuación, se listan algunos hitos importantes en la evolución de las CNN:\n",
    "\n",
    "1. **LeNet (1998)**: Yann LeCun aplicó convoluciones para la clasificación de dígitos en el conjunto MNIST.\n",
    "2. **AlexNet (2012)**: Impulsada por Alex Krizhevsky y Geoffrey Hinton, con ocho capas entrenadas en ImageNet, evidenció el potencial de las CNN en la clasificación de miles de categorías de imágenes.\n",
    "3. **VGG (2014)**: Propuesta por Simonyan y Zisserman. Se caracteriza por usar convoluciones 3×3 y un diseño muy homogéneo y profundo (VGG16, VGG19).\n",
    "4. **GoogLeNet / Inception (2014-2015)**: Introduce el módulo *Inception*, combinando convoluciones con distintos tamaños de kernel en paralelo para extraer características a diferentes escalas.\n",
    "5. **ResNet (2015)**: Propuesta por He et al. Resuelve problemas de degradación en redes muy profundas con la introducción de conexiones residuales (*skip connections*), permitiendo entrenar redes de cientos de capas (ResNet50, ResNet101, etc.).\n",
    "6. **DenseNet (2017)**: Utiliza conexiones densas en las que cada capa recibe como entrada los mapas de características de todas las capas anteriores.\n",
    "\n",
    "Actualmente, ResNet y variantes de modelos \"residuales\" son muy populares. Además de su efectividad, se suelen usar como base para *transfer learning* en multitud de aplicaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866a24f3-dee7-42cb-96d5-f801fd24aa73",
   "metadata": {},
   "source": [
    "### 5. Ejemplo de CNN\n",
    "\n",
    "A modo de ilustración, construyamos una CNN simple para clasificación en el dataset **CIFAR-10** (10 clases: aviones, automóviles, pájaros, gatos, etc.). Este ejemplo muestra el flujo de trabajo en PyTorch.\n",
    "\n",
    "> **Nota**: En un cuaderno de Jupyter, se recomienda instalar las dependencias con `pip install torch torchvision` si no están ya instaladas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b21bc87-bd04-4273-926e-994ae4b3e776",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b642cd89-ac97-4e2a-85ad-ac3380a3cca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 1. Transformaciones y carga de datos\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)) # valores medios y std de CIFAR-10\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform_train\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform_test\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "# 2. Definimos la arquitectura de la red\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # Bloque 1\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),  # Entrada (3, 32,32), Salida (32, 32,32)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),       # Salida (32, 16,16)\n",
    "\n",
    "            # Bloque 2\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),       # Salida (64, 8,8)\n",
    "\n",
    "            # Bloque 3\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)        # Salida (128, 4,4)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128 * 4 * 4, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# 3. Instanciar la red y definir el optimizador y la función de pérdida\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "modelo = SimpleCNN().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(modelo.parameters(), lr=0.001)\n",
    "\n",
    "# 4. Bucle de entrenamiento\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    modelo.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = modelo(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Calcular el accuracy en el conjunto de prueba para cada epoca\n",
    "    modelo.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = modelo(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    accuracy = 100. * correct / total\n",
    "\n",
    "    print(f\"Época [{epoch+1}/{num_epochs}], Pérdida: {running_loss/len(train_loader):.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "print(\"Entrenamiento finalizado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc904ec-9769-4d0f-8d1d-bb1648750327",
   "metadata": {},
   "source": [
    "En esta red se incluyen conceptos como:\n",
    "\n",
    "- Dos convoluciones consecutivas antes de un *max pooling* (inspirado ligeramente en VGG).\n",
    "- **Dropout** en la parte final para evitar sobreajuste.\n",
    "- Función de activación ReLU en cada convolución.\n",
    "\n",
    "Además, se aplica *data augmentation* básico en CIFAR-10 para mejorar la robustez del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f7a1bb-681e-440b-87b5-7401fc0c5a9c",
   "metadata": {},
   "source": [
    "### 6. Ejemplo de transfer learning con PyTorch\n",
    "\n",
    "Ahora veremos cómo usar un modelo preentrenado en ImageNet (por ejemplo, **ResNet18**) y ajustarlo para CIFAR-10. \n",
    "\n",
    "#### 6.1 Congelar capas y entrenar la última capa\n",
    "\n",
    "En este primer ejemplo, solo cambiaremos la capa final (el *classifier*) y congelaremos el resto de la red. De este modo, se aprovechan las características previamente aprendidas en ImageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79f4b41-8fe4-425c-8f86-51e6203a859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "\n",
    "# Supongamos que ya tenemos los DataLoaders (train_loader, test_loader) definidos como en el ejemplo anterior.\n",
    "\n",
    "# 1. Cargar modelo ResNet18 preentrenado\n",
    "resnet18 = models.resnet18(weights=True)\n",
    "\n",
    "# 2. Congelar los parámetros de las capas convolucionales\n",
    "for param in resnet18.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 3. Reemplazar la capa fully connected (fc) final\n",
    "num_ftrs = resnet18.fc.in_features  # número de características de salida de la penúltima capa\n",
    "resnet18.fc = nn.Linear(num_ftrs, 10)  # 10 clases para CIFAR-10\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet18 = resnet18.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Solo entrenamos los parámetros de la nueva capa (resnet18.fc)\n",
    "optimizer = optim.Adam(resnet18.fc.parameters(), lr=0.001)\n",
    "\n",
    "num_epocas = 5\n",
    "for epoca in range(num_epocas):\n",
    "    resnet18.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet18(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Validación en el conjunto de prueba\n",
    "    resnet18.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = resnet18(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    accuracy = 100. * correct / total\n",
    "    print(f\"[{epoca+1}/{num_epocas}] Pérdida: {running_loss/len(train_loader):.4f}, Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0518427c-ae83-498c-8151-76cabee03ba3",
   "metadata": {},
   "source": [
    "En este escenario, toda la red permanece fija (los gradientes no fluyen a través de los pesos congelados), excepto la nueva capa totalmente conectada, que se entrena para la clasificación en CIFAR-10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa15955-89ab-4158-834e-f0d70f7e260f",
   "metadata": {},
   "source": [
    "#### 6.2 Fine-tuning (ajuste fino)\n",
    "\n",
    "Si queremos un poco más de flexibilidad y esperamos que la nueva tarea difiera lo suficiente de ImageNet, podemos optar por hacer *fine-tuning* de algunas capas convolucionales. Normalmente se descongelan las últimas capas convolucionales (más \"especializadas\"). \n",
    "\n",
    "Por ejemplo, podemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38301a2f-471d-48a5-a719-02ac1597344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = models.resnet18(weights=True)\n",
    "\n",
    "# Congelamos la mayoría de capas excepto las últimas\n",
    "ct = 0\n",
    "for name, child in resnet18.named_children():\n",
    "    ct += 1\n",
    "    if ct < 7:\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "# Reemplazamos la capa final\n",
    "num_ftrs = resnet18.fc.in_features\n",
    "resnet18.fc = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "resnet18 = resnet18.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Ahora entrenamos con un lr menor para no destruir los pesos preentrenados\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, resnet18.parameters()), lr=1e-4)\n",
    "\n",
    "# Proceso de entrenamiento similar\n",
    "num_epocas = 5\n",
    "for epoca in range(num_epocas):\n",
    "    resnet18.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet18(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    resnet18.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = resnet18(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    accuracy = 100. * correct / total\n",
    "    print(f\"Época {epoch+1}, Pérdida: {running_loss/len(train_loader):.4f}, Exactitud: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844cfbde-7e02-4e90-a66c-29aea3f30b7c",
   "metadata": {},
   "source": [
    "Con este enfoque, los pesos de la parte de la red que está descongelada se ajustan, lo que suele dar mejores resultados que mantener la red completamente congelada, a costa de un mayor riesgo de sobreajuste y más tiempo de entrenamiento. Es fundamental **ajustar la tasa de aprendizaje** para evitar romper los pesos preentrenados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f349c4a3-b202-4468-ab72-2a0b337498ee",
   "metadata": {},
   "source": [
    "### 7. Técnicas avanzadas y buenas prácticas\n",
    "\n",
    "#### 7.1 Data augmentation avanzado\n",
    "\n",
    "Además de las transformaciones básicas (rotaciones, recortes, espejado horizontal), pueden emplearse transformaciones más complejas para robustecer el modelo frente a variaciones en iluminación, color, perspectiva, etc. PyTorch provee `transforms.ColorJitter`, `transforms.RandomRotation`, `transforms.RandomResizedCrop`, etc.  \n",
    "\n",
    "#### 7.2 Early stopping\n",
    "\n",
    "Muchas veces se monitoriza la pérdida de validación (validation loss) para detener el entrenamiento cuando deja de mejorar, evitando el sobreajuste.\n",
    "\n",
    "#### 7.3 Learning rate scheduling\n",
    "\n",
    "Cambiar dinámicamente la tasa de aprendizaje puede acelerar la convergencia y ayudar a escapar de mínimos locales. En PyTorch se hace con herramientas como `torch.optim.lr_scheduler`, por ejemplo `StepLR`, `ReduceLROnPlateau` o `CosineAnnealingLR`.\n",
    "\n",
    "#### 7.4 Mezcla de datos (\"MixUp\", \"CutMix\")\n",
    "\n",
    "Son técnicas que mezclan (linealmente o por recortes) diferentes imágenes y etiquetas durante el entrenamiento, introduciendo regularización adicional y, a menudo, mejoras de *generalization*.\n",
    "\n",
    "### 7.5 Weight initialization\n",
    "\n",
    "Aunque los modelos preentrenados suelen incorporar pesos ya optimizados, al iniciar redes desde cero es importante la inicialización adecuada de los pesos (p.ej. Kaiming initialization, Xavier initialization).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6926583-2c91-403e-b39c-dd1f00e8fffa",
   "metadata": {},
   "source": [
    "### Ejercicios\n",
    "\n",
    "### Ejercicio 1: Construir una CNN básica desde cero\n",
    "\n",
    "**Objetivo**: Familiarizarse con la estructura básica de una red convolucional (convoluciones, pooling, capas fully connected, etc.) y entrenarla para una tarea de clasificación sencilla.\n",
    "\n",
    "1. **Dataset**: Utiliza el conjunto de datos **MNIST** o **CIFAR-10** (ambos disponibles en `torchvision.datasets`).\n",
    "2. **Modelo**:\n",
    "   - Diseña tu propia clase `MySimpleCNN(nn.Module)` con:\n",
    "     - Dos bloques de capas convolucionales (cada uno con conv → ReLU → conv → ReLU → max pool).\n",
    "     - Una o dos capas fully connected (lineales) al final.\n",
    "   - Incluye algún tipo de regularización, por ejemplo `Dropout`.\n",
    "3. **Entrenamiento**:\n",
    "   - Usa `CrossEntropyLoss` como función de pérdida.\n",
    "   - Emplea `Adam` o `SGD` como optimizador.\n",
    "   - Entrena durante 10-15 épocas.\n",
    "4. **Evaluación**:\n",
    "   - Calcula la exactitud (accuracy) en el conjunto de validación o test.\n",
    "   - Observa la evolución de la pérdida y la exactitud durante el entrenamiento.\n",
    "\n",
    "\n",
    "\n",
    "## Ejercicio 2: Data augmentation avanzado\n",
    "\n",
    "**Objetivo**: Experimentar con diferentes técnicas de aumento de datos (data augmentation) para mejorar la robustez del modelo.\n",
    "\n",
    "1. **Modifica** el *pipeline* de transformaciones para incluir:\n",
    "   - `RandomHorizontalFlip()`\n",
    "   - `RandomCrop()` con *padding*\n",
    "   - `ColorJitter()`\n",
    "   - `RandomRotation()`\n",
    "2. **Comparación**:\n",
    "   - Entrena la misma arquitectura del Ejercicio 1 con y sin data augmentation.\n",
    "   - Compara la precisión y pérdida de validación.\n",
    "\n",
    "**Código base sugerido** (fragmento):\n",
    "\n",
    "```python\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), \n",
    "                         (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "```\n",
    "\n",
    "**Preguntas**:\n",
    "- ¿Qué efecto tienen estas transformaciones en el sobreajuste?\n",
    "- ¿En qué casos puede deteriorarse el rendimiento si se exagera el data augmentation?\n",
    "\n",
    "\n",
    "#### Ejercicio 3: Transfer learning (Feature Extraction)\n",
    "\n",
    "**Objetivo**: Utilizar un modelo preentrenado (ResNet18) como extractor de características y entrenar únicamente la capa de clasificación final.\n",
    "\n",
    "1. **Carga** `resnet18` desde `torchvision.models` con `weights=True`.\n",
    "2. **Congela** todos los parámetros convolucionales (`requires_grad=False`).\n",
    "3. **Reemplaza** la capa final (`resnet18.fc`) para clasificar 10 clases (CIFAR-10, por ejemplo).\n",
    "4. **Entrena** solo la nueva capa por 5-10 épocas.\n",
    "\n",
    "**Código base sugerido**:\n",
    "\n",
    "```python\n",
    "from torchvision import models\n",
    "\n",
    "resnet18 = models.resnet18(weights=True)\n",
    "\n",
    "# Congelar las capas convolucionales\n",
    "for param in resnet18.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Reemplazar la FC final\n",
    "num_ftrs = resnet18.fc.in_features\n",
    "resnet18.fc = nn.Linear(num_ftrs, 10)  # CIFAR-10 => 10 clases\n",
    "\n",
    "resnet18.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet18.fc.parameters(), lr=0.001)\n",
    "\n",
    "# Entrena solo la última capa\n",
    "...\n",
    "```\n",
    "\n",
    "**Preguntas**:\n",
    "- Mide el tiempo de entrenamiento y compara con una arquitectura entrenada desde cero.\n",
    "- Observa si la red alcanza rápidamente buenos resultados con pocas épocas.\n",
    "\n",
    "\n",
    "#### Ejercicio 4: Fine-Tuning (ajuste fino)\n",
    "\n",
    "**Objetivo**: Ajustar parcialmente (o totalmente) los pesos de un modelo preentrenado para adaptarlo a un dataset más complejo o distinto.\n",
    "\n",
    "1. **Elige** cuántos “bloques” finales de ResNet descongelar. Por ejemplo, descongela a partir de la capa *layer3* o *layer4*.\n",
    "2. **Configura** un *learning rate* bajo para los parámetros descongelados (p.ej. $1\\times10^{-4}$) para no \"destruir\" los pesos preentrenados.\n",
    "3. **Entrena** de nuevo y compara el rendimiento con el ejercicio anterior.\n",
    "\n",
    "**Esqueleto de código**:\n",
    "\n",
    "```python\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "\n",
    "# Congelamos casi todas las capas excepto las últimas\n",
    "# Este ejemplo deja congeladas las capas 0 a 6\n",
    "ct = 0\n",
    "for name, child in resnet18.named_children():\n",
    "    ct += 1\n",
    "    if ct < 7:\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "# Ajustamos la FC final\n",
    "num_ftrs = resnet18.fc.in_features\n",
    "resnet18.fc = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "resnet18 = resnet18.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, resnet18.parameters()), \n",
    "    lr=1e-4\n",
    ")\n",
    "\n",
    "# Entrenamiento\n",
    "...\n",
    "```\n",
    "\n",
    "**Preguntas**:\n",
    "- Analiza cuántas capas descongelar y cómo repercute en la capacidad de ajuste a la nueva tarea.\n",
    "- Prueba diferentes *learning rates* para las capas preentrenadas vs. las capas nuevas.\n",
    "\n",
    "\n",
    "#### Ejercicio 5: Regularización y *early stopping*\n",
    "\n",
    "**Objetivo**: Implementar técnicas de regularización (Weight Decay, Dropout, etc.) y usar *early stopping* para evitar sobreajuste.\n",
    "\n",
    "1. **Añade** `weight_decay` en el optimizador, por ejemplo `optim.Adam(model.parameters(), lr=..., weight_decay=1e-4)`.\n",
    "2. **Monitoriza** la pérdida de validación. Si no mejora durante $n$ épocas consecutivas, detén el entrenamiento.\n",
    "3. **Compara** el resultado final (número de épocas efectivas, exactitud) con la estrategia previa de entrenar un número fijo de épocas.\n",
    "\n",
    "**Esqueleto de *early stopping***:\n",
    "\n",
    "```python\n",
    "best_val_loss = float('inf')\n",
    "patience = 3\n",
    "trigger_times = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Entrenamiento ...\n",
    "    \n",
    "    # Validación ...\n",
    "    val_loss = ...\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        trigger_times = 0\n",
    "        # Guardar el modelo ...\n",
    "    else:\n",
    "        trigger_times += 1\n",
    "        if trigger_times >= patience:\n",
    "            print(\"Early stopping activado.\")\n",
    "            break\n",
    "```\n",
    "\n",
    "**Preguntas**:\n",
    "- ¿Cuándo usar *early stopping* vs. entrenar muchas épocas?\n",
    "- ¿Cómo el *weight decay* contribuye a la generalización?\n",
    "\n",
    "\n",
    "#### Ejercicio 6: Programar un *learning rate scheduler*\n",
    "\n",
    "**Objetivo**: Implementar un plan de decremento de la tasa de aprendizaje durante el entrenamiento.\n",
    "\n",
    "1. **Utiliza** `torch.optim.lr_scheduler` (por ejemplo, `StepLR` o `ReduceLROnPlateau`).\n",
    "2. **Observa** cómo el entrenamiento se comporta cuando la tasa de aprendizaje se reduce tras cierto número de épocas o tras estancarse la validación.\n",
    "\n",
    "**Ejemplo con `StepLR`**:\n",
    "\n",
    "```python\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "for epoca in range(num_epocas):\n",
    "    # Entrenamiento ...\n",
    "    \n",
    "    scheduler.step()  # ajusta el LR cada cierto step\n",
    "```\n",
    "\n",
    "**Preguntas**:\n",
    "- ¿En qué escenarios conviene reducir la tasa de aprendizaje de forma escalonada o suave?\n",
    "- ¿Qué diferencias notas frente a un *learning rate* constante?\n",
    "\n",
    "#### Ejercicio 7: Implementar *MixUp* o *CutMix*\n",
    "\n",
    "**Objetivo**: Familiarizarte con técnicas de mezcla de datos para regularización avanzada.\n",
    "\n",
    "1. **Implementa** la función `mixup_data(x, y, alpha)` que, dada una minibatch de imágenes y etiquetas, genera un conjunto mezclado con una distribución Beta($\\alpha, \\alpha$).\n",
    "2. **Modifica** la pérdida: cuando haces forward con la imagen mezclada, la etiqueta también será una combinación lineal (en *one-hot* o manipulando los índices).\n",
    "3. **Mide** si hay incremento en la robustez del modelo frente a la baselínea sin MixUp/CutMix.\n",
    "\n",
    "**Pseudocódigo** (muy simplificado para MixUp):\n",
    "\n",
    "```python\n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9284ae-d9b7-4c86-bb55-e2783e65bf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tus respuestas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
